// OfficeX filesharing app (clone of google drive)
// where possible, show the code changes as green diffs without the +/- symbols

// src/core/state/disks/state.rs
pub mod state {
    use std::cell::RefCell;
    use std::collections::HashMap;

    use crate::{core::{api::uuid::generate_unique_id, state::{disks::types::{Disk, DiskID, DiskTypeEnum, DEFAULT_BROWSERCACHE_DISK_ID, DEFAULT_CANISTER_DISK_ID}, drives::state::state::CANISTER_ID}}, debug_log};
    
    thread_local! {
        pub(crate) static DISKS_BY_ID_HASHTABLE: RefCell<HashMap<DiskID, Disk>> = RefCell::new(HashMap::new());
        pub(crate) static DISKS_BY_EXTERNAL_ID_HASHTABLE: RefCell<HashMap<String, DiskID>> = RefCell::new(HashMap::new());
        pub(crate) static DISKS_BY_TIME_LIST: RefCell<Vec<DiskID>> = RefCell::new(Vec::new());
    }

    pub fn init_default_disks() {

        debug_log!("Initializing default admin api key...");

        let current_canister_disk_id = generate_unique_id("DiskID", &format!("_{}", ic_cdk::api::id().to_text()));
        let default_canister_disk = Disk {
            id: DiskID(current_canister_disk_id.clone()),
            name: "Self Canister Storage (Default)".to_string(),
            disk_type: DiskTypeEnum::IcpCanister,
            private_note: Some("Default Canister Storage".to_string()),
            public_note: Some("Default Canister Storage".to_string()),
            auth_json: None,
            external_id: Some(DEFAULT_CANISTER_DISK_ID.to_string()),
        };
        let browsercache_disk_id = generate_unique_id("DiskID", &format!("_{}", "_browsercache"));
        let default_browsercache_disk = Disk {
            id: DiskID(browsercache_disk_id.clone()),
            name: "Ephemeral Browser Storage (Default)".to_string(),
            disk_type: DiskTypeEnum::BrowserCache,
            private_note: Some("Offline web browser cache. Do not expect persistence in case browser history cleared.".to_string()),
            public_note: Some("Offline web browser cache. Do not expect persistence in case browser history cleared.".to_string()),
            auth_json: None,
            external_id: Some(DEFAULT_BROWSERCACHE_DISK_ID.to_string()),
        };

        let default_disks = vec![default_canister_disk, default_browsercache_disk];

        for disk in default_disks {
            DISKS_BY_ID_HASHTABLE.with(|map| {
                map.borrow_mut().insert(disk.id.clone(), disk.clone());
            });

            DISKS_BY_EXTERNAL_ID_HASHTABLE.with(|map| {
                map.borrow_mut().insert(disk.external_id.clone().unwrap(), disk.id.clone());
            });

            DISKS_BY_TIME_LIST.with(|list| {
                list.borrow_mut().push(disk.id.clone());
            });
        }

    }
}





// src/core/state/disks/types.rs
use serde::{Serialize, Deserialize};
use std::fmt;


#[derive(Debug, Clone, PartialEq, Eq, Hash, Serialize, Deserialize)]
pub struct DiskID(pub String);

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Disk {
    pub id: DiskID,
    pub name: String,
    pub disk_type: DiskTypeEnum,
    pub private_note: Option<String>,
    pub public_note: Option<String>,
    pub auth_json: Option<String>,
    pub external_id: Option<String>,
}

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
pub enum DiskTypeEnum {
    BrowserCache,
    LocalSSD,
    AwsBucket,
    StorjWeb3,
    IcpCanister,
}
impl fmt::Display for DiskTypeEnum {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        match self {
            DiskTypeEnum::BrowserCache => write!(f, "BrowserCache"),
            DiskTypeEnum::LocalSSD => write!(f, "LocalSSD"),
            DiskTypeEnum::AwsBucket => write!(f, "AwsBucket"),
            DiskTypeEnum::StorjWeb3 => write!(f, "StorjWeb3"),
            DiskTypeEnum::IcpCanister => write!(f, "IcpCanister"),
        }
    }
}

pub const DEFAULT_CANISTER_DISK_ID: &str = "DEFAULT_CANISTER_DISK_ID";
pub const DEFAULT_BROWSERCACHE_DISK_ID: &str = "DEFAULT_BROWSERCACHE_DISK_ID";


#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct AwsBucketAuth {
    pub(crate) endpoint: String,
    pub(crate) access_key: String,
    pub(crate) secret_key: String,
    pub(crate) bucket: String,
}


// src/rest/disks/types.rs

use serde::{Deserialize, Serialize};

use crate::{
    core::state::disks::types::{Disk, DiskID, DiskTypeEnum},
    rest::webhooks::types::SortDirection,
};

#[derive(Debug, Clone, Deserialize)]
pub struct ListDisksRequestBody {
    #[serde(default)]
    pub filters: String,
    #[serde(default = "default_page_size")]
    pub page_size: usize,
    #[serde(default)]
    pub direction: SortDirection,
    pub cursor_up: Option<String>,
    pub cursor_down: Option<String>,
}

fn default_page_size() -> usize {
    50
}

#[derive(Debug, Clone, Serialize)]
pub struct ListDisksResponseData {
    pub items: Vec<Disk>,
    pub page_size: usize,
    pub total: usize,
    pub cursor_up: Option<String>,
    pub cursor_down: Option<String>,
}

#[derive(Debug, Clone, Deserialize)]
#[serde(untagged)]
pub enum UpsertDiskRequestBody {
    Create(CreateDiskRequestBody),
    Update(UpdateDiskRequestBody),
}

#[derive(Debug, Clone, Deserialize)]
#[serde(deny_unknown_fields)]
pub struct CreateDiskRequestBody {
    pub name: String,
    pub disk_type: DiskTypeEnum,
    pub public_note: Option<String>,
    pub private_note: Option<String>,
    pub auth_json: Option<String>,
    pub external_id: Option<String>,
}

#[derive(Debug, Clone, Deserialize)]
pub struct UpdateDiskRequestBody {
    pub id: String,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub public_note: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub private_note: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub auth_json: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub external_id: Option<String>,
}

#[derive(Debug, Clone, Deserialize)]
pub struct DeleteDiskRequest {
    pub id: DiskID,
}

#[derive(Debug, Clone, Serialize)]
pub struct DeletedDiskData {
    pub id: DiskID,
    pub deleted: bool,
}

pub type GetDiskResponse<'a> = DiskResponse<'a, Disk>;
pub type DeleteDiskResponse<'a> = DiskResponse<'a, DeletedDiskData>;
pub type ErrorResponse<'a> = DiskResponse<'a, ()>;
pub type ListDisksResponse<'a> = DiskResponse<'a, ListDisksResponseData>;
pub type CreateDiskResponse<'a> = DiskResponse<'a, Disk>;
pub type UpdateDiskResponse<'a> = DiskResponse<'a, Disk>;

#[derive(Debug, Clone, Serialize)]
#[serde(rename_all = "lowercase")]
pub enum DiskResponse<'a, T>
where
    T: Serialize,
{
    Ok { data: &'a T },
    Err { code: u16, message: String },
}

impl<'a, T> DiskResponse<'a, T>
where
    T: Serialize,
{
    pub fn ok(data: &'a T) -> Self {
        DiskResponse::Ok { data }
    }

    pub fn err(code: u16, message: String) -> Self {
        DiskResponse::Err { code, message }
    }

    pub fn encode(&self) -> Vec<u8> {
        serde_json::to_vec(self).unwrap_or_else(|_| 
            serde_json::to_vec(&DiskResponse::Err::<()> {
                code: 500,
                message: "Failed to serialize response".to_string(),
            }).unwrap_or_default()
        )
    }
}

impl<'a> DiskResponse<'a, ()> {
    pub fn not_found() -> Self {
        DiskResponse::Err {
            code: 404,
            message: "Not found".to_string(),
        }
    }
}


// src/rest/disks/route.rs
use crate::debug_log;
use crate::rest::router;
use crate::types::RouteHandler;

pub const DISKS_GET_PATH: &str = "/disks/get/{disk_id}";
pub const DISKS_LIST_PATH: &str = "/disks/list";
pub const DISKS_UPSERT_PATH: &str = "/disks/upsert";
pub const DISKS_DELETE_PATH: &str = "/disks/delete";

type HandlerEntry = (&'static str, &'static str, RouteHandler);

pub fn init_routes() {
    let routes: &[HandlerEntry] = &[
        (
            "GET",
            DISKS_GET_PATH,
            crate::rest::disks::handler::disks_handlers::get_disk_handler,
        ),
        (
            "POST",
            DISKS_LIST_PATH,
            crate::rest::disks::handler::disks_handlers::list_disks_handler,
        ),
        (
            "POST",
            DISKS_UPSERT_PATH,
            crate::rest::disks::handler::disks_handlers::upsert_disk_handler,
        ),
        (
            "POST",
            DISKS_DELETE_PATH,
            crate::rest::disks::handler::disks_handlers::delete_disk_handler,
        )
    ];

    for &(method, path, handler) in routes {
        debug_log!("Registering {} route: {}", method, path);
        router::insert_route(method, path, handler);
    }

}



// src/rest/disks/handler.rs


pub mod disks_handlers {
    use crate::{
        core::{api::uuid::generate_unique_id, state::{disks::{state::state::{DISKS_BY_EXTERNAL_ID_HASHTABLE, DISKS_BY_ID_HASHTABLE, DISKS_BY_TIME_LIST}, types::{Disk, DiskID}}, drives::state::state::OWNER_ID}}, debug_log, rest::{auth::{authenticate_request, create_auth_error_response}, disks::types::{ CreateDiskResponse, DeleteDiskRequest, DeleteDiskResponse, DeletedDiskData, ErrorResponse, GetDiskResponse, ListDisksRequestBody, ListDisksResponse, ListDisksResponseData, UpdateDiskResponse, UpsertDiskRequestBody}, webhooks::types::SortDirection}
        
    };
    use ic_http_certification::{HttpRequest, HttpResponse, StatusCode};
    use matchit::Params;
    use serde::Deserialize;
    #[derive(Deserialize, Default)]
    struct ListQueryParams {
        title: Option<String>,
        completed: Option<bool>,
    }

    pub fn get_disk_handler(req: &HttpRequest, params: &Params) -> HttpResponse<'static> {
        // Authenticate request
        let requester_api_key = match authenticate_request(req) {
            Some(key) => key,
            None => return create_auth_error_response(),
        };

        // Only owner can access disk.private_note
        let is_owner = OWNER_ID.with(|owner_id| requester_api_key.user_id == *owner_id);
        if !is_owner {
            return create_auth_error_response();
        }

        // Get disk ID from params
        let disk_id = DiskID(params.get("disk_id").unwrap().to_string());

        // Get the disk
        let disk = DISKS_BY_ID_HASHTABLE.with(|store| {
            store.borrow().get(&disk_id).cloned()
        });

        match disk {
            Some(mut disk) => {
                if !is_owner {
                    disk.private_note = None;
                    disk.auth_json = None;
                }
                create_response(
                    StatusCode::OK,
                    GetDiskResponse::ok(&disk).encode()
                )
            },
            None => create_response(
                StatusCode::NOT_FOUND,
                ErrorResponse::not_found().encode()
            ),
        }
    }

    pub fn list_disks_handler(request: &HttpRequest, _params: &Params) -> HttpResponse<'static> {
        // Authenticate request
        let requester_api_key = match authenticate_request(request) {
            Some(key) => key,
            None => return create_auth_error_response(),
        };

        let is_owner = OWNER_ID.with(|owner_id| requester_api_key.user_id == *owner_id);
        if !is_owner {
            return create_auth_error_response();
        }

        // Parse request body
        let body = request.body();
        let request_body: ListDisksRequestBody = match serde_json::from_slice(body) {
            Ok(body) => body,
            Err(_) => return create_response(
                StatusCode::BAD_REQUEST,
                ErrorResponse::err(400, "Invalid request format".to_string()).encode()
            ),
        };

        // Parse cursors if provided
        let cursor_up = if let Some(cursor) = request_body.cursor_up {
            match cursor.parse::<usize>() {
                Ok(idx) => Some(idx),
                Err(_) => return create_response(
                    StatusCode::BAD_REQUEST,
                    ErrorResponse::err(400, "Invalid cursor_up format".to_string()).encode()
                ),
            }
        } else {
            None
        };

        let cursor_down = if let Some(cursor) = request_body.cursor_down {
            match cursor.parse::<usize>() {
                Ok(idx) => Some(idx),
                Err(_) => return create_response(
                    StatusCode::BAD_REQUEST,
                    ErrorResponse::err(400, "Invalid cursor_down format".to_string()).encode()
                ),
            }
        } else {
            None
        };

        // Get total count
        let total_count = DISKS_BY_TIME_LIST.with(|list| list.borrow().len());

        // If there are no disks, return early
        if total_count == 0 {
            return create_response(
                StatusCode::OK,
                ListDisksResponse::ok(&ListDisksResponseData {
                    items: vec![],
                    page_size: 0,
                    total: 0,
                    cursor_up: None,
                    cursor_down: None,
                }).encode()
            );
        }

        // Determine starting point based on cursors
        let start_index = if let Some(up) = cursor_up {
            up.min(total_count - 1)
        } else if let Some(down) = cursor_down {
            down.min(total_count - 1)
        } else {
            match request_body.direction {
                SortDirection::Asc => 0,
                SortDirection::Desc => total_count - 1,
            }
        };

        // Get disks with pagination and filtering
        let mut filtered_disks = Vec::new();
        let mut processed_count = 0;

        DISKS_BY_TIME_LIST.with(|time_index| {
            let time_index = time_index.borrow();
            DISKS_BY_ID_HASHTABLE.with(|id_store| {
                let id_store = id_store.borrow();
                
                match request_body.direction {
                    SortDirection::Desc => {
                        let mut current_idx = start_index;
                        while filtered_disks.len() < request_body.page_size && current_idx < total_count {
                            if let Some(disk) = id_store.get(&time_index[current_idx]) {
                                if request_body.filters.is_empty() {
                                    filtered_disks.push(disk.clone());
                                }
                            }
                            if current_idx == 0 {
                                break;
                            }
                            current_idx -= 1;
                            processed_count = start_index - current_idx;
                        }
                    },
                    SortDirection::Asc => {
                        let mut current_idx = start_index;
                        while filtered_disks.len() < request_body.page_size && current_idx < total_count {
                            if let Some(disk) = id_store.get(&time_index[current_idx]) {
                                if request_body.filters.is_empty() {
                                    filtered_disks.push(disk.clone());
                                }
                            }
                            current_idx += 1;
                            processed_count = current_idx - start_index;
                        }
                    }
                }
            });
        });

        // Calculate next cursors based on direction and current position
        let (cursor_up, cursor_down) = match request_body.direction {
            SortDirection::Desc => {
                let next_up = if start_index < total_count - 1 {
                    Some((start_index + 1).to_string())
                } else {
                    None
                };
                let next_down = if processed_count > 0 && start_index >= processed_count {
                    Some((start_index - processed_count).to_string())
                } else {
                    None
                };
                (next_up, next_down)
            },
            SortDirection::Asc => {
                let next_up = if processed_count > 0 {
                    Some((start_index + processed_count).to_string())
                } else {
                    None
                };
                let next_down = if start_index > 0 {
                    Some((start_index - 1).to_string())
                } else {
                    None
                };
                (next_up, next_down)
            }
        };

        create_response(
            StatusCode::OK,
            ListDisksResponse::ok(&ListDisksResponseData {
                items: filtered_disks.clone(),
                page_size: filtered_disks.len(),
                total: total_count,
                cursor_up,
                cursor_down,
            }).encode()
        )
    }


    pub fn upsert_disk_handler(req: &HttpRequest, _params: &Params) -> HttpResponse<'static> {
        // Authenticate request
        let requester_api_key = match authenticate_request(req) {
            Some(key) => key,
            None => return create_auth_error_response(),
        };

        let is_owner = OWNER_ID.with(|owner_id| requester_api_key.user_id == *owner_id);
        if !is_owner {
            return create_auth_error_response();
        }

        // Parse request body
        let body: &[u8] = req.body();

        if let Ok(req) = serde_json::from_slice::<UpsertDiskRequestBody>(body) {
            match req {
                UpsertDiskRequestBody::Update(update_req) => {
                    let disk_id = DiskID(update_req.id);
                    
                    // Get existing disk
                    let mut disk = match DISKS_BY_ID_HASHTABLE.with(|store| store.borrow().get(&disk_id).cloned()) {
                        Some(disk) => disk,
                        None => return create_response(
                            StatusCode::NOT_FOUND,
                            ErrorResponse::not_found().encode()
                        ),
                    };

                    // Update fields
                    if let Some(name) = update_req.name {
                        disk.name = name;
                    }
                    if let Some(public_note) = update_req.public_note {
                        disk.public_note = Some(public_note);
                    }
                    if let Some(private_note) = update_req.private_note {
                        disk.private_note = Some(private_note);
                    }
                    if let Some(auth_json) = update_req.auth_json {
                        disk.auth_json = Some(auth_json);
                    }
                    if let Some(external_id) = update_req.external_id {
                        // Update external ID mapping
                        if let Some(old_external_id) = &disk.external_id {
                            DISKS_BY_EXTERNAL_ID_HASHTABLE.with(|store| {
                                store.borrow_mut().remove(old_external_id);
                            });
                        }
                        DISKS_BY_EXTERNAL_ID_HASHTABLE.with(|store| {
                            store.borrow_mut().insert(external_id.clone(), disk_id.clone());
                        });
                        disk.external_id = Some(external_id);
                    }

                    DISKS_BY_ID_HASHTABLE.with(|store| {
                        store.borrow_mut().insert(disk_id.clone(), disk.clone());
                    });

                    create_response(
                        StatusCode::OK,
                        UpdateDiskResponse::ok(&disk).encode()
                    )
                },
                UpsertDiskRequestBody::Create(create_req) => {
                    // Create new disk
                    let disk_type_suffix = format!("--DiskType_{}", create_req.disk_type);
                    let disk_id = DiskID(generate_unique_id("DiskID", &disk_type_suffix));
                    let disk = Disk {
                        id: disk_id.clone(),
                        name: create_req.name,
                        public_note: create_req.public_note,
                        private_note: create_req.private_note,
                        auth_json: create_req.auth_json,
                        disk_type: create_req.disk_type,
                        external_id: create_req.external_id.clone(),
                    };

                    // Store the disk
                    DISKS_BY_ID_HASHTABLE.with(|store| {
                        store.borrow_mut().insert(disk_id.clone(), disk.clone());
                    });

                    // Store external ID mapping if provided
                    if let Some(external_id) = &disk.external_id {
                        DISKS_BY_EXTERNAL_ID_HASHTABLE.with(|store| {
                            store.borrow_mut().insert(external_id.clone(), disk_id.clone());
                        });
                    }

                    DISKS_BY_TIME_LIST.with(|store| {
                        store.borrow_mut().push(disk_id.clone());
                    });

                    create_response(
                        StatusCode::OK,
                        CreateDiskResponse::ok(&disk).encode()
                    )
                }
            }
        } else {
            create_response(
                StatusCode::BAD_REQUEST,
                ErrorResponse::err(400, "Invalid request format".to_string()).encode()
            )
        }
    }

    pub fn delete_disk_handler(req: &HttpRequest, _params: &Params) -> HttpResponse<'static> {
        // Authenticate request
        let requester_api_key = match authenticate_request(req) {
            Some(key) => key,
            None => return create_auth_error_response(),
        };

        let is_owner = OWNER_ID.with(|owner_id| requester_api_key.user_id == *owner_id);
        if !is_owner {
            return create_auth_error_response();
        }

        // Parse request body
        let body: &[u8] = req.body();
        let delete_request = match serde_json::from_slice::<DeleteDiskRequest>(body) {
            Ok(req) => req,
            Err(_) => return create_response(
                StatusCode::BAD_REQUEST,
                ErrorResponse::err(400, "Invalid request format".to_string()).encode()
            ),
        };

        let disk_id = delete_request.id.clone();

        // Get disk for external ID cleanup
        let disk = DISKS_BY_ID_HASHTABLE.with(|store| {
            store.borrow().get(&disk_id).cloned()
        });

        // Remove from external ID mapping if it exists
        if let Some(disk) = disk {
            if let Some(external_id) = disk.external_id {
                DISKS_BY_EXTERNAL_ID_HASHTABLE.with(|store| {
                    store.borrow_mut().remove(&external_id);
                });
            }
        }

        // Remove from main stores
        DISKS_BY_ID_HASHTABLE.with(|store| {
            store.borrow_mut().remove(&disk_id);
        });

        DISKS_BY_TIME_LIST.with(|store| {
            store.borrow_mut().retain(|id| id != &disk_id);
        });

        create_response(
            StatusCode::OK,
            DeleteDiskResponse::ok(&DeletedDiskData {
                id: disk_id,
                deleted: true
            }).encode()
        )
    }

    fn json_decode<T>(value: &[u8]) -> T
    where
        T: for<'de> Deserialize<'de>,
    {
        serde_json::from_slice(value).expect("Failed to deserialize value")
    }

    fn create_response(status_code: StatusCode, body: Vec<u8>) -> HttpResponse<'static> {
        HttpResponse::builder()
            .with_status_code(status_code)
            .with_headers(vec![
                ("content-type".to_string(), "application/json".to_string()),
                (
                    "strict-transport-security".to_string(),
                    "max-age=31536000; includeSubDomains".to_string(),
                ),
                ("x-content-type-options".to_string(), "nosniff".to_string()),
                ("referrer-policy".to_string(), "no-referrer".to_string()),
                (
                    "cache-control".to_string(),
                    "no-store, max-age=0".to_string(),
                ),
                ("pragma".to_string(), "no-cache".to_string()),
            ])
            .with_body(body)
            .build()
    }
}


// src/core/state/directory/state.rs

pub mod state {
    use std::cell::{RefCell, RefMut};
    use std::collections::HashMap;
    use std::ops::Deref;

    use crate::core::state::{
        directory::types::{DriveFullFilePath, FileMetadata, FileUUID, FolderMetadata, FolderUUID},
        templates::types::{TemplateID, TemplateItem},
    };

    // Wrapper types that implement Deref
    pub struct FolderMap;
    pub struct FileMap;
    pub struct FolderPathMap;
    pub struct FilePathMap;

    impl FolderMap {
        pub fn get(&self, key: &FolderUUID) -> Option<FolderMetadata> {
            folder_uuid_to_metadata_inner.with(|map| map.borrow().get(key).cloned())
        }

        pub fn insert(&self, key: FolderUUID, value: FolderMetadata) {
            folder_uuid_to_metadata_inner.with(|map| map.borrow_mut().insert(key, value));
        }

        pub fn with_mut<R>(&self, f: impl FnOnce(&mut HashMap<FolderUUID, FolderMetadata>) -> R) -> R {
            folder_uuid_to_metadata_inner.with(|map| f(&mut map.borrow_mut()))
        }
    
        pub fn contains_key(&self, key: &FolderUUID) -> bool {
            folder_uuid_to_metadata_inner.with(|map| map.borrow().contains_key(key))
        }
    
        pub fn remove(&self, key: &FolderUUID) -> Option<FolderMetadata> {
            folder_uuid_to_metadata_inner.with(|map| map.borrow_mut().remove(key))
        }
    }

    impl FileMap {
        pub fn get(&self, key: &FileUUID) -> Option<FileMetadata> {
            file_uuid_to_metadata_inner.with(|map| map.borrow().get(key).cloned())
        }

        pub fn insert(&self, key: FileUUID, value: FileMetadata) {
            file_uuid_to_metadata_inner.with(|map| map.borrow_mut().insert(key, value));
        }

        pub fn with_mut<R>(&self, f: impl FnOnce(&mut HashMap<FileUUID, FileMetadata>) -> R) -> R {
            file_uuid_to_metadata_inner.with(|map| f(&mut map.borrow_mut()))
        }
    
        pub fn contains_key(&self, key: &FileUUID) -> bool {
            file_uuid_to_metadata_inner.with(|map| map.borrow().contains_key(key))
        }
    
        pub fn remove(&self, key: &FileUUID) -> Option<FileMetadata> {
            file_uuid_to_metadata_inner.with(|map| map.borrow_mut().remove(key))
        }
    }

    impl FolderPathMap {
        pub fn get(&self, key: &DriveFullFilePath) -> Option<FolderUUID> {
            full_folder_path_to_uuid_inner.with(|map| map.borrow().get(key).cloned())
        }

        pub fn insert(&self, key: DriveFullFilePath, value: FolderUUID) {
            full_folder_path_to_uuid_inner.with(|map| map.borrow_mut().insert(key, value));
        }

        pub fn with_mut<R>(&self, f: impl FnOnce(&mut HashMap<DriveFullFilePath, FolderUUID>) -> R) -> R {
            full_folder_path_to_uuid_inner.with(|map| f(&mut map.borrow_mut()))
        }

        pub fn contains_key(&self, key: &DriveFullFilePath) -> bool {
            full_folder_path_to_uuid_inner.with(|map| map.borrow().contains_key(key))
        }
    
        pub fn remove(&self, key: &DriveFullFilePath) -> Option<FolderUUID> {
            full_folder_path_to_uuid_inner.with(|map| map.borrow_mut().remove(key))
        }
    }

    impl FilePathMap {
        pub fn get(&self, key: &DriveFullFilePath) -> Option<FileUUID> {
            full_file_path_to_uuid_inner.with(|map| map.borrow().get(key).cloned())
        }

        pub fn insert(&self, key: DriveFullFilePath, value: FileUUID) {
            full_file_path_to_uuid_inner.with(|map| map.borrow_mut().insert(key, value));
        }

        pub fn with_mut<R>(&self, f: impl FnOnce(&mut HashMap<DriveFullFilePath, FileUUID>) -> R) -> R {
            full_file_path_to_uuid_inner.with(|map| f(&mut map.borrow_mut()))
        }
    
        pub fn contains_key(&self, key: &DriveFullFilePath) -> bool {
            full_file_path_to_uuid_inner.with(|map| map.borrow().contains_key(key))
        }
    
        pub fn remove(&self, key: &DriveFullFilePath) -> Option<FileUUID> {
            full_file_path_to_uuid_inner.with(|map| map.borrow_mut().remove(key))
        }
    }

    // Private thread_local storage
    thread_local! {
        static folder_uuid_to_metadata_inner: RefCell<HashMap<FolderUUID, FolderMetadata>> = RefCell::new(HashMap::new());
        static file_uuid_to_metadata_inner: RefCell<HashMap<FileUUID, FileMetadata>> = RefCell::new(HashMap::new());
        static full_folder_path_to_uuid_inner: RefCell<HashMap<DriveFullFilePath, FolderUUID>> = RefCell::new(HashMap::new());
        static full_file_path_to_uuid_inner: RefCell<HashMap<DriveFullFilePath, FileUUID>> = RefCell::new(HashMap::new());
    }

    // Public instances with original names
    pub static folder_uuid_to_metadata: FolderMap = FolderMap;
    pub static file_uuid_to_metadata: FileMap = FileMap;
    pub static full_folder_path_to_uuid: FolderPathMap = FolderPathMap;
    pub static full_file_path_to_uuid: FilePathMap = FilePathMap;
}



use std::fmt;

// src/core/state/directory/types.rs
use serde::{Serialize, Deserialize};

use crate::core::{state::disks::types::DiskTypeEnum, types::{ICPPrincipalString, UserID}};


#[derive(Debug, Clone, PartialEq, Eq, Hash, Serialize, Deserialize)]
pub struct FolderUUID(pub String);
impl fmt::Display for FolderUUID {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        write!(f, "{}", self.0)
    }
}

#[derive(Debug, Clone, PartialEq, Eq, Hash, Serialize, Deserialize)]
pub struct FileUUID(pub String);
impl fmt::Display for FileUUID {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        write!(f, "{}", self.0)
    }
}

#[derive(Debug, Clone, PartialEq, Eq, Hash, Serialize, Deserialize)]
pub struct DriveFullFilePath(pub String);
impl fmt::Display for DriveFullFilePath {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        write!(f, "{}", self.0)
    }
}

#[derive(Debug, Clone, PartialEq, Eq, Hash, Serialize, Deserialize)]
pub struct Tag(pub String);





#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FolderMetadata {
    pub id: FolderUUID,
    pub name: String,
    pub parent_folder_uuid: Option<FolderUUID>,
    pub subfolder_uuids: Vec<FolderUUID>,
    pub file_uuids: Vec<FileUUID>,
    pub full_folder_path: DriveFullFilePath,
    pub tags: Vec<Tag>,
    pub owner: UserID,
    pub created_date: u64, // unix ns   
    pub storage_location: DiskTypeEnum,
    pub last_changed_unix_ms: u64,
    pub deleted: bool,
    pub expires_at: i64,
    pub canister_id: ICPPrincipalString,
}


#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FileMetadata {
    pub(crate) id: FileUUID,
    pub(crate) name: String,
    pub(crate) folder_uuid: FolderUUID,
    pub(crate) file_version: u32,
    pub(crate) prior_version: Option<FileUUID>,
    pub(crate) next_version: Option<FileUUID>,
    pub(crate) extension: String,
    pub(crate) full_file_path: DriveFullFilePath,
    pub(crate) tags: Vec<Tag>,
    pub(crate) owner: UserID,
    pub(crate) created_date: u64, // unix ns
    pub(crate) storage_location: DiskTypeEnum,
    pub(crate) file_size: u64,
    pub(crate) raw_url: String,
    pub(crate) last_changed_unix_ms: u64, 
    pub(crate) deleted: bool,
    pub(crate) canister_id: ICPPrincipalString,
    pub(crate) expires_at: i64,
}


// src/core/api/internals.rs
pub mod drive_internals {
    use crate::{
        core::{api::uuid::generate_unique_id, state::{directory::{state::state::{file_uuid_to_metadata, folder_uuid_to_metadata, full_file_path_to_uuid, full_folder_path_to_uuid}, types::{DriveFullFilePath, FileUUID, FolderMetadata, FolderUUID}}, disks::types::DiskTypeEnum}, types::{ICPPrincipalString, PublicKeyBLS, UserID}}, debug_log, 
        
    };
    use regex::Regex;

    pub fn sanitize_file_path(file_path: &str) -> String {
        let mut parts = file_path.splitn(2, "::");
        let storage_part = parts.next().unwrap_or("");
        let path_part = parts.next().unwrap_or("");
    
        let sanitized = path_part.replace(':', ";");

        // Compile a regex to match one or more consecutive slashes
        let re = Regex::new(r"/+").unwrap();
        let sanitized = re.replace_all(&sanitized, "/").to_string();

        // Remove leading and trailing slashes
        let sanitized = sanitized.trim_matches('/').to_string();

        // Additional sanitization can be performed here if necessary
    
        // Reconstruct the full path
        format!("{}::{}", storage_part, sanitized)
    }

    pub fn ensure_root_folder(storage_location: &DiskTypeEnum, user_id: &UserID, canister_id: String,) -> FolderUUID {
        let root_path = DriveFullFilePath(format!("{}::", storage_location.to_string()));
        let canister_icp_principal_string = if canister_id.is_empty() {
            ic_cdk::api::id().to_text()
        } else {
            canister_id.clone()
        };
        if let Some(uuid) = full_folder_path_to_uuid.get(&root_path) {
            uuid.clone()
        } else {
            let root_folder_uuid = generate_unique_id("FolderID", "");
            let root_folder = FolderMetadata {
                id: FolderUUID(root_folder_uuid.clone()),
                name: String::new(),
                parent_folder_uuid: None,
                subfolder_uuids: Vec::new(),
                file_uuids: Vec::new(),
                full_folder_path: root_path.clone(),
                tags: Vec::new(),
                owner: user_id.clone(),
                created_date: ic_cdk::api::time(),
                storage_location: storage_location.clone(),
                last_changed_unix_ms: ic_cdk::api::time() / 1_000_000,
                deleted: false,
                canister_id: ICPPrincipalString(PublicKeyBLS(canister_icp_principal_string)),
                expires_at: -1,
            };

            full_folder_path_to_uuid.insert(root_path, FolderUUID(root_folder_uuid.clone()));
            folder_uuid_to_metadata.insert(FolderUUID(root_folder_uuid.clone()), root_folder);

            FolderUUID(root_folder_uuid)
        }
    }

    pub fn update_subfolder_paths(folder_id: &FolderUUID, old_path: &str, new_path: &str) {
        // Get folder metadata first
        let folder = match folder_uuid_to_metadata.get(folder_id) {
            Some(f) => f,
            None => return,
        };
    
        // Clone the vectors we need to iterate over to avoid borrowing issues
        let subfolder_uuids = folder.subfolder_uuids.clone();
        let file_uuids = folder.file_uuids.clone();
    
        // Update subfolders
        for subfolder_id in &subfolder_uuids {
            // Get old path before updating
            let old_subfolder_path = if let Some(subfolder) = folder_uuid_to_metadata.get(subfolder_id) {
                subfolder.full_folder_path.clone()
            } else {
                continue;
            };
    
            let new_subfolder_path = DriveFullFilePath(old_subfolder_path.to_string().replace(old_path, new_path));
            
            // Update folder metadata
            folder_uuid_to_metadata.with_mut(|map| {
                if let Some(subfolder) = map.get_mut(subfolder_id) {
                    subfolder.full_folder_path = new_subfolder_path.clone();
                }
            });
            
            // Update path mappings
            full_folder_path_to_uuid.remove(&old_subfolder_path);
            full_folder_path_to_uuid.insert(new_subfolder_path.clone(), subfolder_id.clone());
            
            // Recursively update paths for this subfolder
            update_subfolder_paths(subfolder_id, &old_subfolder_path.to_string(), &new_subfolder_path.to_string());
        }
    
        // Update file paths
        for file_id in &file_uuids {
            // Get old path before updating
            let old_file_path = if let Some(file) = file_uuid_to_metadata.get(file_id) {
                file.full_file_path.clone()
            } else {
                continue;
            };
    
            let new_file_path = DriveFullFilePath(old_file_path.to_string().replace(old_path, new_path));
            
            // Update file metadata
            file_uuid_to_metadata.with_mut(|map| {
                if let Some(file) = map.get_mut(file_id) {
                    file.full_file_path = new_file_path.clone();
                }
            });
            
            // Update path mappings
            full_file_path_to_uuid.remove(&old_file_path);
            full_file_path_to_uuid.insert(new_file_path, file_id.clone());
        }
    }

    pub fn ensure_folder_structure(
        folder_path: &str,
        storage_location: DiskTypeEnum,
        user_id: UserID,
        canister_id: String,
    ) -> FolderUUID {
        let path_parts: Vec<&str> = folder_path.split("::").collect();
        let mut current_path = format!("{}::", path_parts[0]);

        let canister_icp_principal_string = if canister_id.is_empty() {
            ic_cdk::api::id().to_text()
        } else {
            canister_id.clone()
        };

        let mut parent_uuid = ensure_root_folder(&storage_location, &user_id, canister_icp_principal_string.clone());

        for part in path_parts[1].split('/').filter(|&p| !p.is_empty()) {
            current_path = format!("{}{}/", current_path.clone(), part);
            
            if !full_folder_path_to_uuid.contains_key(&DriveFullFilePath(current_path.clone())) {
                let new_folder_uuid = FolderUUID(generate_unique_id("FolderID",""));
                let new_folder = FolderMetadata {
                    id: new_folder_uuid.clone(),
                    name: part.to_string(),
                    parent_folder_uuid: Some(parent_uuid.clone()),
                    subfolder_uuids: Vec::new(),
                    file_uuids: Vec::new(),
                    full_folder_path: DriveFullFilePath(current_path.clone()),
                    tags: Vec::new(),
                    owner: user_id.clone(),
                    created_date: ic_cdk::api::time(),
                    storage_location: storage_location.clone(),
                    last_changed_unix_ms: ic_cdk::api::time() / 1_000_000,
                    deleted: false,
                    canister_id: ICPPrincipalString(PublicKeyBLS(canister_icp_principal_string.clone())),
                    expires_at: -1,
                };

                full_folder_path_to_uuid.insert(DriveFullFilePath(current_path.clone()), new_folder_uuid.clone());
                folder_uuid_to_metadata.insert(new_folder_uuid.clone(), new_folder);

                // Update parent folder's subfolder_uuids
                folder_uuid_to_metadata.with_mut(|map| {
                    if let Some(parent_folder) = map.get_mut(&parent_uuid) {
                        if !parent_folder.subfolder_uuids.contains(&new_folder_uuid) {
                            parent_folder.subfolder_uuids.push(new_folder_uuid.clone());
                        }
                    }
                });

                parent_uuid = new_folder_uuid;
            } else {
                parent_uuid = full_folder_path_to_uuid.get(&DriveFullFilePath(current_path.clone()))
                    .expect("Folder UUID not found")
                    .clone();
            }
        }

        parent_uuid
    }

    pub fn split_path(full_path: &str) -> (String, String) {
        let parts: Vec<&str> = full_path.rsplitn(2, '/').collect();
        match parts.as_slice() {
            [file_name, folder_path] => (folder_path.to_string(), file_name.to_string()),
            [single_part] => {
                let storage_parts: Vec<&str> = single_part.splitn(2, "::").collect();
                match storage_parts.as_slice() {
                    [storage, file_name] => (format!("{}::", storage), file_name.to_string()),
                    _ => (String::new(), single_part.to_string()),
                }
            },
            _ => (String::new(), String::new()),
        }
    }

    pub fn update_folder_file_uuids(folder_uuid: &FolderUUID, file_uuid: &FileUUID, is_add: bool) {
        folder_uuid_to_metadata.with_mut(|map| {
            if let Some(folder) = map.get_mut(folder_uuid) {
                if is_add {
                    if !folder.file_uuids.contains(file_uuid) {
                        folder.file_uuids.push(file_uuid.clone());
                    }
                } else {
                    folder.file_uuids.retain(|uuid| uuid != file_uuid);
                }
            }
        });
    }
}