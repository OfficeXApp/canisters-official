// OfficeX filesharing app (clone of google drive)
// where possible, show the code changes as green diffs without the +/- symbols

// src/core/api/actions.rs
use std::result::Result;

use crate::{core::state::directory::{state::state::{file_uuid_to_metadata, folder_uuid_to_metadata}, types::{FileUUID, FolderUUID}}, rest::directory::types::{DeleteFileResponse, DeleteFolderResponse, DirectoryAction, DirectoryActionEnum, DirectoryActionPayload, DirectoryActionResult}};

use super::{drive::drive::{delete_file, delete_folder, get_file_by_id, get_folder_by_id, rename_file, rename_folder}, internals::drive_internals::translate_path_to_id};


#[derive(Debug, Clone)]
pub struct DirectoryActionErrorInfo {
    pub code: i32,
    pub message: String,
}

pub fn pipe_action(action: DirectoryAction) -> Result<DirectoryActionResult, DirectoryActionErrorInfo> {
    match action.action {
        DirectoryActionEnum::GetFile => {
            match action.payload {
                DirectoryActionPayload::GetFile(_) => {
                    // First try resource_id
                    if let Some(id) = action.target.resource_id {
                        match get_file_by_id(FileUUID(id)) {
                            Ok(file) => Ok(DirectoryActionResult::GetFile(file)),
                            Err(e) => Err(DirectoryActionErrorInfo {
                                code: 404,
                                message: format!("File not found by ID: {}", e)
                            })
                        }
                    }
                    // Then try resource_path
                    else if let Some(path) = action.target.resource_path {
                        let translation = translate_path_to_id(path);
                        match translation.file {
                            Some(file) => Ok(DirectoryActionResult::GetFile(file)),
                            None => Err(DirectoryActionErrorInfo {
                                code: 404,
                                message: "File not found at specified path".to_string()
                            })
                        }
                    } else {
                        Err(DirectoryActionErrorInfo {
                            code: 400,
                            message: "Neither resource_id nor resource_path provided".to_string()
                        })
                    }
                }
                _ => Err(DirectoryActionErrorInfo {
                    code: 400,
                    message: "Invalid payload for GET_FILE action".to_string()
                })
            }
        }
        
        DirectoryActionEnum::GetFolder => {
            match action.payload {
                DirectoryActionPayload::GetFolder(_) => {
                    // First try resource_id
                    if let Some(id) = action.target.resource_id {
                        match get_folder_by_id(FolderUUID(id)) {
                            Ok(folder) => Ok(DirectoryActionResult::GetFolder(folder)),
                            Err(e) => Err(DirectoryActionErrorInfo {
                                code: 404,
                                message: format!("Folder not found by ID: {}", e)
                            })
                        }
                    }
                    // Then try resource_path
                    else if let Some(path) = action.target.resource_path {
                        let translation = translate_path_to_id(path);
                        match translation.folder {
                            Some(folder) => Ok(DirectoryActionResult::GetFolder(folder)),
                            None => Err(DirectoryActionErrorInfo {
                                code: 404,
                                message: "Folder not found at specified path".to_string()
                            })
                        }
                    } else {
                        Err(DirectoryActionErrorInfo {
                            code: 400,
                            message: "Neither resource_id nor resource_path provided".to_string()
                        })
                    }
                }
                _ => Err(DirectoryActionErrorInfo {
                    code: 400,
                    message: "Invalid payload for GET_FOLDER action".to_string()
                })
            }
        }
        
        DirectoryActionEnum::CreateFile => {
            match action.payload {
                DirectoryActionPayload::CreateFile(payload) => {
                    // Implementation for creating file
                    todo!("Implement create file")
                }
                _ => Err(DirectoryActionErrorInfo {
                    code: 500,
                    message: "Invalid payload for CREATE_FILE action".to_string()
                })
            }
        }
        
        DirectoryActionEnum::CreateFolder => {
            match action.payload {
                DirectoryActionPayload::CreateFolder(payload) => {
                    // Implementation for creating folder
                    todo!("Implement create folder")
                }
                _ => Err(DirectoryActionErrorInfo {
                    code: 500,
                    message: "Invalid payload for CREATE_FOLDER action".to_string()
                })
            }
        }
        
        DirectoryActionEnum::UpdateFile => {
            match action.payload {
                DirectoryActionPayload::UpdateFile(payload) => {
                    // Get the file ID from either resource_id or resource_path
                    let file_id = if let Some(id) = action.target.resource_id {
                        FileUUID(id)
                    } else if let Some(path) = action.target.resource_path {
                        let translation = translate_path_to_id(path);
                        match translation.file {
                            Some(file) => file.id,
                            None => return Err(DirectoryActionErrorInfo {
                                code: 404,
                                message: "File not found at specified path".to_string()
                            })
                        }
                    } else {
                        return Err(DirectoryActionErrorInfo {
                            code: 400,
                            message: "Neither resource_id nor resource_path provided".to_string()
                        });
                    };
        
                    // Get current file metadata
                    let file = match get_file_by_id(file_id.clone()) {
                        Ok(f) => f,
                        Err(e) => return Err(DirectoryActionErrorInfo {
                            code: 404,
                            message: format!("File not found: {}", e)
                        })
                    };
        
                    // Handle name update separately since it requires path updates
                    if let Some(new_name) = payload.name {
                        if new_name != file.name {
                            match rename_file(file_id.clone(), new_name) {
                                Ok(_) => (),
                                Err(e) => return Err(DirectoryActionErrorInfo {
                                    code: 500,
                                    message: format!("Failed to rename file: {}", e)
                                })
                            }
                        }
                    }
        
                    // Update other metadata fields directly
                    file_uuid_to_metadata.with_mut(|map| {
                        if let Some(file) = map.get_mut(&file_id) {
                            if let Some(tags) = payload.tags {
                                file.tags = tags;
                            }
                            if let Some(raw_url) = payload.raw_url {
                                file.raw_url = raw_url;
                            }
                            if let Some(expires_at) = payload.expires_at {
                                file.expires_at = expires_at;
                            }
                            file.last_changed_unix_ms = ic_cdk::api::time() / 1_000_000;
                        }
                    });
        
                    // Get updated metadata to return
                    match get_file_by_id(file_id) {
                        Ok(updated_file) => Ok(DirectoryActionResult::UpdateFile(updated_file)),
                        Err(e) => Err(DirectoryActionErrorInfo {
                            code: 500,
                            message: format!("Failed to get updated file metadata: {}", e)
                        })
                    }
                }
                _ => Err(DirectoryActionErrorInfo {
                    code: 400,
                    message: "Invalid payload for UPDATE_FILE action".to_string()
                })
            }
        }
        
        DirectoryActionEnum::UpdateFolder => {
            match action.payload {
                DirectoryActionPayload::UpdateFolder(payload) => {
                    // Get the folder ID from either resource_id or resource_path
                    let folder_id = if let Some(id) = action.target.resource_id {
                        FolderUUID(id)
                    } else if let Some(path) = action.target.resource_path {
                        let translation = translate_path_to_id(path);
                        match translation.folder {
                            Some(folder) => folder.id,
                            None => return Err(DirectoryActionErrorInfo {
                                code: 404,
                                message: "Folder not found at specified path".to_string()
                            })
                        }
                    } else {
                        return Err(DirectoryActionErrorInfo {
                            code: 400,
                            message: "Neither resource_id nor resource_path provided".to_string()
                        });
                    };
        
                    // Get current folder metadata
                    let folder = match get_folder_by_id(folder_id.clone()) {
                        Ok(f) => f,
                        Err(e) => return Err(DirectoryActionErrorInfo {
                            code: 404,
                            message: format!("Folder not found: {}", e)
                        })
                    };
        
                    // Handle name update separately since it requires path updates
                    if let Some(new_name) = payload.name {
                        if new_name != folder.name {
                            match rename_folder(folder_id.clone(), new_name) {
                                Ok(_) => (),
                                Err(e) => return Err(DirectoryActionErrorInfo {
                                    code: 500,
                                    message: format!("Failed to rename folder: {}", e)
                                })
                            }
                        }
                    }
        
                    // Update other metadata fields directly
                    folder_uuid_to_metadata.with_mut(|map| {
                        if let Some(folder) = map.get_mut(&folder_id) {
                            if let Some(tags) = payload.tags {
                                folder.tags = tags;
                            }
                            if let Some(expires_at) = payload.expires_at {
                                folder.expires_at = expires_at;
                            }
                            folder.last_changed_unix_ms = ic_cdk::api::time() / 1_000_000;
                        }
                    });
        
                    // Get updated metadata to return
                    match get_folder_by_id(folder_id) {
                        Ok(updated_folder) => Ok(DirectoryActionResult::UpdateFolder(updated_folder)),
                        Err(e) => Err(DirectoryActionErrorInfo {
                            code: 500,
                            message: format!("Failed to get updated folder metadata: {}", e)
                        })
                    }
                }
                _ => Err(DirectoryActionErrorInfo {
                    code: 400,
                    message: "Invalid payload for UPDATE_FOLDER action".to_string()
                })
            }
        }
        
        DirectoryActionEnum::DeleteFile => {
            match action.payload {
                DirectoryActionPayload::DeleteFile(payload) => {
                    // Get the file first to ensure it exists and get its metadata
                    let file_id = if let Some(id) = action.target.resource_id {
                        FileUUID(id)
                    } else if let Some(path) = action.target.resource_path {
                        let translation = translate_path_to_id(path);
                        match translation.file {
                            Some(file) => file.id,
                            None => return Err(DirectoryActionErrorInfo {
                                code: 404,
                                message: "File not found at specified path".to_string()
                            })
                        }
                    } else {
                        return Err(DirectoryActionErrorInfo {
                            code: 400,
                            message: "Neither resource_id nor resource_path provided".to_string()
                        });
                    };

                    // Get file metadata before deletion
                    let file = match get_file_by_id(file_id.clone()) {
                        Ok(f) => f,
                        Err(e) => return Err(DirectoryActionErrorInfo {
                            code: 404,
                            message: format!("File not found: {}", e)
                        })
                    };

                    // Perform deletion
                    match delete_file(&file_id) {
                        Ok(_) => Ok(DirectoryActionResult::DeleteFile(DeleteFileResponse {
                            file_id,
                            full_path: file.full_file_path
                        })),
                        Err(e) => Err(DirectoryActionErrorInfo {
                            code: 500,
                            message: format!("Failed to delete file: {}", e)
                        })
                    }
                }
                _ => Err(DirectoryActionErrorInfo {
                    code: 400,
                    message: "Invalid payload for DELETE_FILE action".to_string()
                })
            }
        }
        
        DirectoryActionEnum::DeleteFolder => {
            match action.payload {
                DirectoryActionPayload::DeleteFolder(payload) => {
                    // Get the folder first to ensure it exists and get its metadata
                    let folder_id = if let Some(id) = action.target.resource_id {
                        FolderUUID(id)
                    } else if let Some(path) = action.target.resource_path {
                        let translation = translate_path_to_id(path);
                        match translation.folder {
                            Some(folder) => folder.id,
                            None => return Err(DirectoryActionErrorInfo {
                                code: 404,
                                message: "Folder not found at specified path".to_string()
                            })
                        }
                    } else {
                        return Err(DirectoryActionErrorInfo {
                            code: 400,
                            message: "Neither resource_id nor resource_path provided".to_string()
                        });
                    };

                    // Get folder metadata before deletion
                    let folder = match get_folder_by_id(folder_id.clone()) {
                        Ok(f) => f,
                        Err(e) => return Err(DirectoryActionErrorInfo {
                            code: 404,
                            message: format!("Folder not found: {}", e)
                        })
                    };

                    // Initialize vectors to collect deleted items
                    let mut deleted_files = Vec::with_capacity(2000);
                    let mut deleted_folders = Vec::with_capacity(2000);

                    // Perform deletion with collection vectors
                    match delete_folder(&folder_id, &mut deleted_folders, &mut deleted_files) {
                        Ok(()) => Ok(DirectoryActionResult::DeleteFolder(DeleteFolderResponse {
                            folder_id,
                            full_path: folder.full_folder_path,
                            deleted_files: Some(deleted_files),
                            deleted_folders: Some(deleted_folders),
                        })),
                        Err(e) => Err(DirectoryActionErrorInfo {
                            code: 500,
                            message: format!("Failed to delete folder: {}", e)
                        })
                    }
                }
                _ => Err(DirectoryActionErrorInfo {
                    code: 400,
                    message: "Invalid payload for DELETE_FOLDER action".to_string()
                })
            }
        }
        
        DirectoryActionEnum::CopyFile => {
            match action.payload {
                DirectoryActionPayload::CopyFile(payload) => {
                    // Implementation for copying file
                    todo!("Implement copy file")
                }
                _ => Err(DirectoryActionErrorInfo {
                    code: 500,
                    message: "Invalid payload for COPY_FILE action".to_string()
                })
            }
        }
        
        DirectoryActionEnum::CopyFolder => {
            match action.payload {
                DirectoryActionPayload::CopyFolder(payload) => {
                    // Implementation for copying folder
                    todo!("Implement copy folder")
                }
                _ => Err(DirectoryActionErrorInfo {
                    code: 500,
                    message: "Invalid payload for COPY_FOLDER action".to_string()
                })
            }
        }
        
        DirectoryActionEnum::MoveFile => {
            match action.payload {
                DirectoryActionPayload::MoveFile(payload) => {
                    // Implementation for moving file
                    todo!("Implement move file")
                }
                _ => Err(DirectoryActionErrorInfo {
                    code: 500,
                    message: "Invalid payload for MOVE_FILE action".to_string()
                })
            }
        }
        
        DirectoryActionEnum::MoveFolder => {
            match action.payload {
                DirectoryActionPayload::MoveFolder(payload) => {
                    // Implementation for moving folder
                    todo!("Implement move folder")
                }
                _ => Err(DirectoryActionErrorInfo {
                    code: 500,
                    message: "Invalid payload for MOVE_FOLDER action".to_string()
                })
            }
        }
    }
}

// src/core/api/drive.rs
pub mod drive {
    use crate::{
        core::{
            api::{
                internals::drive_internals::{ensure_folder_structure, ensure_root_folder, format_file_asset_path, sanitize_file_path, split_path, update_folder_file_uuids, update_subfolder_paths},
                types::DirectoryError,
                uuid::generate_unique_id
            },
            state::{
                directory::{
                    state::state::{file_uuid_to_metadata, folder_uuid_to_metadata, full_file_path_to_uuid, full_folder_path_to_uuid},
                    types::{DriveFullFilePath, FileMetadata, FileUUID, FolderMetadata, FolderUUID}
                },
                disks::types::{DiskID, DiskTypeEnum},
            }, types::{ICPPrincipalString, PublicKeyBLS, UserID},
        }, rest::{directory::types::{DirectoryListResponse, ListDirectoryRequest}, webhooks::types::SortDirection}
    };

    pub fn fetch_files_at_folder_path(config: ListDirectoryRequest) -> Result<DirectoryListResponse, DirectoryError> {
        let ListDirectoryRequest { 
            folder_id, 
            path, 
            filters: _, 
            page_size, 
            direction, 
            cursor 
        } = config;
    
        // Get the folder UUID either from folder_id or path
        let folder_uuid = if let Some(id) = folder_id {
            FolderUUID(id)
        } else if let Some(path_str) = path {
            full_folder_path_to_uuid
                .get(&DriveFullFilePath(path_str.clone()))
                .ok_or_else(|| DirectoryError::FolderNotFound(format!("Path not found: {}", path_str)))?
        } else {
            return Err(DirectoryError::FolderNotFound("Neither folder_id nor path provided".to_string()));
        };
    
        // Get folder metadata
        let folder = folder_uuid_to_metadata
            .get(&folder_uuid)
            .ok_or_else(|| DirectoryError::FolderNotFound("Folder metadata not found".to_string()))?;
    
        let total_folders = folder.subfolder_uuids.len();
        let total_files = folder.file_uuids.len();
        let total_items = total_folders + total_files;
    
        // Parse cursor to get starting position
        let start_pos = cursor
            .and_then(|c| c.parse::<usize>().ok())
            .unwrap_or(0);
    
        // Determine range based on direction and cursor
        let range_start = match direction {
            SortDirection::Asc => start_pos,
            SortDirection::Desc => start_pos.saturating_sub(page_size)
        };
    
        let mut folders = Vec::new();
        let mut files = Vec::new();
        let mut count = 0;
        let mut current_pos = range_start;
        
        // Fill results while tracking count
        while count < page_size && current_pos < total_items {
            if current_pos < total_folders {
                // Add folder
                if let Some(subfolder) = folder_uuid_to_metadata.get(&folder.subfolder_uuids[current_pos]) {
                    folders.push(subfolder);
                    count += 1;
                }
            } else {
                // Add file
                let file_index = current_pos - total_folders;
                if let Some(file) = file_uuid_to_metadata.get(&folder.file_uuids[file_index]) {
                    files.push(file);
                    count += 1;
                }
            }
            current_pos += 1;
        }
    
        // Generate next cursor if there are more items
        let next_cursor = if current_pos < total_items {
            Some(current_pos.to_string())
        } else {
            None
        };
    
        Ok(DirectoryListResponse {
            folders,
            files,
            total_folders,
            total_files,
            cursor: next_cursor,
        })
    }

    pub fn create_file(
        file_path: String,
        disk_id: DiskID,
        user_id: UserID,
        expires_at: i64,
        canister_id: String,
    ) -> Result<FileMetadata, String> {
        let sanitized_file_path = sanitize_file_path(&file_path);
        let full_file_path = sanitized_file_path;
        let new_file_uuid = FileUUID(generate_unique_id("FileID", ""));

        let canister_icp_principal_string = if canister_id.is_empty() {
            ic_cdk::api::id().to_text()
        } else {
            canister_id.clone()
        };

        let (folder_path, file_name) = split_path(&full_file_path);
        let folder_uuid = ensure_folder_structure(&folder_path, disk_id.clone(), user_id.clone(), canister_icp_principal_string.clone());

        let existing_file_uuid = full_file_path_to_uuid.get(&DriveFullFilePath(full_file_path.clone())).map(|uuid| uuid.clone());

        let file_version = if let Some(existing_uuid) = &existing_file_uuid {
            let existing_file = file_uuid_to_metadata.get(existing_uuid).unwrap();
            existing_file.file_version + 1
        } else {
            1
        };

        let extension = file_name.rsplit('.').next().unwrap_or("").to_string();

        let file_metadata = FileMetadata {
            id: new_file_uuid.clone(),
            name: file_name,
            folder_uuid: folder_uuid.clone(),
            file_version,
            prior_version: existing_file_uuid.clone(),
            next_version: None,
            extension: extension.clone(),
            full_file_path: DriveFullFilePath(full_file_path.clone()),
            tags: Vec::new(),
            owner: user_id,
            created_date: ic_cdk::api::time(),
            disk_id,
            file_size: 0,
            raw_url: format_file_asset_path(new_file_uuid.clone(), extension),
            last_changed_unix_ms: ic_cdk::api::time() / 1_000_000,
            deleted: false,
            canister_id: ICPPrincipalString(PublicKeyBLS(canister_icp_principal_string.clone())),
            expires_at,
        };

        // Update hashtables
        file_uuid_to_metadata.insert(new_file_uuid.clone(), file_metadata.clone());
        full_file_path_to_uuid.insert(DriveFullFilePath(full_file_path), new_file_uuid.clone());

        // Update parent folder's file_uuids
        update_folder_file_uuids(&folder_uuid, &new_file_uuid, true);

        // Update prior version if it exists
        if let Some(existing_uuid) = existing_file_uuid {
            file_uuid_to_metadata.with_mut(|map| {
                if let Some(existing_file) = map.get_mut(&existing_uuid) {
                    existing_file.next_version = Some(new_file_uuid.clone());
                }
            });
            // Remove the old file UUID from the parent folder
            update_folder_file_uuids(&folder_uuid, &existing_uuid, false);
        }

        Ok(file_metadata)
    }

    pub fn create_folder(
        full_folder_path: DriveFullFilePath,
        disk_id: DiskID,
        user_id: UserID,
        expires_at: i64,
        canister_id: String,
    ) -> Result<FolderMetadata, String> {
        // Ensure the path ends with a slash
        let mut sanitized_path = sanitize_file_path(&full_folder_path.to_string());
        if !sanitized_path.ends_with('/') {
            sanitized_path.push('/');
        }
    
        if sanitized_path.is_empty() {
            return Err(String::from("Invalid folder path"));
        }
    
        // Split the path into storage and folder parts
        let parts: Vec<&str> = sanitized_path.split("::").collect();
        if parts.len() < 2 {
            return Err(String::from("Invalid folder path format"));
        }
    
        let storage_part = parts[0];
        let folder_path = parts[1..].join("::");
    
        // Ensure the storage location matches
        if storage_part != disk_id.to_string() {
            return Err(String::from("Storage location mismatch"));
        }
    
        // Split the folder path into individual parts
        let path_parts: Vec<&str> = folder_path.split('/').filter(|&x| !x.is_empty()).collect();

        let canister_icp_principal_string = if canister_id.is_empty() {
            ic_cdk::api::id().to_text()
        } else {
            canister_id.clone()
        };
    
        let mut current_path = format!("{}::", storage_part);
        let mut parent_folder_uuid = ensure_root_folder(&disk_id, &user_id, canister_icp_principal_string.clone());

        // root folder case
        if path_parts.is_empty() {
            return folder_uuid_to_metadata
                .get(&parent_folder_uuid)
                .map(|metadata| metadata.clone())
                .ok_or_else(|| "Parent folder not found".to_string());
        }
    
        // Iterate through path parts and create folders as needed
        for (i, part) in path_parts.iter().enumerate() {
            current_path.push_str(part);
            current_path.push('/');
    
            if !full_folder_path_to_uuid.contains_key(&DriveFullFilePath(current_path.clone())) {
                let new_folder_uuid = FolderUUID(generate_unique_id("FolderUUID", ""));
                let new_folder = FolderMetadata {
                    id: new_folder_uuid.clone(),
                    name: part.to_string(),
                    parent_folder_uuid: Some(parent_folder_uuid.clone()),
                    subfolder_uuids: Vec::new(),
                    file_uuids: Vec::new(),
                    full_folder_path: DriveFullFilePath(current_path.clone()),
                    tags: Vec::new(),
                    owner: user_id.clone(),
                    created_date: ic_cdk::api::time(),
                    disk_id: disk_id.clone(),
                    last_changed_unix_ms: ic_cdk::api::time() / 1_000_000,
                    deleted: false,
                    canister_id: ICPPrincipalString(PublicKeyBLS(canister_icp_principal_string.clone())),
                    expires_at,
                };
    
                full_folder_path_to_uuid.insert(DriveFullFilePath(current_path.clone()), new_folder_uuid.clone());
                folder_uuid_to_metadata.insert(new_folder_uuid.clone(), new_folder.clone());
    
                // Update parent folder
                folder_uuid_to_metadata.with_mut(|map| {
                    if let Some(parent_folder) = map.get_mut(&parent_folder_uuid) {
                        parent_folder.subfolder_uuids.push(new_folder_uuid.clone());
                    }
                });
    
                parent_folder_uuid = new_folder_uuid;
    
                // If this is the last part, return the created folder
                if i == path_parts.len() - 1 {
                    return Ok(new_folder);
                }
            } else {
                parent_folder_uuid = full_folder_path_to_uuid
                    .get(&DriveFullFilePath(current_path.clone()))
                    .expect("Failed to get parent folder UUID from path");
            }
        }
    
        // If we've reached here, it means the folder already existed
        Err(String::from("Folder already exists"))
    }

    pub fn get_file_by_id(file_id: FileUUID) -> Result<FileMetadata, String> {
        file_uuid_to_metadata
            .get(&file_id)
            .map(|metadata| metadata.clone())
            .ok_or_else(|| "File not found".to_string())
    }

    pub fn get_folder_by_id(folder_id: FolderUUID) -> Result<FolderMetadata, String> {
        folder_uuid_to_metadata
            .get(&folder_id)
            .map(|metadata| metadata.clone())
            .ok_or_else(|| "Folder not found".to_string())
    }

    pub fn rename_folder(folder_id: FolderUUID, new_name: String) -> Result<FolderUUID, String> {
        // Get current folder metadata
        let folder = folder_uuid_to_metadata
            .get(&folder_id)
            .ok_or_else(|| "Folder not found".to_string())?;
        
        let old_path = folder.full_folder_path.clone();
        ic_cdk::println!("Old folder path: {}", old_path);
    
        // Create owned String before splitting
        let path_string = old_path.to_string();
        
        // Split the path into storage and folder parts
        let parts: Vec<&str> = path_string.splitn(2, "::").collect();
        if parts.len() != 2 {
            return Err("Invalid folder structure".to_string());
        }
    
        let storage_part = parts[0].to_string();
        let folder_path = parts[1].trim_end_matches('/').to_string();
    
        // Perform path manipulation
        let path_parts: Vec<&str> = folder_path.rsplitn(2, '/').collect();
        let (parent_path, _current_folder_name) = match path_parts.len() {
            2 => (path_parts[1].to_string(), path_parts[0].to_string()),
            1 => (String::new(), path_parts[0].to_string()),
            _ => return Err("Invalid folder structure".to_string()),
        };
    
        // Construct the new folder path
        let new_folder_path = if parent_path.is_empty() {
            format!("{}::{}{}", storage_part, new_name, "/")
        } else {
            format!("{}::{}/{}{}", storage_part, parent_path, new_name, "/")
        };
    
        // Check if a folder with the new path already exists
        if full_folder_path_to_uuid.contains_key(&DriveFullFilePath(new_folder_path.clone())) {
            return Err("A folder with the new name already exists in the parent directory".to_string());
        }
    
        // Update folder metadata using with_mut
        folder_uuid_to_metadata.with_mut(|map| {
            if let Some(folder) = map.get_mut(&folder_id) {
                folder.name = new_name;
                folder.full_folder_path = DriveFullFilePath(new_folder_path.clone());
                folder.last_changed_unix_ms = ic_cdk::api::time() / 1_000_000;
            }
        });
    
        // Update path mappings
        ic_cdk::println!("Removing old path from full_folder_path_to_uuid: {}", old_path);
        full_folder_path_to_uuid.remove(&old_path);
    
        ic_cdk::println!("Inserting new path into full_folder_path_to_uuid: {}", new_folder_path);
        full_folder_path_to_uuid.insert(DriveFullFilePath(new_folder_path.clone()), folder_id.clone());
    
        // Update subfolder paths recursively
        update_subfolder_paths(&folder_id, &old_path.to_string(), &new_folder_path);
    
        // Update parent folder reference if needed
        if !parent_path.is_empty() {
            let parent_full_path = format!("{}::{}", storage_part, parent_path);
            if let Some(parent_uuid) = full_folder_path_to_uuid.get(&DriveFullFilePath(parent_full_path.clone())) {
                folder_uuid_to_metadata.with_mut(|map| {
                    if let Some(parent_folder) = map.get_mut(&parent_uuid) {
                        if !parent_folder.subfolder_uuids.contains(&folder_id) {
                            parent_folder.subfolder_uuids.push(folder_id.clone());
                            ic_cdk::println!("Added folder UUID to parent folder's subfolder_uuids");
                        }
                    }
                });
            } else {
                ic_cdk::println!("Parent folder not found for path: {}", parent_full_path);
                return Err("Parent folder not found".to_string());
            }
        }
    
        ic_cdk::println!("Folder renamed successfully");
        Ok(folder_id)
    }
    
    pub fn rename_file(file_id: FileUUID, new_name: String) -> Result<FileUUID, String> {
        ic_cdk::println!(
            "Attempting to rename file. File ID: {}, New Name: {}",
            file_id,
            new_name
        );
    
        // Get current file metadata
        let file = file_uuid_to_metadata
            .get(&file_id)
            .ok_or_else(|| "File not found".to_string())?;
        
        let old_path = file.full_file_path.clone();
        ic_cdk::println!("Old file path: {}", old_path);
    
        // Create owned String before splitting
        let path_string = old_path.to_string();
        
        // Split the path into storage part and the rest
        let parts: Vec<&str> = path_string.splitn(2, "::").collect();
        if parts.len() != 2 {
            return Err("Invalid file structure".to_string());
        }
    
        let storage_part = parts[0].to_string();
        let file_path = parts[1].to_string();
    
        // Split the file path and replace the last part (file name)
        let path_parts: Vec<&str> = file_path.rsplitn(2, '/').collect();
        let new_path = if path_parts.len() > 1 {
            format!("{}::{}/{}", storage_part, path_parts[1], new_name)
        } else {
            format!("{}::{}", storage_part, new_name)
        };
    
        ic_cdk::println!("New file path: {}", new_path);
    
        // Check if a file with the new name already exists
        if full_file_path_to_uuid.contains_key(&DriveFullFilePath(new_path.clone())) {
            ic_cdk::println!("Error: A file with this name already exists");
            return Err("A file with this name already exists".to_string());
        }
    
        // Update file metadata
        file_uuid_to_metadata.with_mut(|map| {
            if let Some(file) = map.get_mut(&file_id) {
                file.name = new_name.clone();
                file.full_file_path = DriveFullFilePath(new_path.clone());
                file.last_changed_unix_ms = ic_cdk::api::time() / 1_000_000;
                file.extension = new_name
                    .rsplit('.')
                    .next()
                    .unwrap_or("")
                    .to_string();
                ic_cdk::println!("Updated file metadata: {:?}", file);
            }
        });
    
        // Update path mappings
        ic_cdk::println!(
            "Removing old path from full_file_path_to_uuid: {}",
            old_path
        );
        full_file_path_to_uuid.remove(&old_path);
    
        ic_cdk::println!(
            "Inserting new path into full_file_path_to_uuid: {}",
            new_path
        );
        full_file_path_to_uuid.insert(DriveFullFilePath(new_path), file_id.clone());
    
        ic_cdk::println!("File renamed successfully");
        Ok(file_id)
    }

    pub fn delete_folder(
        folder_id: &FolderUUID,
        all_deleted_folders: &mut Vec<FolderUUID>,
        all_deleted_files: &mut Vec<FileUUID>,
    ) -> Result<(), String> {
        ic_cdk::println!("Attempting to delete folder. Folder ID: {}", folder_id);
        
        // Get folder data before modifications
        let folder = folder_uuid_to_metadata
            .get(folder_id)
            .ok_or_else(|| {
                ic_cdk::println!("Error: Folder not found. Folder ID: {}", folder_id);
                "Folder not found".to_string()
            })?;
    
        let folder_path = folder.full_folder_path.clone();
        let subfolder_ids = folder.subfolder_uuids.clone();
        let file_ids = folder.file_uuids.clone();
        
        ic_cdk::println!("Folder found. Full path: {}", folder_path);

        // Add this folder's files to the deleted files list, respecting the limit
        for file_id in file_ids.clone() {
            if all_deleted_files.len() >= 2000 {
                break;
            }
            ic_cdk::println!("Deleting file: {}", file_id);
            if let Ok(()) = delete_file(&file_id) {
                all_deleted_files.push(file_id);
            }
        }

        // First delete files in the current folder
        ic_cdk::println!("Deleting files in the folder");
        for file_id in file_ids {
            ic_cdk::println!("Deleting file: {}", file_id);
            if let Err(e) = delete_file(&file_id) {
                ic_cdk::println!("Error deleting file {}: {}", file_id, e);
                return Err(format!("Failed to delete file {}: {}", file_id, e));
            }
            
            // Only add to deleted files list after successful deletion
            if all_deleted_files.len() < 2000 {
                all_deleted_files.push(file_id);
            }
        }
    
        // Recursively delete subfolders, passing the same vectors
        for subfolder_id in subfolder_ids {
            if let Err(e) = delete_folder(&subfolder_id, all_deleted_folders, all_deleted_files) {
                ic_cdk::println!("Error deleting subfolder {}: {}", subfolder_id, e);
            }
        }
    
    
        // Mark the folder as deleted
        folder_uuid_to_metadata.with_mut(|map| {
            if let Some(folder) = map.get_mut(folder_id) {
                folder.last_changed_unix_ms = ic_cdk::api::time() / 1_000_000;
                folder.deleted = true;
            }
        });
        
        // Remove folder path mapping
        ic_cdk::println!("Removing folder path from full_folder_path_to_uuid");
        full_folder_path_to_uuid.remove(&folder_path);

        // Add to deleted folders list after successful deletion
        if all_deleted_folders.len() < 2000 {
            all_deleted_folders.push(folder_id.clone());
        }
    
        ic_cdk::println!("Folder deleted successfully");
        Ok(())
    }
    
    pub fn delete_file(file_id: &FileUUID) -> Result<(), String> {
        ic_cdk::println!("Attempting to delete file. File ID: {}", file_id);
        
        // Get file data before modifications
        let file = file_uuid_to_metadata
            .get(file_id)
            .ok_or_else(|| {
                ic_cdk::println!("Error: File not found. File ID: {}", file_id);
                "File not found".to_string()
            })?;
    
        let file_path = file.full_file_path.clone();
        // Use ref in pattern matching to avoid moving the values
        let ref prior_version = file.prior_version;
        let ref next_version = file.next_version;
        
        ic_cdk::println!("File found. Full path: {}", file_path);
        
        // Remove file path mapping
        ic_cdk::println!("Removing file path from full_file_path_to_uuid");
        full_file_path_to_uuid.remove(&file_path);
    
        // Handle versioning
        if let Some(ref prior_id) = prior_version {
            ic_cdk::println!("Updating prior version. Prior version ID: {}", prior_id);
            file_uuid_to_metadata.with_mut(|map| {
                if let Some(prior_file) = map.get_mut(&prior_id) {
                    prior_file.next_version = next_version.clone();
                    ic_cdk::println!("Updated prior file's next_version: {:?}", prior_file.next_version);
                }
            });
        }
    
        if let Some(ref next_id) = next_version {
            ic_cdk::println!("Updating next version. Next version ID: {}", next_id);
            file_uuid_to_metadata.with_mut(|map| {
                if let Some(next_file) = map.get_mut(next_id) {
                    next_file.prior_version = prior_version.clone();
                    ic_cdk::println!("Updated next file's prior_version: {:?}", next_file.prior_version);
                }
            });
        }
    
        // Remove file metadata
        file_uuid_to_metadata.remove(file_id);
    
        ic_cdk::println!("File deleted successfully");
        Ok(())
    }


}

// src/core/api/internals.rs
pub mod drive_internals {
    use crate::{
        core::{api::uuid::generate_unique_id, state::{directory::{state::state::{file_uuid_to_metadata, folder_uuid_to_metadata, full_file_path_to_uuid, full_folder_path_to_uuid}, types::{DriveFullFilePath, FileUUID, FolderMetadata, FolderUUID, PathTranslationResponse}}, disks::types::{DiskID, DiskTypeEnum}}, types::{ICPPrincipalString, PublicKeyBLS, UserID}}, debug_log, 
        
    };
    
    use regex::Regex;

    pub fn sanitize_file_path(file_path: &str) -> String {
        let mut parts = file_path.splitn(2, "::");
        let storage_part = parts.next().unwrap_or("");
        let path_part = parts.next().unwrap_or("");
    
        let sanitized = path_part.replace(':', ";");

        // Compile a regex to match one or more consecutive slashes
        let re = Regex::new(r"/+").unwrap();
        let sanitized = re.replace_all(&sanitized, "/").to_string();

        // Remove leading and trailing slashes
        let sanitized = sanitized.trim_matches('/').to_string();

        // Additional sanitization can be performed here if necessary
    
        // Reconstruct the full path
        format!("{}::{}", storage_part, sanitized)
    }

    pub fn ensure_root_folder(disk_id: &DiskID, user_id: &UserID, canister_id: String,) -> FolderUUID {
        let root_path = DriveFullFilePath(format!("{}::", disk_id.to_string()));
        let canister_icp_principal_string = if canister_id.is_empty() {
            ic_cdk::api::id().to_text()
        } else {
            canister_id.clone()
        };
        if let Some(uuid) = full_folder_path_to_uuid.get(&root_path) {
            uuid.clone()
        } else {
            let root_folder_uuid = generate_unique_id("FolderUUID", "");
            let root_folder = FolderMetadata {
                id: FolderUUID(root_folder_uuid.clone()),
                name: String::new(),
                parent_folder_uuid: None,
                subfolder_uuids: Vec::new(),
                file_uuids: Vec::new(),
                full_folder_path: root_path.clone(),
                tags: Vec::new(),
                owner: user_id.clone(),
                created_date: ic_cdk::api::time(),
                disk_id: disk_id.clone(),
                last_changed_unix_ms: ic_cdk::api::time() / 1_000_000,
                deleted: false,
                canister_id: ICPPrincipalString(PublicKeyBLS(canister_icp_principal_string)),
                expires_at: -1,
            };

            full_folder_path_to_uuid.insert(root_path, FolderUUID(root_folder_uuid.clone()));
            folder_uuid_to_metadata.insert(FolderUUID(root_folder_uuid.clone()), root_folder);

            FolderUUID(root_folder_uuid)
        }
    }

    pub fn update_subfolder_paths(folder_id: &FolderUUID, old_path: &str, new_path: &str) {
        // Get folder metadata first
        let folder = match folder_uuid_to_metadata.get(folder_id) {
            Some(f) => f,
            None => return,
        };
    
        // Clone the vectors we need to iterate over to avoid borrowing issues
        let subfolder_uuids = folder.subfolder_uuids.clone();
        let file_uuids = folder.file_uuids.clone();
    
        // Update subfolders
        for subfolder_id in &subfolder_uuids {
            // Get old path before updating
            let old_subfolder_path = if let Some(subfolder) = folder_uuid_to_metadata.get(subfolder_id) {
                subfolder.full_folder_path.clone()
            } else {
                continue;
            };
    
            let new_subfolder_path = DriveFullFilePath(old_subfolder_path.to_string().replace(old_path, new_path));
            
            // Update folder metadata
            folder_uuid_to_metadata.with_mut(|map| {
                if let Some(subfolder) = map.get_mut(subfolder_id) {
                    subfolder.full_folder_path = new_subfolder_path.clone();
                }
            });
            
            // Update path mappings
            full_folder_path_to_uuid.remove(&old_subfolder_path);
            full_folder_path_to_uuid.insert(new_subfolder_path.clone(), subfolder_id.clone());
            
            // Recursively update paths for this subfolder
            update_subfolder_paths(subfolder_id, &old_subfolder_path.to_string(), &new_subfolder_path.to_string());
        }
    
        // Update file paths
        for file_id in &file_uuids {
            // Get old path before updating
            let old_file_path = if let Some(file) = file_uuid_to_metadata.get(file_id) {
                file.full_file_path.clone()
            } else {
                continue;
            };
    
            let new_file_path = DriveFullFilePath(old_file_path.to_string().replace(old_path, new_path));
            
            // Update file metadata
            file_uuid_to_metadata.with_mut(|map| {
                if let Some(file) = map.get_mut(file_id) {
                    file.full_file_path = new_file_path.clone();
                }
            });
            
            // Update path mappings
            full_file_path_to_uuid.remove(&old_file_path);
            full_file_path_to_uuid.insert(new_file_path, file_id.clone());
        }
    }

    pub fn ensure_folder_structure(
        folder_path: &str,
        disk_id: DiskID,
        user_id: UserID,
        canister_id: String,
    ) -> FolderUUID {
        let path_parts: Vec<&str> = folder_path.split("::").collect();
        let mut current_path = format!("{}::", path_parts[0]);

        let canister_icp_principal_string = if canister_id.is_empty() {
            ic_cdk::api::id().to_text()
        } else {
            canister_id.clone()
        };

        let mut parent_uuid = ensure_root_folder(&disk_id, &user_id, canister_icp_principal_string.clone());

        for part in path_parts[1].split('/').filter(|&p| !p.is_empty()) {
            current_path = format!("{}{}/", current_path.clone(), part);
            
            if !full_folder_path_to_uuid.contains_key(&DriveFullFilePath(current_path.clone())) {
                let new_folder_uuid = FolderUUID(generate_unique_id("FolderUUID",""));
                let new_folder = FolderMetadata {
                    id: new_folder_uuid.clone(),
                    name: part.to_string(),
                    parent_folder_uuid: Some(parent_uuid.clone()),
                    subfolder_uuids: Vec::new(),
                    file_uuids: Vec::new(),
                    full_folder_path: DriveFullFilePath(current_path.clone()),
                    tags: Vec::new(),
                    owner: user_id.clone(),
                    created_date: ic_cdk::api::time(),
                    disk_id: disk_id.clone(),
                    last_changed_unix_ms: ic_cdk::api::time() / 1_000_000,
                    deleted: false,
                    canister_id: ICPPrincipalString(PublicKeyBLS(canister_icp_principal_string.clone())),
                    expires_at: -1,
                };

                full_folder_path_to_uuid.insert(DriveFullFilePath(current_path.clone()), new_folder_uuid.clone());
                folder_uuid_to_metadata.insert(new_folder_uuid.clone(), new_folder);

                // Update parent folder's subfolder_uuids
                folder_uuid_to_metadata.with_mut(|map| {
                    if let Some(parent_folder) = map.get_mut(&parent_uuid) {
                        if !parent_folder.subfolder_uuids.contains(&new_folder_uuid) {
                            parent_folder.subfolder_uuids.push(new_folder_uuid.clone());
                        }
                    }
                });

                parent_uuid = new_folder_uuid;
            } else {
                parent_uuid = full_folder_path_to_uuid.get(&DriveFullFilePath(current_path.clone()))
                    .expect("Folder UUID not found")
                    .clone();
            }
        }

        parent_uuid
    }

    pub fn split_path(full_path: &str) -> (String, String) {
        let parts: Vec<&str> = full_path.rsplitn(2, '/').collect();
        match parts.as_slice() {
            [file_name, folder_path] => (folder_path.to_string(), file_name.to_string()),
            [single_part] => {
                let storage_parts: Vec<&str> = single_part.splitn(2, "::").collect();
                match storage_parts.as_slice() {
                    [storage, file_name] => (format!("{}::", storage), file_name.to_string()),
                    _ => (String::new(), single_part.to_string()),
                }
            },
            _ => (String::new(), String::new()),
        }
    }

    pub fn update_folder_file_uuids(folder_uuid: &FolderUUID, file_uuid: &FileUUID, is_add: bool) {
        folder_uuid_to_metadata.with_mut(|map| {
            if let Some(folder) = map.get_mut(folder_uuid) {
                if is_add {
                    if !folder.file_uuids.contains(file_uuid) {
                        folder.file_uuids.push(file_uuid.clone());
                    }
                } else {
                    folder.file_uuids.retain(|uuid| uuid != file_uuid);
                }
            }
        });
    }
    
    pub fn translate_path_to_id(path: DriveFullFilePath) -> PathTranslationResponse {
        // Check if path ends with '/' to determine if we're looking for a folder
        let is_folder_path = path.0.ends_with('/');
        
        let mut response = PathTranslationResponse {
            folder: None,
            file: None,
        };

        if is_folder_path {
            // Look up folder UUID first
            if let Some(folder_uuid) = full_folder_path_to_uuid.get(&path) {
                // Then get the folder metadata
                response.folder = folder_uuid_to_metadata.get(&folder_uuid);
            }
        } else {
            // Look up file UUID first
            if let Some(file_uuid) = full_file_path_to_uuid.get(&path) {
                // Then get the file metadata
                response.file = file_uuid_to_metadata.get(&file_uuid);
            }
        }

        response
    }

    pub fn format_file_asset_path (
        file_uuid: FileUUID,
        extension: String,
    ) -> String {
        format!(
            "https://{}.raw.icp0.io/asset/{file_uuid}.{extension}",
            ic_cdk::api::id().to_text()
        )
    }

}


// src/rest/directory/handler.rs


pub mod directorys_handlers {
    use crate::{
        core::{api::{disks::aws_s3::generate_s3_upload_url, drive::drive::fetch_files_at_folder_path, uuid::generate_unique_id}, state::{directory::{}, disks::{state::state::DISKS_BY_ID_HASHTABLE, types::{AwsBucketAuth, DiskID, DiskTypeEnum}}, drives::state::state::OWNER_ID, raw_storage::{state::{get_file_chunks, store_chunk, store_filename, FILE_META}, types::{ChunkId, FileChunk, CHUNK_SIZE}}}}, debug_log, rest::{auth::{authenticate_request, create_auth_error_response, create_raw_upload_error_response}, directory::types::{ClientSideUploadRequest, ClientSideUploadResponse, CompleteUploadRequest, CompleteUploadResponse, DirectoryAction, DirectoryActionError, DirectoryActionOutcome, DirectoryActionOutcomeID, DirectoryActionRequestBody, DirectoryListResponse, ErrorResponse, FileMetadataResponse, ListDirectoryRequest, UploadChunkRequest, UploadChunkResponse}}, 
        
    };
    
    use ic_http_certification::{HttpRequest, HttpResponse, StatusCode};
    use matchit::Params;
    use serde::Deserialize;
    use urlencoding::decode;
    #[derive(Deserialize, Default)]
    struct ListQueryParams {
        title: Option<String>,
        completed: Option<bool>,
    }

    pub fn search_directory_handler(request: &HttpRequest, _params: &Params) -> HttpResponse<'static> {
        let requester_api_key = match authenticate_request(request) {
            Some(key) => key,
            None => return create_auth_error_response(),
        };
    
        let is_owner = OWNER_ID.with(|owner_id| requester_api_key.user_id == *owner_id);
        if !is_owner {
            return create_auth_error_response();
        }
    
        let response = DirectoryListResponse {
            folders: Vec::new(),
            files: Vec::new(),
            total_folders: 0,
            total_files: 0,
            cursor: None,
        };
    
        create_response(
            StatusCode::OK,
            serde_json::to_vec(&response).expect("Failed to serialize response")
        )
    }

    pub fn list_directorys_handler(request: &HttpRequest, _params: &Params) -> HttpResponse<'static> {
        // Authenticate request
        let requester_api_key = match authenticate_request(request) {
            Some(key) => key,
            None => return create_auth_error_response(),
        };
    
        // Only owner can access directories
        let is_owner = OWNER_ID.with(|owner_id| requester_api_key.user_id == *owner_id);
        if !is_owner {
            return create_auth_error_response();
        }
    
        // Parse request body
        let list_request: ListDirectoryRequest = match serde_json::from_slice(request.body()) {
            Ok(req) => req,
            Err(_) => return create_response(
                StatusCode::BAD_REQUEST,
                ErrorResponse::err(400, "Invalid request format".to_string()).encode()
            ),
        };
    
        match fetch_files_at_folder_path(list_request) {
            Ok(response) => create_response(
                StatusCode::OK,
                serde_json::to_vec(&response).expect("Failed to serialize response")
            ),
            Err(err) => create_response(
                StatusCode::NOT_FOUND,
                ErrorResponse::err(404, format!("Failed to list directory: {:?}", err)).encode()
            )
        }
    }

    pub fn action_directory_handler(request: &HttpRequest, _params: &Params) -> HttpResponse<'static> {
        let requester_api_key = match authenticate_request(request) {
            Some(key) => key,
            None => return create_auth_error_response(),
        };
    
        let is_owner = OWNER_ID.with(|owner_id| requester_api_key.user_id == *owner_id);
        if !is_owner {
            return create_auth_error_response();
        }
    
        let action_batch: DirectoryActionRequestBody = match serde_json::from_slice(request.body()) {
            Ok(req) => req,
            Err(_) => return create_response(
                StatusCode::BAD_REQUEST,
                ErrorResponse::err(400, "Invalid request format".to_string()).encode()
            ),
        };
    
        let mut outcomes = Vec::new();
        
        for action in action_batch.actions {
            let outcome_id = DirectoryActionOutcomeID(generate_unique_id("DirectoryActionOutcomeID", ""));
            let outcome = match crate::core::api::actions::pipe_action(action.clone()) {
                Ok(result) => DirectoryActionOutcome {
                    id: outcome_id,
                    success: true,
                    action: action.action,
                    target: action.target,
                    payload: action.payload,
                    result: Some(result),
                    error: None,
                },
                Err(error_info) => DirectoryActionOutcome {
                    id: outcome_id,
                    success: false,
                    action: action.action,
                    target: action.target,
                    payload: action.payload,
                    result: None,
                    error: Some(DirectoryActionError {
                        code: error_info.code,
                        message: error_info.message,
                    }),
                },
            };
            outcomes.push(outcome);
        }
    
        create_response(
            StatusCode::OK,
            serde_json::to_vec(&outcomes).expect("Failed to serialize response")
        )
    }

    pub fn handle_upload_chunk(req: &HttpRequest, _: &Params) -> HttpResponse<'static> {
        debug_log!("Handling upload chunk request");

        let upload_req: UploadChunkRequest = match serde_json::from_slice(req.body()) {
            Ok(req) => req,
            Err(_) => {
                debug_log!("handle_upload_chunk: Failed to deserialize request");
                return create_raw_upload_error_response("Invalid request format")
            }
        };

        debug_log!("handle_upload_chunk: Handling chunk upload");
        debug_log!("  file_id      = {}", upload_req.file_id);
        debug_log!("  chunk_index  = {}", upload_req.chunk_index);
        debug_log!("  total_chunks = {}", upload_req.total_chunks);
        debug_log!("  chunk_size   = {}", upload_req.chunk_data.len());
    
        if upload_req.chunk_data.len() > CHUNK_SIZE {
            return create_raw_upload_error_response("Chunk too large");
        }
    
        let chunk_id = ChunkId(format!("{}-{}", upload_req.file_id, upload_req.chunk_index));
        
        let chunk = FileChunk {
            id: chunk_id.clone(),
            file_id: upload_req.file_id,
            chunk_index: upload_req.chunk_index,
            data: upload_req.chunk_data.clone(),
            size: upload_req.chunk_data.len()
        };
        debug_log!("handle_upload_chunk: Storing chunk {:?}", chunk.id);
    
        store_chunk(chunk);
    
        let response = UploadChunkResponse {
            chunk_id: chunk_id.0,
            bytes_received: upload_req.chunk_data.len()
        };
    
        debug_log!("handle_upload_chunk: Successfully stored chunk");
        create_success_response(&response)
    }
    
    pub fn handle_complete_upload(req: &HttpRequest, _: &Params) -> HttpResponse<'static> {
        let complete_req: CompleteUploadRequest = match serde_json::from_slice(req.body()) {
            Ok(req) => req,
            Err(_) => return create_raw_upload_error_response("Invalid request format")
        };
        debug_log!("handle_complete_upload: Completing upload");
        debug_log!("  file_id = {}", complete_req.file_id);

        store_filename(&complete_req.file_id, &complete_req.filename);
    
        let chunks = get_file_chunks(&complete_req.file_id);
        debug_log!("handle_complete_upload: Found {} chunks", chunks.len());

        let total_size: usize = chunks.iter().map(|c| c.size).sum();
        debug_log!("handle_complete_upload: Total size = {} bytes", total_size);
    
        let response = CompleteUploadResponse {
            file_id: complete_req.file_id,
            size: total_size,
            chunks: chunks.len() as u32,
            filename: complete_req.filename
        };
         debug_log!("handle_complete_upload: Returning final response with size={} chunks={}", response.size, response.chunks);
    
        create_success_response(&response)
    }

    /// Returns the metadata about a file: total size, total chunks, etc.
    pub fn download_file_metadata_handler(req: &HttpRequest, _: &Params) -> HttpResponse<'static> {
        debug_log!("download_file_metadata_handler: Handling file metadata request");

        // // 1. Optionally authenticate, if required
        // let requester_api_key = match authenticate_request(req) {
        //     Some(key) => key,
        //     None => return create_auth_error_response(),
        // };

        // // 2. Check if user is owner, if that's your policy
        // let is_owner = OWNER_ID.with(|owner_id| requester_api_key.user_id == *owner_id);
        // if !is_owner {
        //     return create_auth_error_response();
        // }

        // 3. Parse query string for file_id
        let raw_query_string = req.get_query().unwrap_or(Some("".to_string()));
        let query_string = raw_query_string.as_deref().unwrap_or("");
        let query_map = crate::rest::helpers::parse_query_string(&query_string);

        let file_id = match query_map.get("file_id") {
            Some(fid) => fid,
            None => {
                return create_response(
                    StatusCode::BAD_REQUEST,
                    ErrorResponse::err(400, "Missing file_id in query".to_string()).encode()
                );
            }
        };
        let file_id = decode(file_id).unwrap_or_else(|_| file_id.into());

        debug_log!("download_file_metadata_handler: file_id={}", file_id);

        // 4. Collect chunks for this file, if any
        let mut chunks = get_file_chunks(&file_id);
        if chunks.is_empty() {
            return create_response(
                StatusCode::NOT_FOUND,
                ErrorResponse::err(404, "File not found".to_string()).encode()
            );
        }

        // 5. Sort by chunk index and compute total size
        chunks.sort_by_key(|c| c.chunk_index);
        let total_size: usize = chunks.iter().map(|c| c.size).sum();
        let total_chunks = chunks.len() as u32;

        let filename: String = FILE_META.with(|map| 
            map.borrow()
                .get(&file_id.to_string())
                .clone()  // Change cloned() to clone()
        ).unwrap_or_else(|| "unknown.bin".to_string());

        // Create a JSON response with metadata
        let metadata_response = FileMetadataResponse {
            file_id: file_id.clone().to_string(),
            total_size,
            total_chunks,
            filename
        };

        debug_log!(
            "download_file_metadata_handler: total_size={}, total_chunks={}",
            total_size,
            total_chunks
        );

        create_success_response(&metadata_response)
    }

    /// Returns the data for a single chunk by index.
    pub fn download_file_chunk_handler(req: &HttpRequest, _: &Params) -> HttpResponse<'static> {
        debug_log!("download_file_chunk_handler: Handling file chunk request");

        // // 1. Optionally authenticate
        // let requester_api_key = match authenticate_request(req) {
        //     Some(key) => key,
        //     None => return create_auth_error_response(),
        // };

        // // 2. Owner check, if you want
        // let is_owner = OWNER_ID.with(|owner_id| requester_api_key.user_id == *owner_id);
        // if !is_owner {
        //     return create_auth_error_response();
        // }

        // 3. Parse query for file_id & chunk_index
        let raw_query_string = req.get_query().unwrap_or(Some("".to_string()));
        let query_string = raw_query_string.as_deref().unwrap_or("");
        let query_map = crate::rest::helpers::parse_query_string(query_string);

        let file_id = match query_map.get("file_id") {
            Some(fid) => fid,
            None => {
                return create_response(
                    StatusCode::BAD_REQUEST,
                    ErrorResponse::err(400, "Missing file_id".to_string()).encode()
                );
            }
        };
        let file_id = decode(file_id).unwrap_or_else(|_| file_id.into());

        let chunk_index_str = match query_map.get("chunk_index") {
            Some(cix) => cix,
            None => {
                return create_response(
                    StatusCode::BAD_REQUEST,
                    ErrorResponse::err(400, "Missing chunk_index".to_string()).encode()
                );
            }
        };
        let chunk_index: u32 = match chunk_index_str.parse() {
            Ok(num) => num,
            Err(_) => {
                return create_response(
                    StatusCode::BAD_REQUEST,
                    ErrorResponse::err(400, "Invalid chunk_index".to_string()).encode()
                );
            }
        };

        debug_log!("download_file_chunk_handler: file_id={}, chunk_index={}", file_id, chunk_index);

        // 4. Retrieve all chunks, or just the one
        let mut chunks = get_file_chunks(&file_id);
        chunks.sort_by_key(|c| c.chunk_index);

        // Check if chunk_index is valid
        if chunk_index as usize >= chunks.len() {
            return create_response(
                StatusCode::NOT_FOUND,
                ErrorResponse::err(404, "Chunk index out of range".to_string()).encode()
            );
        }

        let chunk = &chunks[chunk_index as usize];
        debug_log!("download_file_chunk_handler: Found chunk size={}", chunk.size);

        // 5. Return the chunk data in the HTTP body
        //    We'll set the content-type to "application/octet-stream".
        HttpResponse::builder()
            .with_status_code(StatusCode::OK)
            .with_headers(vec![
                ("content-type".to_string(), "application/octet-stream".to_string()),
                ("cache-control".to_string(), "no-store, max-age=0".to_string()),
            ])
            .with_body(chunk.data.clone())
            .build()
    }

    pub fn request_clientside_upload_handler(req: &HttpRequest, _: &Params) -> HttpResponse<'static> {
        // 1. Authenticate request
        let requester_api_key = match authenticate_request(req) {
            Some(key) => key,
            None => return create_auth_error_response(),
        };
    
        // 2. Only owner can request uploads
        let is_owner = OWNER_ID.with(|owner_id| requester_api_key.user_id == *owner_id);
        if !is_owner {
            return create_auth_error_response();
        }
    
        // 3. Parse request body
        let upload_req: ClientSideUploadRequest = match serde_json::from_slice(req.body()) {
            Ok(req) => req,
            Err(_) => return create_response(
                StatusCode::BAD_REQUEST,
                ErrorResponse::err(400, "Invalid request format".to_string()).encode()
            ),
        };
    
        // 4. Validate the disk exists and is AWS type
        let disk = DISKS_BY_ID_HASHTABLE.with(|map| {
            map.borrow()
                .get(&DiskID(upload_req.disk_id.clone()))
                .cloned()
        });
    
        let disk = match disk {
            Some(d) => d,
            None => return create_response(
                StatusCode::NOT_FOUND,
                ErrorResponse::err(404, "Disk not found".to_string()).encode()
            ),
        };
    
        if disk.disk_type != DiskTypeEnum::AwsBucket {
            return create_response(
                StatusCode::BAD_REQUEST,
                ErrorResponse::err(400, "Disk is not an AWS S3 bucket".to_string()).encode()
            );
        }
    
        // 5. Parse AWS credentials from disk auth_json
        let aws_auth: AwsBucketAuth = match disk.auth_json {
            Some(auth_str) => match serde_json::from_str(&auth_str) {
                Ok(auth) => auth,
                Err(_) => return create_response(
                    StatusCode::INTERNAL_SERVER_ERROR,
                    ErrorResponse::err(500, "Invalid AWS credentials format".to_string()).encode()
                ),
            },
            None => return create_response(
                StatusCode::INTERNAL_SERVER_ERROR,
                ErrorResponse::err(500, "Missing AWS credentials".to_string()).encode()
            ),
        };
    
        // 6. Generate the upload URL and signature
        // Set reasonable limits: 100GB max size, 24 hour expiry
        let max_file_size = 100 * 1024 * 1024 * 1024; // 10GB in bytes
        let expires_in = 3600 * 24; // 24 hours in seconds
    
        let s3_response = generate_s3_upload_url(
            &upload_req.folder_path,
            &aws_auth,
            max_file_size,
            expires_in
        );
    
        // 7. Return the signed URL and fields
        let response = ClientSideUploadResponse {
            signature: s3_response,  // Contains URL and form fields
        };
    
        create_success_response(&response)
    }

    fn json_decode<T>(value: &[u8]) -> T
    where
        T: for<'de> Deserialize<'de>,
    {
        serde_json::from_slice(value).expect("Failed to deserialize value")
    }

    fn create_response(status_code: StatusCode, body: Vec<u8>) -> HttpResponse<'static> {
        HttpResponse::builder()
            .with_status_code(status_code)
            .with_headers(vec![
                ("content-type".to_string(), "application/json".to_string()),
                (
                    "strict-transport-security".to_string(),
                    "max-age=31536000; includeSubDomains".to_string(),
                ),
                ("x-content-type-options".to_string(), "nosniff".to_string()),
                ("referrer-policy".to_string(), "no-referrer".to_string()),
                (
                    "cache-control".to_string(),
                    "no-store, max-age=0".to_string(),
                ),
                ("pragma".to_string(), "no-cache".to_string()),
            ])
            .with_body(body)
            .build()
    }

    fn create_success_response<T: serde::Serialize>(data: &T) -> HttpResponse<'static> {
        let body = serde_json::to_vec(data).expect("Failed to serialize response");
        create_response(StatusCode::OK, body)
    }
    
}


// src/rest/directory/types.rs
use serde::{Deserialize, Serialize};
use crate::{core::state::directory::types::{DriveFullFilePath, FileMetadata, FileUUID, FolderMetadata, FolderUUID, Tag}, rest::webhooks::types::SortDirection};
use crate::core::{
    state::disks::types::{DiskID, DiskTypeEnum},
    types::{ICPPrincipalString, UserID}
};


#[derive(Debug, Clone, Deserialize)]
pub struct SearchDirectoryRequest {
    pub query_string: String,
}

#[derive(Debug, Clone, Deserialize)]
pub struct ListDirectoryRequest {
    pub folder_id: Option<String>,
    pub path: Option<String>,
    #[serde(default)]
    pub filters: String,
    #[serde(default = "default_page_size")]
    pub page_size: usize,
    #[serde(default)]
    pub direction: SortDirection,
    pub cursor: Option<String>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DirectoryListResponse {
    pub folders: Vec<FolderMetadata>,
    pub files: Vec<FileMetadata>,
    pub total_files: usize,
    pub total_folders: usize,
    pub cursor: Option<String>,
}

fn default_page_size() -> usize {
    50
}


#[derive(Debug, Clone, Deserialize)]
pub struct UploadChunkRequest {
    pub file_id: String,
    pub chunk_index: u32,
    pub chunk_data: Vec<u8>,
    pub total_chunks: u32
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct UploadChunkResponse {
    pub chunk_id: String,
    pub bytes_received: usize
}

#[derive(Debug, Clone, Deserialize)] 
pub struct CompleteUploadRequest {
    pub file_id: String,
    pub filename: String
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct CompleteUploadResponse {
    pub file_id: String,
    pub size: usize,
    pub chunks: u32,
    pub filename: String
}


#[derive(serde::Serialize, Deserialize)]
pub struct FileMetadataResponse {
    pub file_id: String,
    pub total_size: usize,
    pub total_chunks: u32,
    pub filename: String
}

pub type SearchDirectoryResponse = DirectoryListResponse;

pub type DirectoryResponse<'a, T> = crate::rest::drives::types::DriveResponse<'a, T>;
pub type ErrorResponse<'a> = DirectoryResponse<'a, ()>;



#[derive(Debug, Clone, Deserialize)] 
pub struct ClientSideUploadRequest {
    pub disk_id: String,
    pub folder_path: String,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ClientSideUploadResponse {
    pub signature: String,
}


// --------------------------------------------


#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DirectoryAction {
    pub action: DirectoryActionEnum,
    pub target: ResourceIdentifier,
    pub payload: DirectoryActionPayload,
}

#[derive(Debug, Clone, PartialEq, Eq, Hash, Serialize, Deserialize)]
pub struct DirectoryActionOutcomeID(pub String);

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DirectoryActionOutcome {
    pub id: DirectoryActionOutcomeID,
    pub success: bool,
    pub action: DirectoryActionEnum,
    pub target: ResourceIdentifier,
    pub payload: DirectoryActionPayload,
    pub result: Option<DirectoryActionResult>,
    pub error: Option<DirectoryActionError>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DirectoryActionRequestBody {
    pub actions: Vec<DirectoryAction>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DirectoryActionError {
    pub code: i32,
    pub message: String,
}

#[derive(Debug, Clone,Serialize,  Deserialize)]
#[serde(rename_all = "SCREAMING_SNAKE_CASE")]
pub enum DirectoryActionEnum {
    GetFile,
    GetFolder,
    CreateFile,
    CreateFolder,
    UpdateFile,
    UpdateFolder,
    DeleteFile,
    DeleteFolder,
    CopyFile,
    CopyFolder,
    MoveFile,
    MoveFolder,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ResourceIdentifier {
    #[serde(default)]
    pub resource_path: Option<DriveFullFilePath>,
    #[serde(default)]
    pub resource_id: Option<String>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(untagged)]
pub enum DirectoryActionPayload {
    GetFile(GetFilePayload),
    GetFolder(GetFolderPayload),
    CreateFile(CreateFilePayload),
    CreateFolder(CreateFolderPayload),
    UpdateFile(UpdateFilePayload),
    UpdateFolder(UpdateFolderPayload),
    DeleteFile(DeleteFilePayload),
    DeleteFolder(DeleteFolderPayload),
    CopyFile(CopyFilePayload),
    CopyFolder(CopyFolderPayload),
    MoveFile(MoveFilePayload),
    MoveFolder(MoveFolderPayload),
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct GetFilePayload {}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct GetFolderPayload {}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct CreateFilePayload {
    pub name: String,
    pub extension: String,
    pub tags: Vec<Tag>,
    pub file_size: u64,
    pub raw_url: String,
    pub disk_id: DiskID,
    pub expires_at: Option<i64>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct CreateFolderPayload {
    pub name: String,
    pub tags: Vec<Tag>,
    pub disk_id: DiskID,
    pub expires_at: Option<i64>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct UpdateFilePayload {
    pub name: Option<String>,
    pub tags: Option<Vec<Tag>>,
    pub raw_url: Option<String>,
    pub expires_at: Option<i64>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct UpdateFolderPayload {
    pub name: Option<String>,
    pub tags: Option<Vec<Tag>>,
    pub expires_at: Option<i64>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DeleteFilePayload {
    pub permanent: bool,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DeleteFolderPayload {
    pub permanent: bool,
    pub recursive: bool,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct CopyFilePayload {
    pub destination_folder_id: FolderUUID,
    pub new_name: Option<String>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct CopyFolderPayload {
    pub destination_parent_id: FolderUUID,
    pub new_name: Option<String>,
    pub recursive: bool,
}

#[derive(Debug, Clone,Serialize, Deserialize)]
pub struct MoveFilePayload {
    pub destination_folder_id: FolderUUID,
    pub new_name: Option<String>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct MoveFolderPayload {
    pub destination_parent_id: FolderUUID,
    pub new_name: Option<String>,
}



// Response types remain the same as before
#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(untagged)]
pub enum DirectoryActionResult {
    GetFile(FileMetadata),
    GetFolder(FolderMetadata),
    CreateFile(FileMetadata),
    CreateFolder(FolderMetadata),
    UpdateFile(FileMetadata),
    UpdateFolder(FolderMetadata),
    DeleteFile(DeleteFileResponse),
    DeleteFolder(DeleteFolderResponse),
    CopyFile(FileMetadata),
    CopyFolder(FolderMetadata),
    MoveFile(FileMetadata),
    MoveFolder(FolderMetadata),
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DeleteFileResponse {
    pub file_id: FileUUID,
    pub full_path: DriveFullFilePath,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DeleteFolderResponse {
    pub folder_id: FolderUUID,
    pub full_path: DriveFullFilePath,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub deleted_files: Option<Vec<FileUUID>>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub deleted_folders: Option<Vec<FolderUUID>>,
}

// Example JSON requests:
/*
1. GET_FILE request (by path):
{
    "action": "GET_FILE",
    "target": {
        "resource_path": "/user/documents/report.pdf"
    },
    "payload": {}
}

2. GET_FILE request (by id):
{
    "action": "GET_FILE",
    "target": {
        "resource_id": "file-uuid-123"
    },
    "payload": {}
}

3. GET_FOLDER request:
{
    "action": "GET_FOLDER",
    "target": {
        "resource_id": "folder-uuid-456"
    },
    "payload": {}
}

4. CREATE_FILE request:
{
    "action": "CREATE_FILE",
    "target": {
        "resource_path": "/user/documents/report.pdf"
    },
    "payload": {
        "name": "report.pdf",
        "folder_uuid": "folder-uuid-789",
        "extension": "pdf",
        "tags": ["work", "2024"],
        "file_size": 1024567,
        "raw_url": "https://example.com/files/raw/123",
        "disk_id": "disk-1",
        "expires_at": 1735689600000
    }
}

5. CREATE_FOLDER request:
{
    "action": "CREATE_FOLDER",
    "target": {
        "resource_path": "/user/documents/project-alpha"
    },
    "payload": {
        "name": "project-alpha",
        "parent_folder_uuid": "folder-uuid-123",
        "tags": ["project", "active"],
        "disk_id": "disk-1",
        "expires_at": 1735689600000
    }
}

6. UPDATE_FILE request:
{
    "action": "UPDATE_FILE",
    "target": {
        "resource_id": "file-uuid-123"
    },
    "payload": {
        "name": "updated-report.pdf",
        "folder_uuid": "folder-uuid-new",
        "tags": ["work", "2024", "reviewed"],
        "raw_url": "https://example.com/files/raw/124",
        "expires_at": 1735689600000
    }
}

7. UPDATE_FOLDER request:
{
    "action": "UPDATE_FOLDER",
    "target": {
        "resource_id": "folder-uuid-456"
    },
    "payload": {
        "name": "project-beta",
        "parent_folder_uuid": "folder-uuid-new-parent",
        "tags": ["project", "active", "phase-2"],
        "expires_at": 1735689600000
    }
}

8. DELETE_FILE request:
{
    "action": "DELETE_FILE",
    "target": {
        "resource_id": "file-uuid-123"
    },
    "payload": {
        "permanent": false
    }
}

9. DELETE_FOLDER request:
{
    "action": "DELETE_FOLDER",
    "target": {
        "resource_id": "folder-uuid-456"
    },
    "payload": {
        "permanent": false,
        "recursive": true
    }
}

10. COPY_FILE request:
{
    "action": "COPY_FILE",
    "target": {
        "resource_id": "file-uuid-123"
    },
    "payload": {
        "destination_folder_id": "folder-uuid-destination",
        "new_name": "report-copy.pdf"
    }
}

11. COPY_FOLDER request:
{
    "action": "COPY_FOLDER",
    "target": {
        "resource_id": "folder-uuid-456"
    },
    "payload": {
        "destination_parent_id": "folder-uuid-destination",
        "new_name": "project-alpha-backup",
        "recursive": true
    }
}

12. MOVE_FILE request:
{
    "action": "MOVE_FILE",
    "target": {
        "resource_id": "file-uuid-123"
    },
    "payload": {
        "destination_folder_id": "folder-uuid-destination",
        "new_name": "report-new-location.pdf"
    }
}

13. MOVE_FOLDER request:
{
    "action": "MOVE_FOLDER",
    "target": {
        "resource_id": "folder-uuid-456"
    },
    "payload": {
        "destination_parent_id": "folder-uuid-destination",
        "new_name": "project-alpha-archived"
    }
}
*/



// src/rest/directorys/route.rs
use crate::debug_log;
use crate::rest::router;
use crate::types::RouteHandler;

pub const DIRECTORYS_SEARCH_PATH: &str = "/directory/search";
pub const DIRECTORYS_LIST_PATH: &str = "/directory/list";
pub const DIRECTORYS_ACTION_PATH: &str = "/directory/action";
pub const UPLOAD_CHUNK_PATH: &str = "/directory/raw_upload/chunk";
pub const COMPLETE_UPLOAD_PATH: &str = "/directory/raw_upload/complete";
pub const RAW_DOWNLOAD_META_PATH: &str = "/directory/raw_download/meta";
pub const RAW_DOWNLOAD_CHUNK_PATH: &str = "/directory/raw_download/chunk";
pub const RAW_URL_PROXY_PATH: &str = "/asset/{file_id}"; // for proxying raw urls 302 redirect to temp presigned s3 urls

pub const REQUEST_CLIENTSIDE_UPLOAD: &str = "/directory/testing/aws_s3";

type HandlerEntry = (&'static str, &'static str, RouteHandler);

pub fn init_routes() {
    let routes: &[HandlerEntry] = &[
        (
            "POST",
            DIRECTORYS_SEARCH_PATH,
            crate::rest::directory::handler::directorys_handlers::search_directory_handler,
        ),
        (
            "POST",
            DIRECTORYS_LIST_PATH,
            crate::rest::directory::handler::directorys_handlers::list_directorys_handler,
        ),
        (
            "POST",
            DIRECTORYS_ACTION_PATH,
            crate::rest::directory::handler::directorys_handlers::action_directory_handler,
        ),
        (
            "POST",
            UPLOAD_CHUNK_PATH,
            crate::rest::directory::handler::directorys_handlers::handle_upload_chunk,
        ),
        (
            "POST",
            COMPLETE_UPLOAD_PATH,
            crate::rest::directory::handler::directorys_handlers::handle_complete_upload,
        ),
        (
            "GET",
            RAW_DOWNLOAD_META_PATH,
            crate::rest::directory::handler::directorys_handlers::download_file_metadata_handler,
        ),
        (
            "GET",
            RAW_DOWNLOAD_CHUNK_PATH,
            crate::rest::directory::handler::directorys_handlers::download_file_chunk_handler,
        ),
        (
            "POST",
            REQUEST_CLIENTSIDE_UPLOAD,
            crate::rest::directory::handler::directorys_handlers::request_clientside_upload_handler,
        ),
    ];

    for &(method, path, handler) in routes {
        debug_log!("Registering {} route: {}", method, path);
        router::insert_route(method, path, handler);
    }

}


// src/core/state/directory/state.rs

pub mod state {
    use std::cell::{RefCell, RefMut};
    use std::collections::HashMap;
    use std::ops::Deref;

    use crate::core::state::{
        directory::types::{DriveFullFilePath, FileMetadata, FileUUID, FolderMetadata, FolderUUID},
        templates::types::{TemplateID, TemplateItem},
    };

    // Wrapper types that implement Deref
    pub struct FolderMap;
    pub struct FileMap;
    pub struct FolderPathMap;
    pub struct FilePathMap;

    impl FolderMap {
        pub fn get(&self, key: &FolderUUID) -> Option<FolderMetadata> {
            folder_uuid_to_metadata_inner.with(|map| map.borrow().get(key).cloned())
        }

        pub fn insert(&self, key: FolderUUID, value: FolderMetadata) {
            folder_uuid_to_metadata_inner.with(|map| map.borrow_mut().insert(key, value));
        }

        pub fn with_mut<R>(&self, f: impl FnOnce(&mut HashMap<FolderUUID, FolderMetadata>) -> R) -> R {
            folder_uuid_to_metadata_inner.with(|map| f(&mut map.borrow_mut()))
        }
    
        pub fn contains_key(&self, key: &FolderUUID) -> bool {
            folder_uuid_to_metadata_inner.with(|map| map.borrow().contains_key(key))
        }
    
        pub fn remove(&self, key: &FolderUUID) -> Option<FolderMetadata> {
            folder_uuid_to_metadata_inner.with(|map| map.borrow_mut().remove(key))
        }
    }

    impl FileMap {
        pub fn get(&self, key: &FileUUID) -> Option<FileMetadata> {
            file_uuid_to_metadata_inner.with(|map| map.borrow().get(key).cloned())
        }

        pub fn insert(&self, key: FileUUID, value: FileMetadata) {
            file_uuid_to_metadata_inner.with(|map| map.borrow_mut().insert(key, value));
        }

        pub fn with_mut<R>(&self, f: impl FnOnce(&mut HashMap<FileUUID, FileMetadata>) -> R) -> R {
            file_uuid_to_metadata_inner.with(|map| f(&mut map.borrow_mut()))
        }
    
        pub fn contains_key(&self, key: &FileUUID) -> bool {
            file_uuid_to_metadata_inner.with(|map| map.borrow().contains_key(key))
        }
    
        pub fn remove(&self, key: &FileUUID) -> Option<FileMetadata> {
            file_uuid_to_metadata_inner.with(|map| map.borrow_mut().remove(key))
        }
    }

    impl FolderPathMap {
        pub fn get(&self, key: &DriveFullFilePath) -> Option<FolderUUID> {
            full_folder_path_to_uuid_inner.with(|map| map.borrow().get(key).cloned())
        }

        pub fn insert(&self, key: DriveFullFilePath, value: FolderUUID) {
            full_folder_path_to_uuid_inner.with(|map| map.borrow_mut().insert(key, value));
        }

        pub fn with_mut<R>(&self, f: impl FnOnce(&mut HashMap<DriveFullFilePath, FolderUUID>) -> R) -> R {
            full_folder_path_to_uuid_inner.with(|map| f(&mut map.borrow_mut()))
        }

        pub fn contains_key(&self, key: &DriveFullFilePath) -> bool {
            full_folder_path_to_uuid_inner.with(|map| map.borrow().contains_key(key))
        }
    
        pub fn remove(&self, key: &DriveFullFilePath) -> Option<FolderUUID> {
            full_folder_path_to_uuid_inner.with(|map| map.borrow_mut().remove(key))
        }
    }

    impl FilePathMap {
        pub fn get(&self, key: &DriveFullFilePath) -> Option<FileUUID> {
            full_file_path_to_uuid_inner.with(|map| map.borrow().get(key).cloned())
        }

        pub fn insert(&self, key: DriveFullFilePath, value: FileUUID) {
            full_file_path_to_uuid_inner.with(|map| map.borrow_mut().insert(key, value));
        }

        pub fn with_mut<R>(&self, f: impl FnOnce(&mut HashMap<DriveFullFilePath, FileUUID>) -> R) -> R {
            full_file_path_to_uuid_inner.with(|map| f(&mut map.borrow_mut()))
        }
    
        pub fn contains_key(&self, key: &DriveFullFilePath) -> bool {
            full_file_path_to_uuid_inner.with(|map| map.borrow().contains_key(key))
        }
    
        pub fn remove(&self, key: &DriveFullFilePath) -> Option<FileUUID> {
            full_file_path_to_uuid_inner.with(|map| map.borrow_mut().remove(key))
        }
    }

    // Private thread_local storage
    thread_local! {
        static folder_uuid_to_metadata_inner: RefCell<HashMap<FolderUUID, FolderMetadata>> = RefCell::new(HashMap::new());
        static file_uuid_to_metadata_inner: RefCell<HashMap<FileUUID, FileMetadata>> = RefCell::new(HashMap::new());
        static full_folder_path_to_uuid_inner: RefCell<HashMap<DriveFullFilePath, FolderUUID>> = RefCell::new(HashMap::new());
        static full_file_path_to_uuid_inner: RefCell<HashMap<DriveFullFilePath, FileUUID>> = RefCell::new(HashMap::new());
    }

    // Public instances with original names
    pub static folder_uuid_to_metadata: FolderMap = FolderMap;
    pub static file_uuid_to_metadata: FileMap = FileMap;
    pub static full_folder_path_to_uuid: FolderPathMap = FolderPathMap;
    pub static full_file_path_to_uuid: FilePathMap = FilePathMap;
}


use std::fmt;

// src/core/state/directory/types.rs
use serde::{Serialize, Deserialize};

use crate::core::{state::disks::types::{DiskID, DiskTypeEnum}, types::{ICPPrincipalString, UserID}};


#[derive(Debug, Clone, PartialEq, Eq, Hash, Serialize, Deserialize)]
pub struct FolderUUID(pub String);
impl fmt::Display for FolderUUID {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        write!(f, "{}", self.0)
    }
}

#[derive(Debug, Clone, PartialEq, Eq, Hash, Serialize, Deserialize)]
pub struct FileUUID(pub String);
impl fmt::Display for FileUUID {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        write!(f, "{}", self.0)
    }
}

#[derive(Debug, Clone, PartialEq, Eq, Hash, Serialize, Deserialize)]
pub struct DriveFullFilePath(pub String);
impl fmt::Display for DriveFullFilePath {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        write!(f, "{}", self.0)
    }
}

#[derive(Debug, Clone, PartialEq, Eq, Hash, Serialize, Deserialize)]
pub struct Tag(pub String);





#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FolderMetadata {
    pub id: FolderUUID,
    pub name: String,
    pub parent_folder_uuid: Option<FolderUUID>,
    pub subfolder_uuids: Vec<FolderUUID>,
    pub file_uuids: Vec<FileUUID>,
    pub full_folder_path: DriveFullFilePath,
    pub tags: Vec<Tag>,
    pub owner: UserID,
    pub created_date: u64, // unix ns   
    pub disk_id: DiskID,
    pub last_changed_unix_ms: u64,
    pub deleted: bool,
    pub expires_at: i64,
    pub canister_id: ICPPrincipalString,
}


#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FileMetadata {
    pub(crate) id: FileUUID,
    pub(crate) name: String,
    pub(crate) folder_uuid: FolderUUID,
    pub(crate) file_version: u32,
    pub(crate) prior_version: Option<FileUUID>,
    pub(crate) next_version: Option<FileUUID>,
    pub(crate) extension: String,
    pub(crate) full_file_path: DriveFullFilePath,
    pub(crate) tags: Vec<Tag>,
    pub(crate) owner: UserID,
    pub(crate) created_date: u64, // unix ns
    pub(crate) disk_id: DiskID,
    pub(crate) file_size: u64,
    pub(crate) raw_url: String,
    pub(crate) last_changed_unix_ms: u64, 
    pub(crate) deleted: bool,
    pub(crate) canister_id: ICPPrincipalString,
    pub(crate) expires_at: i64,
}




#[derive(Serialize, Deserialize, Debug)]
pub struct PathTranslationResponse {
    pub folder: Option<FolderMetadata>,
    pub file: Option<FileMetadata>,
}