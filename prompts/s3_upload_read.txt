// OfficeX filesharing app (clone of google drive)
// where possible, show the code changes as green diffs without the +/- symbols

// src/core/api/disks/aws_s3.rs

use std::collections::HashMap;

use base64::{Engine as _, engine::general_purpose};
use ic_cdk::api::management_canister::http_request::{http_request, CanisterHttpRequestArgument, HttpHeader, HttpMethod};
use serde::{Serialize, Deserialize};
use time::{Duration, OffsetDateTime};
use crate::core::state::disks::types::AwsBucketAuth;
use num_traits::cast::ToPrimitive;

 pub fn generate_s3_view_url(
        file_key: &str,
        auth: &AwsBucketAuth,
        expires_in: Option<u64>,
        download_filename: Option<&str>  // New parameter
    ) -> String {

    let DEFAULT_EXPIRATION: u64 = 3600; // 1 hour in seconds

    let current_time = ic_cdk::api::time();
    
    // Format dates
    let date = format_date(current_time);         // YYYYMMDD
    let date_time = format_datetime(current_time); // YYYYMMDDTHHMMSSZ
    
    // Construct canonical request components
    let http_method = "GET";
    let canonical_uri = format!("/{}/{}", auth.bucket, file_key);
    
    // Query parameters
    let credential = format!("{}/{}/{}/s3/aws4_request", 
        auth.access_key, date, auth.region);
    
    let expiration = expires_in.unwrap_or(DEFAULT_EXPIRATION).to_string();


    // Create content disposition string if filename provided
    let content_disposition = download_filename.map(|filename| {
        let encoded_filename = url_encode(filename);
        format!("attachment; filename=\"{}\"", encoded_filename)
    });

    // Create query parameters including content-disposition if filename provided
    let mut query_params = vec![
        ("X-Amz-Algorithm", "AWS4-HMAC-SHA256"),
        ("X-Amz-Credential", &credential),
        ("X-Amz-Date", &date_time),
        ("X-Amz-Expires", &expiration),
        ("X-Amz-SignedHeaders", "host")
    ];
     

    // Add content-disposition if present
    if let Some(ref disposition) = content_disposition {
        query_params.push(("response-content-disposition", disposition));
    }
    
    // Sort query parameters
    query_params.sort_by(|a, b| a.0.cmp(b.0));
    
    // Create canonical query string
    let canonical_query_string = query_params
        .iter()
        .map(|(k, v)| format!("{}={}", 
            url_encode(k), 
            url_encode(v)))
        .collect::<Vec<_>>()
        .join("&");
    
    // Create canonical headers
    let host = format!("{}.s3.{}.amazonaws.com", auth.bucket, auth.region);
    let canonical_headers = format!("host:{}\n", host);
    
    // Create canonical request
    let canonical_request = format!("{}\n{}\n{}\n{}\n{}\n{}",
        http_method,
        canonical_uri,
        canonical_query_string,
        canonical_headers,
        "host",  // signed headers
        "UNSIGNED-PAYLOAD"
    );
    
    // Create string to sign
    let string_to_sign = format!(
        "AWS4-HMAC-SHA256\n{}\n{}/{}/s3/aws4_request\n{}",
        date_time,
        date,
        auth.region,
        hex::encode(sha256_hash(canonical_request.as_bytes()))
    );
    
    // Calculate signature
    let signature = sign_policy(&string_to_sign, &auth.secret_key, &date, &auth.region);
    
    // Construct final URL
    format!(
        "https://{}/{}?{}&X-Amz-Signature={}",
        host,
        file_key,
        canonical_query_string,
        signature
    )
}

// URL encode function that follows AWS rules
fn url_encode(s: &str) -> String {
    let mut encoded = String::new();
    for c in s.chars() {
        match c {
            'A'..='Z' | 'a'..='z' | '0'..='9' | '_' | '-' | '~' | '.' => encoded.push(c),
            _ => {
                encoded.push_str(&format!("%{:02X}", c as u8));
            }
        }
    }
    encoded
}

// SHA256 hash function
fn sha256_hash(data: &[u8]) -> Vec<u8> {
    use sha2::{Sha256, Digest};
    let mut hasher = Sha256::new();
    hasher.update(data);
    hasher.finalize().to_vec()
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct S3UploadResponse {
    pub url: String,
    pub fields: HashMap<String, String>,
}

pub fn generate_s3_upload_url(
    parent_folder_id: &str,
    auth: &AwsBucketAuth,
    max_size: u64,
    expires_in: u64
) -> Result<S3UploadResponse, String> {
    let current_time = ic_cdk::api::time();
    let expiration_time = current_time + (expires_in * 1_000_000_000);

    // Convert timestamps to required formats
    let date = format_date(current_time);         
    let date_time = format_datetime(current_time); 
    let expiration = format_iso8601(expiration_time);

    // Policy document restricting uploads to folder
    let policy = format!(
        r#"{{
            "expiration": "{}",
            "conditions": [
                {{"bucket": "{}"}},
                ["starts-with", "$key", "{}/"],
                {{"acl": "private"}},
                ["content-length-range", 0, {}],
                {{"x-amz-algorithm": "AWS4-HMAC-SHA256"}},
                {{"x-amz-credential": "{}/{}/{}/s3/aws4_request"}},
                {{"x-amz-date": "{}"}}
            ]
        }}"#,
        expiration,
        auth.bucket,
        parent_folder_id,
        max_size,
        auth.access_key,
        date,
        auth.region,
        date_time
    );

    let policy_base64 = general_purpose::STANDARD.encode(policy);
    let signature = sign_policy(&policy_base64, &auth.secret_key, &date, &auth.region);

    // Construct fields map
    let mut fields = HashMap::new();
    fields.insert("key".to_string(), format!("{}/{{filename}}", parent_folder_id));
    fields.insert("acl".to_string(), "private".to_string());
    fields.insert("x-amz-algorithm".to_string(), "AWS4-HMAC-SHA256".to_string());
    fields.insert(
        "x-amz-credential".to_string(), 
        format!("{}/{}/{}/s3/aws4_request", auth.access_key, date, auth.region)
    );
    fields.insert("x-amz-date".to_string(), date_time);
    fields.insert("policy".to_string(), policy_base64);
    fields.insert("x-amz-signature".to_string(), signature);

    Ok(S3UploadResponse {
        url: format!("{}/{}", auth.endpoint, auth.bucket),
        fields,
    })
}


fn format_date(time: u64) -> String {
    let nanoseconds = time as i64;
    let seconds = nanoseconds / 1_000_000_000;
    let nanos_remainder = nanoseconds % 1_000_000_000;
    
    let dt = OffsetDateTime::from_unix_timestamp(seconds)
        .unwrap()
        .saturating_add(Duration::nanoseconds(nanos_remainder));
    
    format!("{:04}{:02}{:02}", 
        dt.year(), dt.month() as u8, dt.day())
}

fn format_datetime(time: u64) -> String {
    let nanoseconds = time as i64;
    let seconds = nanoseconds / 1_000_000_000;
    let nanos_remainder = nanoseconds % 1_000_000_000;
    
    let dt = OffsetDateTime::from_unix_timestamp(seconds)
        .unwrap()
        .saturating_add(Duration::nanoseconds(nanos_remainder));
    
    format!("{:04}{:02}{:02}T{:02}{:02}{:02}Z",
        dt.year(), dt.month() as u8, dt.day(),
        dt.hour(), dt.minute(), dt.second())
}

fn format_iso8601(time: u64) -> String {
    let nanoseconds = time as i64;
    let seconds = nanoseconds / 1_000_000_000;
    let nanos_remainder = nanoseconds % 1_000_000_000;
    
    let dt = OffsetDateTime::from_unix_timestamp(seconds)
        .unwrap()
        .saturating_add(Duration::nanoseconds(nanos_remainder));
    
    format!("{:04}-{:02}-{:02}T{:02}:{:02}:{:02}Z",
        dt.year(), dt.month() as u8, dt.day(),
        dt.hour(), dt.minute(), dt.second())
}

fn sign_policy(policy: &str, secret: &str, date: &str, region: &str) -> String {
    let date_key = hmac_sha256(
        format!("AWS4{}", secret).as_bytes(),
        date.as_bytes()
    );
    let region_key = hmac_sha256(&date_key, region.as_bytes());
    let service_key = hmac_sha256(&region_key, b"s3");
    let signing_key = hmac_sha256(&service_key, b"aws4_request");
    
    hex::encode(hmac_sha256(&signing_key, policy.as_bytes()))
}

fn hmac_sha256(key: &[u8], data: &[u8]) -> Vec<u8> {
    use hmac::{Hmac, Mac};
    use sha2::Sha256;
    
    type HmacSha256 = Hmac<Sha256>;
    let mut mac = HmacSha256::new_from_slice(key)
        .expect("HMAC can take key of any size");
    mac.update(data);
    mac.finalize().into_bytes().to_vec()
}



pub async fn copy_s3_object(
    source_key: &str,
    destination_key: &str, 
    auth: &AwsBucketAuth,
) -> Result<(), String> {
    let host = format!("{}.s3.{}.amazonaws.com", auth.bucket, auth.region);
    let current_time = ic_cdk::api::time();
    let date = format_date(current_time);
    let date_time = format_datetime(current_time);

    // Create the canonical request components for AWS Signature V4
    let credential = format!("{}/{}/{}/s3/aws4_request", 
        auth.access_key, date, auth.region);

    // Create copy source header
    let copy_source = format!("{}/{}", auth.bucket, source_key);
    
    // Construct the request headers
    let headers = vec![
        HttpHeader {
            name: "Host".to_string(),
            value: host.clone(),
        },
        HttpHeader {
            name: "x-amz-date".to_string(),
            value: date_time.clone(),
        },
        HttpHeader {
            name: "x-amz-copy-source".to_string(),
            value: copy_source.clone(),
        },
        HttpHeader {
            name: "x-amz-content-sha256".to_string(),
            value: "UNSIGNED-PAYLOAD".to_string(),
        },
    ];

    // Create canonical request
    let canonical_uri = format!("/{}", destination_key);
    let canonical_headers = format!(
        "host:{}\nx-amz-content-sha256:UNSIGNED-PAYLOAD\nx-amz-copy-source:{}\nx-amz-date:{}\n",
        host, copy_source, date_time
    );
    let signed_headers = "host;x-amz-content-sha256;x-amz-copy-source;x-amz-date";

    let canonical_request = format!("{}\n{}\n\n{}\n{}\n{}",
        "PUT",
        canonical_uri,
        canonical_headers,
        signed_headers,
        "UNSIGNED-PAYLOAD"
    );

    // Create string to sign
    let string_to_sign = format!(
        "AWS4-HMAC-SHA256\n{}\n{}/{}/s3/aws4_request\n{}",
        date_time,
        date,
        auth.region,
        hex::encode(sha256_hash(canonical_request.as_bytes()))
    );

    // Calculate signature
    let signature = sign_policy(&string_to_sign, &auth.secret_key, &date, &auth.region);

    // Create Authorization header
    let authorization = format!(
        "AWS4-HMAC-SHA256 Credential={},SignedHeaders={},Signature={}",
        credential, signed_headers, signature
    );

    // Add Authorization header to headers vec
    let mut final_headers = headers;
    final_headers.push(HttpHeader {
        name: "Authorization".to_string(),
        value: authorization,
    });

    // Create the HTTP request
    let request = CanisterHttpRequestArgument {
        url: format!("https://{}/{}", host, destination_key),
        method: HttpMethod::POST,
        headers: final_headers,
        body: None,
        max_response_bytes: Some(2048),
        transform: None,
    };

    // Make the HTTP request using IC management canister
    let cycles: u128 = 100_000_000_000;
    
    match http_request(request, cycles).await {
        Ok((response,)) => {
            let status_u16: u16 = response.status.0.to_u64() // Convert BigUint to u64 first
                .and_then(|n| {
                    if n <= u16::MAX as u64 {
                        Some(n as u16) // Safely narrow to u16
                    } else {
                        None // Handle overflow
                    }
                })
                .unwrap_or(500); // Fallback to 500 if conversion fails

            if status_u16 < 200 || status_u16 >= 300 {
                Err(format!("S3 copy failed with status {}: {}", 
                    status_u16,
                    String::from_utf8_lossy(&response.body)))
            } else {
                Ok(())
            }
        },
        Err((code, msg)) => Err(format!("HTTP request failed: {:?} - {}", code, msg))
    }
}

// src/core/api/actions.rs
use std::result::Result;

use crate::{core::{state::directory::{state::state::{file_uuid_to_metadata, folder_uuid_to_metadata}, types::{DriveFullFilePath, FileUUID, FolderUUID, PathTranslationResponse}}, types::{ICPPrincipalString, PublicKeyBLS, UserID}}, debug_log, rest::directory::types::{CreateFileResponse, DeleteFileResponse, DeleteFolderResponse, DirectoryAction, DirectoryActionEnum, DirectoryActionPayload, DirectoryActionResult}};

use super::{drive::drive::{copy_file, copy_folder, create_file, create_folder, delete_file, delete_folder, get_file_by_id, get_folder_by_id, move_file, move_folder, rename_file, rename_folder, restore_from_trash}, internals::drive_internals::{get_destination_folder, translate_path_to_id}};


#[derive(Debug, Clone)]
pub struct DirectoryActionErrorInfo {
    pub code: i32,
    pub message: String,
}

pub fn pipe_action(action: DirectoryAction, user_id: UserID) -> Result<DirectoryActionResult, DirectoryActionErrorInfo> {
    match action.action {
        DirectoryActionEnum::GetFile => {
            match action.payload {
                DirectoryActionPayload::GetFile(_) => {
                    // First try resource_id
                    if let Some(id) = action.target.resource_id {
                        match get_file_by_id(FileUUID(id)) {
                            Ok(file) => Ok(DirectoryActionResult::GetFile(file)),
                            Err(e) => Err(DirectoryActionErrorInfo {
                                code: 404,
                                message: format!("File not found by ID: {}", e)
                            })
                        }
                    }
                    // Then try resource_path
                    else if let Some(path) = action.target.resource_path {
                        let translation = translate_path_to_id(path);
                        match translation.file {
                            Some(file) => Ok(DirectoryActionResult::GetFile(file)),
                            None => Err(DirectoryActionErrorInfo {
                                code: 404,
                                message: "File not found at specified path".to_string()
                            })
                        }
                    } else {
                        Err(DirectoryActionErrorInfo {
                            code: 400,
                            message: "Neither resource_id nor resource_path provided".to_string()
                        })
                    }
                }
                _ => Err(DirectoryActionErrorInfo {
                    code: 400,
                    message: "Invalid payload for GET_FILE action".to_string()
                })
            }
        }
        
        DirectoryActionEnum::GetFolder => {
            match action.payload {
                DirectoryActionPayload::GetFolder(_) => {
                    // First try resource_id
                    if let Some(id) = action.target.resource_id {
                        match get_folder_by_id(FolderUUID(id)) {
                            Ok(folder) => Ok(DirectoryActionResult::GetFolder(folder)),
                            Err(e) => Err(DirectoryActionErrorInfo {
                                code: 404,
                                message: format!("Folder not found by ID: {}", e)
                            })
                        }
                    }
                    // Then try resource_path
                    else if let Some(path) = action.target.resource_path {
                        let translation = translate_path_to_id(path);
                        match translation.folder {
                            Some(folder) => Ok(DirectoryActionResult::GetFolder(folder)),
                            None => Err(DirectoryActionErrorInfo {
                                code: 404,
                                message: "Folder not found at specified path".to_string()
                            })
                        }
                    } else {
                        Err(DirectoryActionErrorInfo {
                            code: 400,
                            message: "Neither resource_id nor resource_path provided".to_string()
                        })
                    }
                }
                _ => Err(DirectoryActionErrorInfo {
                    code: 400,
                    message: "Invalid payload for GET_FOLDER action".to_string()
                })
            }
        }
        
        DirectoryActionEnum::CreateFile => {
            match action.payload {
                DirectoryActionPayload::CreateFile(payload) => {
                    // Determine the full file path.
                    // If the user provided a resource_path, we try to translate it.
                    // - If translation finds a folder, we use its full path.
                    // - Otherwise, we use the user’s resource_path as provided (ensuring it ends with a '/').
                    // If no resource_path is provided but a resource_id is,
                    // then we require that get_folder_by_id returns a valid folder.
                    let full_file_path = if let Some(user_resource_path) = action.target.resource_path {
                        let translation = translate_path_to_id(user_resource_path.clone());
                        if let Some(folder) = translation.folder {
                            let resulting_path = format!("{}/{}", folder.full_folder_path.0.trim_end_matches('/'), payload.name);
                            debug_log!("if full_file_path = {}", resulting_path);
                            resulting_path
                        } else {
                            // No folder found from the given path.
                            // That’s fine – let the drive API create parent folders.
                            let parent_path = if user_resource_path.to_string().ends_with('/') {
                                user_resource_path.to_string()
                            } else {
                                format!("{}/", user_resource_path)
                            };
                            let resulting_path = format!("{}{}", parent_path, payload.name);
                            debug_log!("else full_file_path = {}", resulting_path);
                            resulting_path
                        }
                    } else if let Some(id) = action.target.resource_id {
                        // For resource_id, a valid parent folder MUST be found.
                        let folder = get_folder_by_id(FolderUUID(id)).map_err(|e| DirectoryActionErrorInfo {
                            code: 404,
                            message: format!("Parent folder not found: {}", e)
                        })?;
                        let resulting_path = format!("{}/{}", folder.full_folder_path.0.trim_end_matches('/'), payload.name);
                        debug_log!("else if full_file_path = {}", resulting_path);
                        resulting_path
                    } else {
                        return Err(DirectoryActionErrorInfo {
                            code: 400,
                            message: "Neither resource_path nor resource_id provided for parent folder".to_string()
                        });
                    };

                    debug_log!("full_file_path = {}", full_file_path);
        
                    // Create file using the drive API.
                    match create_file(
                        full_file_path,
                        payload.disk_id,
                        user_id.clone(),
                        payload.file_size,
                        payload.expires_at.unwrap_or(-1),
                        String::new(), // Empty canister ID to use current canister
                        payload.file_conflict_resolution,
                    ) {
                        Ok((file_metadata, upload_response)) => {
                            Ok(DirectoryActionResult::CreateFile(CreateFileResponse {
                                file: file_metadata,
                                upload: upload_response,
                                notes: "File created successfully".to_string(),
                            }))
                        },
                        Err(e) => Err(DirectoryActionErrorInfo {
                            code: 500,
                            message: format!("Failed to create file: {}", e)
                        })
                    }
                }
                other => {
                    let error_msg = format!(
                        "Invalid payload for CREATE_FILE action. Expected CreateFile, got: {:?}",
                        other
                    );
                    ic_cdk::println!("Payload error: {}", error_msg);
                    Err(DirectoryActionErrorInfo {
                        code: 400,
                        message: error_msg
                    })
                }
            }
        }
        
        
        DirectoryActionEnum::CreateFolder => {
            match action.payload {
                DirectoryActionPayload::CreateFolder(payload) => {
                    // Get full folder path either from existing parent or construct from resource_path
                    let full_folder_path = if let Some(path) = action.target.resource_path {
                        match translate_path_to_id(path.clone()) {
                            PathTranslationResponse { folder: Some(folder), .. } => {
                                // Parent exists, construct path normally
                                DriveFullFilePath(format!("{}{}/", folder.full_folder_path.0, payload.name))
                            },
                            _ => {
                                // Parent doesn't exist, construct path from the provided resource_path
                                DriveFullFilePath(format!("{}{}/", path, payload.name))
                            }
                        }
                    } else if let Some(id) = action.target.resource_id {
                        match get_folder_by_id(FolderUUID(id)) {
                            Ok(folder) => DriveFullFilePath(format!("{}{}/", folder.full_folder_path.0, payload.name)),
                            Err(_) => return Err(DirectoryActionErrorInfo {
                                code: 404,
                                message: "Cannot create folder: parent folder ID not found".to_string()
                            })
                        }
                    } else {
                        return Err(DirectoryActionErrorInfo {
                            code: 400,
                            message: "Neither resource_path nor resource_id provided for parent folder".to_string()
                        });
                    };
        
                    // Create folder using the drive API
                    match create_folder(
                        full_folder_path,
                        payload.disk_id,
                        user_id.clone(),
                        payload.expires_at.unwrap_or(-1),
                        String::new(),
                        payload.file_conflict_resolution,
                    ) {
                        Ok(folder) => Ok(DirectoryActionResult::CreateFolder(folder)),
                        Err(e) => match e.as_str() {
                            "Folder already exists" => Err(DirectoryActionErrorInfo {
                                code: 409,
                                message: "A folder with this name already exists".to_string()
                            }),
                            _ => Err(DirectoryActionErrorInfo {
                                code: 500,
                                message: format!("Failed to create folder: {}", e)
                            })
                        }
                    }
                }
                _ => Err(DirectoryActionErrorInfo {
                    code: 400,
                    message: "Invalid payload for CREATE_FOLDER action".to_string()
                })
            }
        }
        
        DirectoryActionEnum::UpdateFile => {
            match action.payload {
                DirectoryActionPayload::UpdateFile(payload) => {
                    // Get the file ID from either resource_id or resource_path
                    let file_id = if let Some(id) = action.target.resource_id {
                        FileUUID(id)
                    } else if let Some(path) = action.target.resource_path {
                        let translation = translate_path_to_id(path);
                        match translation.file {
                            Some(file) => file.id,
                            None => return Err(DirectoryActionErrorInfo {
                                code: 404,
                                message: "File not found at specified path".to_string()
                            })
                        }
                    } else {
                        return Err(DirectoryActionErrorInfo {
                            code: 400,
                            message: "Neither resource_id nor resource_path provided".to_string()
                        });
                    };
        
                    // Get current file metadata
                    let file = match get_file_by_id(file_id.clone()) {
                        Ok(f) => f,
                        Err(e) => return Err(DirectoryActionErrorInfo {
                            code: 404,
                            message: format!("File not found: {}", e)
                        })
                    };
        
                    // Handle name update separately since it requires path updates
                    if let Some(new_name) = payload.name {
                        if new_name != file.name {
                            match rename_file(file_id.clone(), new_name) {
                                Ok(_) => (),
                                Err(e) => return Err(DirectoryActionErrorInfo {
                                    code: 500,
                                    message: format!("Failed to rename file: {}", e)
                                })
                            }
                        }
                    }
        
                    // Update other metadata fields directly
                    file_uuid_to_metadata.with_mut(|map| {
                        if let Some(file) = map.get_mut(&file_id) {
                            if let Some(tags) = payload.tags {
                                file.tags = tags;
                            }
                            if let Some(raw_url) = payload.raw_url {
                                file.raw_url = raw_url;
                            }
                            if let Some(expires_at) = payload.expires_at {
                                file.expires_at = expires_at;
                            }
                            file.last_updated_date_ms = ic_cdk::api::time() / 1_000_000;
                        }
                    });
        
                    // Get updated metadata to return
                    match get_file_by_id(file_id) {
                        Ok(updated_file) => Ok(DirectoryActionResult::UpdateFile(updated_file)),
                        Err(e) => Err(DirectoryActionErrorInfo {
                            code: 500,
                            message: format!("Failed to get updated file metadata: {}", e)
                        })
                    }
                }
                _ => Err(DirectoryActionErrorInfo {
                    code: 400,
                    message: "Invalid payload for UPDATE_FILE action".to_string()
                })
            }
        }
        
        DirectoryActionEnum::UpdateFolder => {
            match action.payload {
                DirectoryActionPayload::UpdateFolder(payload) => {
                    // Get the folder ID from either resource_id or resource_path
                    let folder_id = if let Some(id) = action.target.resource_id {
                        FolderUUID(id)
                    } else if let Some(path) = action.target.resource_path {
                        let translation = translate_path_to_id(path);
                        match translation.folder {
                            Some(folder) => folder.id,
                            None => return Err(DirectoryActionErrorInfo {
                                code: 404,
                                message: "Folder not found at specified path".to_string()
                            })
                        }
                    } else {
                        return Err(DirectoryActionErrorInfo {
                            code: 400,
                            message: "Neither resource_id nor resource_path provided".to_string()
                        });
                    };
        
                    // Get current folder metadata
                    let folder = match get_folder_by_id(folder_id.clone()) {
                        Ok(f) => f,
                        Err(e) => return Err(DirectoryActionErrorInfo {
                            code: 404,
                            message: format!("Folder not found: {}", e)
                        })
                    };
        
                    // Handle name update separately since it requires path updates
                    if let Some(new_name) = payload.name {
                        if new_name != folder.name {
                            match rename_folder(folder_id.clone(), new_name) {
                                Ok(_) => (),
                                Err(e) => return Err(DirectoryActionErrorInfo {
                                    code: 500,
                                    message: format!("Failed to rename folder: {}", e)
                                })
                            }
                        }
                    }
        
                    // Update other metadata fields directly
                    folder_uuid_to_metadata.with_mut(|map| {
                        if let Some(folder) = map.get_mut(&folder_id) {
                            if let Some(tags) = payload.tags {
                                folder.tags = tags;
                            }
                            if let Some(expires_at) = payload.expires_at {
                                folder.expires_at = expires_at;
                            }
                            folder.last_updated_date_ms = ic_cdk::api::time() / 1_000_000;
                        }
                    });
        
                    // Get updated metadata to return
                    match get_folder_by_id(folder_id) {
                        Ok(updated_folder) => Ok(DirectoryActionResult::UpdateFolder(updated_folder)),
                        Err(e) => Err(DirectoryActionErrorInfo {
                            code: 500,
                            message: format!("Failed to get updated folder metadata: {}", e)
                        })
                    }
                }
                _ => Err(DirectoryActionErrorInfo {
                    code: 400,
                    message: "Invalid payload for UPDATE_FOLDER action".to_string()
                })
            }
        }
        
        DirectoryActionEnum::DeleteFile => {
            match action.payload {
                DirectoryActionPayload::DeleteFile(payload) => {
                    // Get the file first to ensure it exists and get its metadata
                    let file_id = if let Some(id) = action.target.resource_id {
                        FileUUID(id)
                    } else if let Some(path) = action.target.resource_path {
                        let translation = translate_path_to_id(path);
                        match translation.file {
                            Some(file) => file.id,
                            None => return Err(DirectoryActionErrorInfo {
                                code: 404,
                                message: "File not found at specified path".to_string()
                            })
                        }
                    } else {
                        return Err(DirectoryActionErrorInfo {
                            code: 400,
                            message: "Neither resource_id nor resource_path provided".to_string()
                        });
                    };

                    // Get file metadata before deletion
                    let file = match get_file_by_id(file_id.clone()) {
                        Ok(f) => f,
                        Err(e) => return Err(DirectoryActionErrorInfo {
                            code: 404,
                            message: format!("File not found: {}", e)
                        })
                    };

                    // Perform deletion
                    match delete_file(&file_id, payload.permanent) {
                        Ok(path_to_trash) => Ok(DirectoryActionResult::DeleteFile(DeleteFileResponse {
                            file_id,
                            path_to_trash
                        })),
                        Err(e) => Err(DirectoryActionErrorInfo {
                            code: 500,
                            message: format!("Failed to delete file: {}", e)
                        })
                    }
                }
                _ => Err(DirectoryActionErrorInfo {
                    code: 400,
                    message: "Invalid payload for DELETE_FILE action".to_string()
                })
            }
        }
        
        DirectoryActionEnum::DeleteFolder => {
            match action.payload {
                DirectoryActionPayload::DeleteFolder(payload) => {
                    // Get the folder first to ensure it exists and get its metadata
                    let folder_id = if let Some(id) = action.target.resource_id {
                        FolderUUID(id)
                    } else if let Some(path) = action.target.resource_path {
                        let translation = translate_path_to_id(path);
                        match translation.folder {
                            Some(folder) => folder.id,
                            None => return Err(DirectoryActionErrorInfo {
                                code: 404,
                                message: "Folder not found at specified path".to_string()
                            })
                        }
                    } else {
                        return Err(DirectoryActionErrorInfo {
                            code: 400,
                            message: "Neither resource_id nor resource_path provided".to_string()
                        });
                    };

                    // Get folder metadata before deletion
                    let folder = match get_folder_by_id(folder_id.clone()) {
                        Ok(f) => f,
                        Err(e) => return Err(DirectoryActionErrorInfo {
                            code: 404,
                            message: format!("Folder not found: {}", e)
                        })
                    };

                    // Initialize vectors to collect deleted items
                    let mut deleted_files = Vec::with_capacity(2000);
                    let mut deleted_folders = Vec::with_capacity(2000);

                    // Perform deletion with collection vectors
                    match delete_folder(&folder_id, &mut deleted_folders, &mut deleted_files, payload.permanent) {
                        Ok(path_to_trash) => Ok(DirectoryActionResult::DeleteFolder(DeleteFolderResponse {
                            folder_id,
                            path_to_trash,
                            deleted_files: Some(deleted_files),
                            deleted_folders: Some(deleted_folders),
                        })),
                        Err(e) => Err(DirectoryActionErrorInfo {
                            code: 500,
                            message: format!("Failed to delete folder: {}", e)
                        })
                    }
                }
                _ => Err(DirectoryActionErrorInfo {
                    code: 400,
                    message: "Invalid payload for DELETE_FOLDER action".to_string()
                })
            }
        }
        
        DirectoryActionEnum::CopyFile => {
            match action.payload {
                DirectoryActionPayload::CopyFile(payload) => {
                    // Get the file ID from either resource_id or resource_path
                    let file_id = if let Some(id) = action.target.resource_id {
                        FileUUID(id)
                    } else if let Some(path) = action.target.resource_path {
                        let translation = translate_path_to_id(path);
                        match translation.file {
                            Some(file) => file.id,
                            None => return Err(DirectoryActionErrorInfo {
                                code: 404,
                                message: "Source file not found at specified path".to_string()
                            })
                        }
                    } else {
                        return Err(DirectoryActionErrorInfo {
                            code: 400,
                            message: "Neither resource_id nor resource_path provided for source file".to_string()
                        });
                    };

                    // get the file from directory state
                    let preexisting_file = file_uuid_to_metadata.get(&file_id).unwrap();
        
                    // Get destination folder
                    let destination_folder = match get_destination_folder(
                        payload.destination_folder_id,
                        payload.destination_folder_path,
                        preexisting_file.disk_id,
                        user_id,
                        preexisting_file.canister_id.to_string()
                    ) {
                        Ok(folder) => folder,
                        Err(e) => return Err(DirectoryActionErrorInfo {
                            code: 404,
                            message: format!("Destination folder not found: {}", e)
                        })
                    };
        
                    match copy_file(&file_id, &destination_folder, payload.file_conflict_resolution) {
                        Ok(file) => Ok(DirectoryActionResult::CopyFile(file)),
                        Err(e) => Err(DirectoryActionErrorInfo {
                            code: 500,
                            message: format!("Failed to copy file: {}", e)
                        })
                    }
                }
                _ => Err(DirectoryActionErrorInfo {
                    code: 400,
                    message: "Invalid payload for COPY_FILE action".to_string()
                })
            }
        }
        
        DirectoryActionEnum::CopyFolder => {
            match action.payload {
                DirectoryActionPayload::CopyFolder(payload) => {
                    // Get the folder ID from either resource_id or resource_path
                    let folder_id = if let Some(id) = action.target.resource_id {
                        FolderUUID(id)
                    } else if let Some(path) = action.target.resource_path {
                        let translation = translate_path_to_id(path);
                        match translation.folder {
                            Some(folder) => folder.id,
                            None => return Err(DirectoryActionErrorInfo {
                                code: 404,
                                message: "Source folder not found at specified path".to_string()
                            })
                        }
                    } else {
                        return Err(DirectoryActionErrorInfo {
                            code: 400,
                            message: "Neither resource_id nor resource_path provided for source folder".to_string()
                        });
                    };

                    let preexisting_folder = match get_folder_by_id(folder_id.clone()) {
                        Ok(f) => f,
                        Err(e) => return Err(DirectoryActionErrorInfo {
                            code: 404,
                            message: format!("Folder not found: {}", e)
                        })
                    };
        
                    // Get destination folder
                    let destination_folder = match get_destination_folder(
                        payload.destination_folder_id,
                        payload.destination_folder_path,
                        preexisting_folder.disk_id,
                        user_id,
                        preexisting_folder.canister_id.to_string()
                    ) {
                        Ok(folder) => folder,
                        Err(e) => return Err(DirectoryActionErrorInfo {
                            code: 404,
                            message: format!("Destination folder not found: {}", e)
                        })
                    };
        
                    match copy_folder(&folder_id, &destination_folder, payload.file_conflict_resolution) {
                        Ok(folder) => Ok(DirectoryActionResult::CopyFolder(folder)),
                        Err(e) => Err(DirectoryActionErrorInfo {
                            code: 500,
                            message: format!("Failed to copy folder: {}", e)
                        })
                    }
                }
                _ => Err(DirectoryActionErrorInfo {
                    code: 400,
                    message: "Invalid payload for COPY_FOLDER action".to_string()
                })
            }
        }
        
        DirectoryActionEnum::MoveFile => {
            match action.payload {
                DirectoryActionPayload::MoveFile(payload) => {
                    // Get the file ID from either resource_id or resource_path
                    let file_id = if let Some(id) = action.target.resource_id {
                        FileUUID(id)
                    } else if let Some(path) = action.target.resource_path {
                        let translation = translate_path_to_id(path);
                        match translation.file {
                            Some(file) => file.id,
                            None => return Err(DirectoryActionErrorInfo {
                                code: 404,
                                message: "Source file not found at specified path".to_string()
                            })
                        }
                    } else {
                        return Err(DirectoryActionErrorInfo {
                            code: 400,
                            message: "Neither resource_id nor resource_path provided for source file".to_string()
                        });
                    };

                    let preexisting_file = file_uuid_to_metadata.get(&file_id).unwrap();
        
                    // Get destination folder
                    let destination_folder = match get_destination_folder(
                        payload.destination_folder_id,
                        payload.destination_folder_path,
                        preexisting_file.disk_id,
                        user_id,
                        preexisting_file.canister_id.to_string()
                    ) {
                        Ok(folder) => folder,
                        Err(e) => return Err(DirectoryActionErrorInfo {
                            code: 404,
                            message: format!("Destination folder not found: {}", e)
                        })
                    };
        
                    match move_file(&file_id, &destination_folder, payload.file_conflict_resolution) {
                        Ok(file) => Ok(DirectoryActionResult::MoveFile(file)),
                        Err(e) => Err(DirectoryActionErrorInfo {
                            code: 500,
                            message: format!("Failed to move file: {}", e)
                        })
                    }
                }
                _ => Err(DirectoryActionErrorInfo {
                    code: 400,
                    message: "Invalid payload for MOVE_FILE action".to_string()
                })
            }
        }
        
        DirectoryActionEnum::MoveFolder => {
            match action.payload {
                DirectoryActionPayload::MoveFolder(payload) => {
                    // Get the folder ID from either resource_id or resource_path
                    let folder_id = if let Some(id) = action.target.resource_id {
                        FolderUUID(id)
                    } else if let Some(path) = action.target.resource_path {
                        let translation = translate_path_to_id(path);
                        match translation.folder {
                            Some(folder) => folder.id,
                            None => return Err(DirectoryActionErrorInfo {
                                code: 404,
                                message: "Source folder not found at specified path".to_string()
                            })
                        }
                    } else {
                        return Err(DirectoryActionErrorInfo {
                            code: 400,
                            message: "Neither resource_id nor resource_path provided for source folder".to_string()
                        });
                    };

                    // get the folder metadata
                    let preexisting_folder = match get_folder_by_id(folder_id.clone()) {
                        Ok(f) => f,
                        Err(e) => return Err(DirectoryActionErrorInfo {
                            code: 404,
                            message: format!("Folder not found: {}", e)
                        })
                    };
        
                    // Get destination folder
                    let destination_folder = match get_destination_folder(
                        payload.destination_folder_id,
                        payload.destination_folder_path,
                        preexisting_folder.disk_id,
                        user_id,
                        preexisting_folder.canister_id.to_string()
                    ) {
                        Ok(folder) => folder,
                        Err(e) => return Err(DirectoryActionErrorInfo {
                            code: 404,
                            message: format!("Destination folder not found: {}", e)
                        })
                    };
        
                    match move_folder(&folder_id, &destination_folder, payload.file_conflict_resolution) {
                        Ok(folder) => Ok(DirectoryActionResult::MoveFolder(folder)),
                        Err(e) => Err(DirectoryActionErrorInfo {
                            code: 500,
                            message: format!("Failed to move folder: {}", e)
                        })
                    }
                }
                _ => Err(DirectoryActionErrorInfo {
                    code: 400,
                    message: "Invalid payload for MOVE_FOLDER action".to_string()
                })
            }
        }
        
        DirectoryActionEnum::RestoreTrash => {
            match action.payload {
                DirectoryActionPayload::RestoreTrash(payload) => {
                    let resource_id = action.target.resource_id.ok_or_else(|| DirectoryActionErrorInfo {
                        code: 400,
                        message: "Resource ID is required for restore operation".to_string()
                    })?;
        
                    match restore_from_trash(&resource_id, &payload) {
                        Ok(result) => Ok(result),
                        Err(e) => Err(DirectoryActionErrorInfo {
                            code: 500,
                            message: format!("Failed to restore from trash: {}", e)
                        })
                    }
                }
                _ => Err(DirectoryActionErrorInfo {
                    code: 400,
                    message: "Invalid payload for RESTORE_TRASH action".to_string()
                })
            }
        }
    }
}

// src/core/api/internals.rs
pub mod drive_internals {
    use crate::{
        core::{api::{drive::drive::get_folder_by_id, uuid::generate_unique_id}, state::{directory::{state::state::{file_uuid_to_metadata, folder_uuid_to_metadata, full_file_path_to_uuid, full_folder_path_to_uuid}, types::{DriveFullFilePath, FileUUID, FolderMetadata, FolderUUID, PathTranslationResponse}}, disks::types::{AwsBucketAuth, DiskID, DiskTypeEnum}}, types::{ICPPrincipalString, PublicKeyBLS, UserID}}, debug_log, rest::directory::types::FileConflictResolutionEnum, 
        
    };
    
    use regex::Regex;

    pub fn sanitize_file_path(file_path: &str) -> String {
        let original = file_path.to_string();
        let mut parts = file_path.splitn(2, "::");
        let storage_part = parts.next().unwrap_or("");
        let path_part = parts.next().unwrap_or("");
    
        let sanitized = path_part.replace(':', ";");
        let re = Regex::new(r"/+").unwrap();
        let sanitized = re.replace_all(&sanitized, "/").to_string();
        let sanitized = sanitized.trim_matches('/').to_string();
    
        let final_path = format!("{}::{}", storage_part, sanitized);
        ic_cdk::println!("sanitize_file_path: {} -> {}", original, final_path);
        final_path
    }
    

    pub fn ensure_root_folder(disk_id: &DiskID, user_id: &UserID, canister_id: String,) -> FolderUUID {
        let root_path = DriveFullFilePath(format!("{}::", disk_id.to_string()));
        let canister_icp_principal_string = if canister_id.is_empty() {
            ic_cdk::api::id().to_text()
        } else {
            canister_id.clone()
        };
        let root_uuid = if let Some(uuid) = full_folder_path_to_uuid.get(&root_path) {
            uuid.clone()
        } else {
            let root_folder_uuid = generate_unique_id("FolderUUID", "");
            let root_folder = FolderMetadata {
                id: FolderUUID(root_folder_uuid.clone()),
                name: String::new(),
                parent_folder_uuid: None,
                restore_trash_prior_folder_path: None,
                subfolder_uuids: Vec::new(),
                file_uuids: Vec::new(),
                full_folder_path: root_path.clone(),
                tags: Vec::new(),
                created_by: user_id.clone(),
                created_date_ms: ic_cdk::api::time(),
                disk_id: disk_id.clone(),
                last_updated_date_ms: ic_cdk::api::time() / 1_000_000,
                last_updated_by: user_id.clone(),
                deleted: false,
                canister_id: ICPPrincipalString(PublicKeyBLS(canister_icp_principal_string.clone())),
                expires_at: -1,
            };
    
            full_folder_path_to_uuid.insert(root_path, FolderUUID(root_folder_uuid.clone()));
            folder_uuid_to_metadata.insert(FolderUUID(root_folder_uuid.clone()), root_folder);
            FolderUUID(root_folder_uuid)
        };

        // Ensure .trash folder exists
        let trash_path = DriveFullFilePath(format!("{}::.trash/", disk_id.to_string()));
        if !full_folder_path_to_uuid.contains_key(&trash_path) {
            let trash_folder_uuid = generate_unique_id("FolderUUID", "");
            let trash_folder = FolderMetadata {
                id: FolderUUID(trash_folder_uuid.clone()),
                name: ".trash".to_string(),
                parent_folder_uuid: Some(root_uuid.clone()),
                restore_trash_prior_folder_path: None,
                subfolder_uuids: Vec::new(),
                file_uuids: Vec::new(),
                full_folder_path: trash_path.clone(),
                tags: Vec::new(),
                created_by: user_id.clone(),
                created_date_ms: ic_cdk::api::time(),
                disk_id: disk_id.clone(),
                last_updated_date_ms: ic_cdk::api::time() / 1_000_000,
                last_updated_by: user_id.clone(),
                deleted: false,
                canister_id: ICPPrincipalString(PublicKeyBLS(canister_icp_principal_string)),
                expires_at: -1,
            };

            full_folder_path_to_uuid.insert(trash_path, FolderUUID(trash_folder_uuid.clone()));
            folder_uuid_to_metadata.insert(FolderUUID(trash_folder_uuid.clone()), trash_folder);
            
            // Add trash folder to root's subfolders
            folder_uuid_to_metadata.with_mut(|map| {
                if let Some(root_folder) = map.get_mut(&root_uuid) {
                    root_folder.subfolder_uuids.push(FolderUUID(trash_folder_uuid));
                }
            });
        }

        root_uuid
    }

    pub fn update_subfolder_paths(folder_id: &FolderUUID, old_path: &str, new_path: &str) {
        // Get folder metadata first
        let folder = match folder_uuid_to_metadata.get(folder_id) {
            Some(f) => f,
            None => return,
        };
    
        // Clone the vectors we need to iterate over to avoid borrowing issues
        let subfolder_uuids = folder.subfolder_uuids.clone();
        let file_uuids = folder.file_uuids.clone();
    
        // Update subfolders
        for subfolder_id in &subfolder_uuids {
            // Get old path before updating
            let old_subfolder_path = if let Some(subfolder) = folder_uuid_to_metadata.get(subfolder_id) {
                subfolder.full_folder_path.clone()
            } else {
                continue;
            };
    
            let new_subfolder_path = DriveFullFilePath(old_subfolder_path.to_string().replace(old_path, new_path));
            
            // Update folder metadata
            folder_uuid_to_metadata.with_mut(|map| {
                if let Some(subfolder) = map.get_mut(subfolder_id) {
                    subfolder.full_folder_path = new_subfolder_path.clone();
                }
            });
            
            // Update path mappings
            full_folder_path_to_uuid.remove(&old_subfolder_path);
            full_folder_path_to_uuid.insert(new_subfolder_path.clone(), subfolder_id.clone());
            
            // Recursively update paths for this subfolder
            update_subfolder_paths(subfolder_id, &old_subfolder_path.to_string(), &new_subfolder_path.to_string());
        }
    
        // Update file paths
        for file_id in &file_uuids {
            // Get old path before updating
            let old_file_path = if let Some(file) = file_uuid_to_metadata.get(file_id) {
                file.full_file_path.clone()
            } else {
                continue;
            };
    
            let new_file_path = DriveFullFilePath(old_file_path.to_string().replace(old_path, new_path));
            
            // Update file metadata
            file_uuid_to_metadata.with_mut(|map| {
                if let Some(file) = map.get_mut(file_id) {
                    file.full_file_path = new_file_path.clone();
                }
            });
            
            // Update path mappings
            full_file_path_to_uuid.remove(&old_file_path);
            full_file_path_to_uuid.insert(new_file_path, file_id.clone());
        }
    }

    pub fn ensure_folder_structure(
        folder_path: &str,
        disk_id: DiskID,
        user_id: UserID,
        canister_id: String,
    ) -> FolderUUID {
        let path_parts: Vec<&str> = folder_path.split("::").collect();
        let mut current_path = format!("{}::", path_parts[0]);

        let canister_icp_principal_string = if canister_id.is_empty() {
            ic_cdk::api::id().to_text()
        } else {
            canister_id.clone()
        };

        let mut parent_uuid = ensure_root_folder(&disk_id, &user_id, canister_icp_principal_string.clone());

        for part in path_parts[1].split('/').filter(|&p| !p.is_empty()) {
            current_path = format!("{}{}/", current_path.clone(), part);
            
            if !full_folder_path_to_uuid.contains_key(&DriveFullFilePath(current_path.clone())) {
                let new_folder_uuid = FolderUUID(generate_unique_id("FolderUUID",""));
                let new_folder = FolderMetadata {
                    id: new_folder_uuid.clone(),
                    name: part.to_string(),
                    parent_folder_uuid: Some(parent_uuid.clone()),
                    subfolder_uuids: Vec::new(),
                    file_uuids: Vec::new(),
                    full_folder_path: DriveFullFilePath(current_path.clone()),
                    tags: Vec::new(),
                    created_by: user_id.clone(),
                    created_date_ms: ic_cdk::api::time(),
                    disk_id: disk_id.clone(),
                    last_updated_date_ms: ic_cdk::api::time() / 1_000_000,
                    last_updated_by: user_id.clone(),
                    deleted: false,
                    canister_id: ICPPrincipalString(PublicKeyBLS(canister_icp_principal_string.clone())),
                    expires_at: -1,
                    restore_trash_prior_folder_path: None,
                };

                full_folder_path_to_uuid.insert(DriveFullFilePath(current_path.clone()), new_folder_uuid.clone());
                folder_uuid_to_metadata.insert(new_folder_uuid.clone(), new_folder);

                // Update parent folder's subfolder_uuids
                folder_uuid_to_metadata.with_mut(|map| {
                    if let Some(parent_folder) = map.get_mut(&parent_uuid) {
                        if !parent_folder.subfolder_uuids.contains(&new_folder_uuid) {
                            parent_folder.subfolder_uuids.push(new_folder_uuid.clone());
                        }
                    }
                });

                parent_uuid = new_folder_uuid;
            } else {
                parent_uuid = full_folder_path_to_uuid.get(&DriveFullFilePath(current_path.clone()))
                    .expect("Folder UUID not found")
                    .clone();
            }
        }

            

        parent_uuid
    }

    pub fn split_path(full_path: &str) -> (String, String) {
        let original = full_path.to_string();
        let parts: Vec<&str> = full_path.rsplitn(2, '/').collect();
        let (folder, filename) = match parts.as_slice() {
            [file_name, folder_path] => (folder_path.to_string(), file_name.to_string()),
            [single_part] => {
                let storage_parts: Vec<&str> = single_part.splitn(2, "::").collect();
                match storage_parts.as_slice() {
                    [storage, file_name] => (format!("{}::", storage), file_name.to_string()),
                    _ => (String::new(), single_part.to_string()),
                }
            },
            _ => (String::new(), String::new()),
        };
        ic_cdk::println!("split_path: {} -> ({}, {})", original, folder, filename);
        (folder, filename)
    }
    

    pub fn update_folder_file_uuids(folder_uuid: &FolderUUID, file_uuid: &FileUUID, is_add: bool) {
        folder_uuid_to_metadata.with_mut(|map| {
            if let Some(folder) = map.get_mut(folder_uuid) {
                if is_add {
                    if !folder.file_uuids.contains(file_uuid) {
                        folder.file_uuids.push(file_uuid.clone());
                    }
                } else {
                    folder.file_uuids.retain(|uuid| uuid != file_uuid);
                }
            }
        });
    }
    
    pub fn translate_path_to_id(path: DriveFullFilePath) -> PathTranslationResponse {
        // Check if path ends with '/' to determine if we're looking for a folder
        let is_folder_path = path.0.ends_with('/');
        
        let mut response = PathTranslationResponse {
            folder: None,
            file: None,
        };

        if is_folder_path {
            // Look up folder UUID first
            if let Some(folder_uuid) = full_folder_path_to_uuid.get(&path) {
                // Then get the folder metadata
                response.folder = folder_uuid_to_metadata.get(&folder_uuid);
            }
        } else {
            // Look up file UUID first
            if let Some(file_uuid) = full_file_path_to_uuid.get(&path) {
                // Then get the file metadata
                response.file = file_uuid_to_metadata.get(&file_uuid);
            }
        }

        response
    }

    pub fn format_file_asset_path (
        file_uuid: FileUUID,
        extension: String,
    ) -> String {
        format!(
            "https://{}.raw.icp0.io/directory/asset/{file_uuid}.{extension}",
            ic_cdk::api::id().to_text()
        )
    }

    pub fn resolve_naming_conflict(
        base_path: &str,
        name: &str,
        is_folder: bool,
        resolution: Option<FileConflictResolutionEnum>,
    ) -> (String, String) {
        // Start with the initial name and computed full path.
        let mut final_name = name.to_string();
        let mut final_path = if is_folder {
            format!("{}/{}/", base_path.trim_end_matches('/'), final_name)
        } else {
            format!("{}/{}", base_path.trim_end_matches('/'), final_name)
        };
    
        debug_log!(
            "resolve_naming_conflict: initial base_path: '{}', name: '{}', is_folder: {} -> final_name: '{}', final_path: '{}'",
            base_path, name, is_folder, final_name, final_path
        );
    
        match resolution.unwrap_or(FileConflictResolutionEnum::KEEP_BOTH) {
            FileConflictResolutionEnum::REPLACE => {
                debug_log!(
                    "resolve_naming_conflict: Using REPLACE. Returning final_name: '{}' and final_path: '{}'",
                    final_name,
                    final_path
                );
                (final_name, final_path)
            },
            FileConflictResolutionEnum::KEEP_ORIGINAL => {
                if (is_folder && full_folder_path_to_uuid.contains_key(&DriveFullFilePath(final_path.clone())))
                    || (!is_folder && full_file_path_to_uuid.contains_key(&DriveFullFilePath(final_path.clone())))
                {
                    debug_log!(
                        "resolve_naming_conflict (KEEP_ORIGINAL): Conflict found for final_path: '{}'. Returning empty strings to keep original.",
                        final_path
                    );
                    return (String::new(), String::new()); // Signal to keep original
                }
                debug_log!(
                    "resolve_naming_conflict (KEEP_ORIGINAL): No conflict for final_path: '{}'. Returning final_name: '{}' and final_path: '{}'",
                    final_path, final_name, final_path
                );
                (final_name, final_path)
            },
            FileConflictResolutionEnum::KEEP_NEWER => {
                debug_log!(
                    "resolve_naming_conflict: Using KEEP_NEWER. Returning final_name: '{}' and final_path: '{}'",
                    final_name,
                    final_path
                );
                (final_name, final_path)
            },
            FileConflictResolutionEnum::KEEP_BOTH => {
                let mut counter = 1;
                while (is_folder && full_folder_path_to_uuid.contains_key(&DriveFullFilePath(final_path.clone())))
                    || (!is_folder && full_file_path_to_uuid.contains_key(&DriveFullFilePath(final_path.clone())))
                {
                    debug_log!(
                        "resolve_naming_conflict (KEEP_BOTH): Conflict for final_path: '{}'. Counter: {}",
                        final_path,
                        counter
                    );
                    counter += 1;
    
                    // Split name and extension for files.
                    let (base_name, ext) = if !is_folder && name.contains('.') {
                        let parts: Vec<&str> = name.rsplitn(2, '.').collect();
                        (parts[1], parts[0])
                    } else {
                        (name, "")
                    };
    
                    final_name = if ext.is_empty() {
                        format!("{} ({})", base_name, counter)
                    } else {
                        format!("{} ({}).{}", base_name, counter, ext)
                    };
    
                    final_path = if is_folder {
                        format!("{}/{}/", base_path.trim_end_matches('/'), final_name)
                    } else {
                        format!("{}/{}", base_path.trim_end_matches('/'), final_name)
                    };
    
                    debug_log!(
                        "resolve_naming_conflict (KEEP_BOTH): New computed final_name: '{}', final_path: '{}'",
                        final_name,
                        final_path
                    );
                }
                debug_log!(
                    "resolve_naming_conflict (KEEP_BOTH): Final resolved final_name: '{}', final_path: '{}'",
                    final_name,
                    final_path
                );
                (final_name, final_path)
            }
        }
    }
    
    

    // Helper function to get destination folder from either ID or path
    pub fn get_destination_folder(
        folder_id: Option<FolderUUID>, 
        folder_path: Option<DriveFullFilePath>,
        disk_id: DiskID,
        user_id: UserID,
        canister_id: String,
    ) -> Result<FolderMetadata, String> {
        if let Some(id) = folder_id {
            folder_uuid_to_metadata
                .get(&id)
                .clone()
                .ok_or_else(|| "Destination folder not found".to_string())
        } else if let Some(path) = folder_path {
            let translation = translate_path_to_id(path.clone());
            if let Some(folder) = translation.folder {
                Ok(folder)
            } else {
                // Folder not found at the given path; create the folder structure.
                let new_folder_uuid = ensure_folder_structure(
                    &path.to_string(),
                    disk_id,
                    user_id,
                    canister_id,
                );
                // Retrieve the folder metadata using the new UUID.
                get_folder_by_id(new_folder_uuid)
            }
        } else {
            Err("Neither destination folder ID nor path provided".to_string())
        }
    }
    

    /// Validates that if the disk type is AwsBucket or StorjWeb3,
    /// then auth_json is provided and can be deserialized into AwsBucketAuth.
    pub fn validate_auth_json(disk_type: &DiskTypeEnum, auth_json: &Option<String>) -> Result<(), String> {
        if *disk_type == DiskTypeEnum::AwsBucket || *disk_type == DiskTypeEnum::StorjWeb3 {
            match auth_json {
                Some(json_str) => {
                    // Try to parse the provided JSON string into AwsBucketAuth.
                    serde_json::from_str::<AwsBucketAuth>(json_str)
                        .map_err(|e| format!("Invalid auth_json for {}: {}", disk_type, e))?;
                    Ok(())
                },
                None => Err(format!("auth_json is required for disk type {}", disk_type)),
            }
        } else {
            Ok(())
        }
    }

}


use std::fmt;

// src/core/state/directory/types.rs
use serde::{Serialize, Deserialize};

use crate::core::{state::disks::types::{DiskID, DiskTypeEnum}, types::{ICPPrincipalString, UserID}};


#[derive(Debug, Clone, PartialEq, Eq, Hash, Serialize, Deserialize)]
pub struct FolderUUID(pub String);
impl fmt::Display for FolderUUID {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        write!(f, "{}", self.0)
    }
}

#[derive(Debug, Clone, PartialEq, Eq, Hash, Serialize, Deserialize)]
pub struct FileUUID(pub String);
impl fmt::Display for FileUUID {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        write!(f, "{}", self.0)
    }
}

#[derive(Debug, Clone, PartialEq, Eq, Hash, Serialize, Deserialize)]
pub struct DriveFullFilePath(pub String);
impl fmt::Display for DriveFullFilePath {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        write!(f, "{}", self.0)
    }
}

#[derive(Debug, Clone, PartialEq, Eq, Hash, Serialize, Deserialize)]
pub struct Tag(pub String);





#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FolderMetadata {
    pub(crate) id: FolderUUID,
    pub(crate) name: String,
    pub(crate) parent_folder_uuid: Option<FolderUUID>,
    pub(crate) subfolder_uuids: Vec<FolderUUID>,
    pub(crate) file_uuids: Vec<FileUUID>,
    pub(crate) full_folder_path: DriveFullFilePath,
    pub(crate) tags: Vec<Tag>,
    pub(crate) created_by: UserID,
    pub(crate) created_date_ms: u64, // unix ms
    pub(crate) last_updated_date_ms: u64,  // unix ms
    pub(crate) last_updated_by: UserID,
    pub(crate) disk_id: DiskID,
    pub(crate) deleted: bool,
    pub(crate) expires_at: i64,
    pub(crate) canister_id: ICPPrincipalString,
    pub(crate) restore_trash_prior_folder_path: Option<DriveFullFilePath>,
}


#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct FileMetadata {
    pub(crate) id: FileUUID,
    pub(crate) name: String,
    pub(crate) folder_uuid: FolderUUID,
    pub(crate) file_version: u32,
    pub(crate) prior_version: Option<FileUUID>,
    pub(crate) next_version: Option<FileUUID>,
    pub(crate) extension: String,
    pub(crate) full_file_path: DriveFullFilePath,
    pub(crate) tags: Vec<Tag>,
    pub(crate) created_by: UserID,
    pub(crate) created_date_ms: u64, // unix ms
    pub(crate) disk_id: DiskID,
    pub(crate) disk_type: DiskTypeEnum,
    pub(crate) file_size: u64,
    pub(crate) raw_url: String,
    pub(crate) last_updated_date_ms: u64,  // unix ms
    pub(crate) last_updated_by: UserID,
    pub(crate) deleted: bool,
    pub(crate) canister_id: ICPPrincipalString,
    pub(crate) expires_at: i64,
    pub(crate) restore_trash_prior_folder_path: Option<DriveFullFilePath>,
}




#[derive(Serialize, Deserialize, Debug)]
pub struct PathTranslationResponse {
    pub folder: Option<FolderMetadata>,
    pub file: Option<FileMetadata>,
}





// src/core/state/directory/state.rs

pub mod state {
    use std::cell::{RefCell, RefMut};
    use std::collections::HashMap;
    use std::ops::Deref;

    use crate::core::state::{
        directory::types::{DriveFullFilePath, FileMetadata, FileUUID, FolderMetadata, FolderUUID},
        templates::types::{TemplateID, TemplateItem},
    };

    // Wrapper types that implement Deref
    pub struct FolderMap;
    pub struct FileMap;
    pub struct FolderPathMap;
    pub struct FilePathMap;

    impl FolderMap {
        pub fn get(&self, key: &FolderUUID) -> Option<FolderMetadata> {
            folder_uuid_to_metadata_inner.with(|map| map.borrow().get(key).cloned())
        }

        pub fn insert(&self, key: FolderUUID, value: FolderMetadata) {
            folder_uuid_to_metadata_inner.with(|map| map.borrow_mut().insert(key, value));
        }

        pub fn with_mut<R>(&self, f: impl FnOnce(&mut HashMap<FolderUUID, FolderMetadata>) -> R) -> R {
            folder_uuid_to_metadata_inner.with(|map| f(&mut map.borrow_mut()))
        }
    
        pub fn contains_key(&self, key: &FolderUUID) -> bool {
            folder_uuid_to_metadata_inner.with(|map| map.borrow().contains_key(key))
        }
    
        pub fn remove(&self, key: &FolderUUID) -> Option<FolderMetadata> {
            folder_uuid_to_metadata_inner.with(|map| map.borrow_mut().remove(key))
        }
    }

    impl FileMap {
        pub fn get(&self, key: &FileUUID) -> Option<FileMetadata> {
            file_uuid_to_metadata_inner.with(|map| map.borrow().get(key).cloned())
        }

        pub fn insert(&self, key: FileUUID, value: FileMetadata) {
            file_uuid_to_metadata_inner.with(|map| map.borrow_mut().insert(key, value));
        }

        pub fn with_mut<R>(&self, f: impl FnOnce(&mut HashMap<FileUUID, FileMetadata>) -> R) -> R {
            file_uuid_to_metadata_inner.with(|map| f(&mut map.borrow_mut()))
        }
    
        pub fn contains_key(&self, key: &FileUUID) -> bool {
            file_uuid_to_metadata_inner.with(|map| map.borrow().contains_key(key))
        }
    
        pub fn remove(&self, key: &FileUUID) -> Option<FileMetadata> {
            file_uuid_to_metadata_inner.with(|map| map.borrow_mut().remove(key))
        }
    }

    impl FolderPathMap {
        pub fn get(&self, key: &DriveFullFilePath) -> Option<FolderUUID> {
            full_folder_path_to_uuid_inner.with(|map| map.borrow().get(key).cloned())
        }

        pub fn insert(&self, key: DriveFullFilePath, value: FolderUUID) {
            full_folder_path_to_uuid_inner.with(|map| map.borrow_mut().insert(key, value));
        }

        pub fn with_mut<R>(&self, f: impl FnOnce(&mut HashMap<DriveFullFilePath, FolderUUID>) -> R) -> R {
            full_folder_path_to_uuid_inner.with(|map| f(&mut map.borrow_mut()))
        }

        pub fn contains_key(&self, key: &DriveFullFilePath) -> bool {
            full_folder_path_to_uuid_inner.with(|map| map.borrow().contains_key(key))
        }
    
        pub fn remove(&self, key: &DriveFullFilePath) -> Option<FolderUUID> {
            full_folder_path_to_uuid_inner.with(|map| map.borrow_mut().remove(key))
        }
    }

    impl FilePathMap {
        pub fn get(&self, key: &DriveFullFilePath) -> Option<FileUUID> {
            full_file_path_to_uuid_inner.with(|map| map.borrow().get(key).cloned())
        }

        pub fn insert(&self, key: DriveFullFilePath, value: FileUUID) {
            full_file_path_to_uuid_inner.with(|map| map.borrow_mut().insert(key, value));
        }

        pub fn with_mut<R>(&self, f: impl FnOnce(&mut HashMap<DriveFullFilePath, FileUUID>) -> R) -> R {
            full_file_path_to_uuid_inner.with(|map| f(&mut map.borrow_mut()))
        }
    
        pub fn contains_key(&self, key: &DriveFullFilePath) -> bool {
            full_file_path_to_uuid_inner.with(|map| map.borrow().contains_key(key))
        }
    
        pub fn remove(&self, key: &DriveFullFilePath) -> Option<FileUUID> {
            full_file_path_to_uuid_inner.with(|map| map.borrow_mut().remove(key))
        }
    }

    // Private thread_local storage
    thread_local! {
        static folder_uuid_to_metadata_inner: RefCell<HashMap<FolderUUID, FolderMetadata>> = RefCell::new(HashMap::new());
        static file_uuid_to_metadata_inner: RefCell<HashMap<FileUUID, FileMetadata>> = RefCell::new(HashMap::new());
        static full_folder_path_to_uuid_inner: RefCell<HashMap<DriveFullFilePath, FolderUUID>> = RefCell::new(HashMap::new());
        static full_file_path_to_uuid_inner: RefCell<HashMap<DriveFullFilePath, FileUUID>> = RefCell::new(HashMap::new());
    }

    // Public instances with original names
    pub static folder_uuid_to_metadata: FolderMap = FolderMap;
    pub static file_uuid_to_metadata: FileMap = FileMap;
    pub static full_folder_path_to_uuid: FolderPathMap = FolderPathMap;
    pub static full_file_path_to_uuid: FilePathMap = FilePathMap;
}


// src/rest/directory/handler.rs


pub mod directorys_handlers {
    use crate::{
        core::{api::{disks::aws_s3::{generate_s3_upload_url, generate_s3_view_url}, drive::drive::fetch_files_at_folder_path, uuid::generate_unique_id}, state::{directory::{state::state::file_uuid_to_metadata, types::FileUUID}, disks::{state::state::DISKS_BY_ID_HASHTABLE, types::{AwsBucketAuth, DiskID, DiskTypeEnum}}, drives::state::state::OWNER_ID, raw_storage::{state::{get_file_chunks, store_chunk, store_filename, FILE_META}, types::{ChunkId, FileChunk, CHUNK_SIZE}}}}, debug_log, rest::{auth::{authenticate_request, create_auth_error_response, create_raw_upload_error_response}, directory::types::{ClientSideUploadRequest, ClientSideUploadResponse, CompleteUploadRequest, CompleteUploadResponse, DirectoryAction, DirectoryActionError, DirectoryActionOutcome, DirectoryActionOutcomeID, DirectoryActionRequestBody, DirectoryActionResponse, DirectoryListResponse, ErrorResponse, FileMetadataResponse, ListDirectoryRequest, UploadChunkRequest, UploadChunkResponse}}, 
        
    };
    
    use ic_http_certification::{HttpRequest, HttpResponse, StatusCode};
    use matchit::Params;
    use serde::Deserialize;
    use urlencoding::decode;
    #[derive(Deserialize, Default)]
    struct ListQueryParams {
        title: Option<String>,
        completed: Option<bool>,
    }

    pub fn search_directory_handler(request: &HttpRequest, _params: &Params) -> HttpResponse<'static> {
        let requester_api_key = match authenticate_request(request) {
            Some(key) => key,
            None => return create_auth_error_response(),
        };
    
        let is_owner = OWNER_ID.with(|owner_id| requester_api_key.user_id == *owner_id);
        if !is_owner {
            return create_auth_error_response();
        }
    
        let response = DirectoryListResponse {
            folders: Vec::new(),
            files: Vec::new(),
            total_folders: 0,
            total_files: 0,
            cursor: None,
        };
    
        create_response(
            StatusCode::OK,
            serde_json::to_vec(&response).expect("Failed to serialize response")
        )
    }

    pub fn list_directorys_handler(request: &HttpRequest, _params: &Params) -> HttpResponse<'static> {
        // Authenticate request
        let requester_api_key = match authenticate_request(request) {
            Some(key) => key,
            None => return create_auth_error_response(),
        };
    
        // Only owner can access directories
        let is_owner = OWNER_ID.with(|owner_id| requester_api_key.user_id == *owner_id);
        if !is_owner {
            return create_auth_error_response();
        }
    
        // Parse request body
        let list_request: ListDirectoryRequest = match serde_json::from_slice(request.body()) {
            Ok(req) => req,
            Err(_) => return create_response(
                StatusCode::BAD_REQUEST,
                ErrorResponse::err(400, "Invalid request format".to_string()).encode()
            ),
        };
    
        match fetch_files_at_folder_path(list_request) {
            Ok(response) => create_response(
                StatusCode::OK,
                serde_json::to_vec(&response).expect("Failed to serialize response")
            ),
            Err(err) => create_response(
                StatusCode::NOT_FOUND,
                ErrorResponse::err(404, format!("Failed to list directory: {:?}", err)).encode()
            )
        }
    }

    pub fn action_directory_handler(request: &HttpRequest, _params: &Params) -> HttpResponse<'static> {
        let requester_api_key = match authenticate_request(request) {
            Some(key) => key,
            None => return create_auth_error_response(),
        };
    
        let is_owner = OWNER_ID.with(|owner_id| requester_api_key.user_id == *owner_id);
        if !is_owner {
            return create_auth_error_response();
        }
    
        let action_batch: DirectoryActionRequestBody = match serde_json::from_slice(request.body()) {
            Ok(req) => req,
            Err(_) => return create_response(
                StatusCode::BAD_REQUEST,
                ErrorResponse::err(400, "Invalid request format".to_string()).encode()
            ),
        };
    
        let mut outcomes = Vec::new();
        
        for action in action_batch.actions {
            let outcome_id = DirectoryActionOutcomeID(generate_unique_id("DirectoryActionOutcomeID", ""));
            let outcome = match crate::core::api::actions::pipe_action(action.clone(), requester_api_key.user_id.clone()) {
                Ok(result) => DirectoryActionOutcome {
                    id: outcome_id,
                    success: true,
                    request: DirectoryAction {
                        action: action.action,
                        target: action.target,
                        payload: action.payload,
                    },
                    response: DirectoryActionResponse {
                        result: Some(result),
                        error: None,
                    }
                },
                Err(error_info) => DirectoryActionOutcome {
                    id: outcome_id,
                    success: false,
                    request: DirectoryAction {
                        action: action.action,
                        target: action.target,
                        payload: action.payload,
                    },
                    response: DirectoryActionResponse {
                        result: None,
                        error: Some(DirectoryActionError {
                            code: error_info.code,
                            message: error_info.message,
                        }),
                    }
                },
            };
            outcomes.push(outcome);
        }
    
        create_response(
            StatusCode::OK,
            serde_json::to_vec(&outcomes).expect("Failed to serialize response")
        )
    }

    pub fn handle_upload_chunk(req: &HttpRequest, _: &Params) -> HttpResponse<'static> {
        debug_log!("Handling upload chunk request");

        let upload_req: UploadChunkRequest = match serde_json::from_slice(req.body()) {
            Ok(req) => req,
            Err(_) => {
                debug_log!("handle_upload_chunk: Failed to deserialize request");
                return create_raw_upload_error_response("Invalid request format")
            }
        };

        debug_log!("handle_upload_chunk: Handling chunk upload");
        debug_log!("  file_id      = {}", upload_req.file_id);
        debug_log!("  chunk_index  = {}", upload_req.chunk_index);
        debug_log!("  total_chunks = {}", upload_req.total_chunks);
        debug_log!("  chunk_size   = {}", upload_req.chunk_data.len());
    
        if upload_req.chunk_data.len() > CHUNK_SIZE {
            return create_raw_upload_error_response("Chunk too large");
        }
    
        let chunk_id = ChunkId(format!("{}-{}", upload_req.file_id, upload_req.chunk_index));
        
        let chunk = FileChunk {
            id: chunk_id.clone(),
            file_id: upload_req.file_id,
            chunk_index: upload_req.chunk_index,
            data: upload_req.chunk_data.clone(),
            size: upload_req.chunk_data.len()
        };
        debug_log!("handle_upload_chunk: Storing chunk {:?}", chunk.id);
    
        store_chunk(chunk);
    
        let response = UploadChunkResponse {
            chunk_id: chunk_id.0,
            bytes_received: upload_req.chunk_data.len()
        };
    
        debug_log!("handle_upload_chunk: Successfully stored chunk");
        create_success_response(&response)
    }
    
    pub fn handle_complete_upload(req: &HttpRequest, _: &Params) -> HttpResponse<'static> {
        let complete_req: CompleteUploadRequest = match serde_json::from_slice(req.body()) {
            Ok(req) => req,
            Err(_) => return create_raw_upload_error_response("Invalid request format")
        };
        debug_log!("handle_complete_upload: Completing upload");
        debug_log!("  file_id = {}", complete_req.file_id);

        store_filename(&complete_req.file_id, &complete_req.filename);
    
        let chunks = get_file_chunks(&complete_req.file_id);
        debug_log!("handle_complete_upload: Found {} chunks", chunks.len());

        let total_size: usize = chunks.iter().map(|c| c.size).sum();
        debug_log!("handle_complete_upload: Total size = {} bytes", total_size);
    
        let response = CompleteUploadResponse {
            file_id: complete_req.file_id,
            size: total_size,
            chunks: chunks.len() as u32,
            filename: complete_req.filename
        };
         debug_log!("handle_complete_upload: Returning final response with size={} chunks={}", response.size, response.chunks);
    
        create_success_response(&response)
    }

    /// Returns the metadata about a file: total size, total chunks, etc.
    pub fn download_file_metadata_handler(req: &HttpRequest, _: &Params) -> HttpResponse<'static> {
        debug_log!("download_file_metadata_handler: Handling file metadata request");

        // // 1. Optionally authenticate, if required
        // let requester_api_key = match authenticate_request(req) {
        //     Some(key) => key,
        //     None => return create_auth_error_response(),
        // };

        // // 2. Check if user is owner, if that's your policy
        // let is_owner = OWNER_ID.with(|owner_id| requester_api_key.user_id == *owner_id);
        // if !is_owner {
        //     return create_auth_error_response();
        // }

        // 3. Parse query string for file_id
        let raw_query_string = req.get_query().unwrap_or(Some("".to_string()));
        let query_string = raw_query_string.as_deref().unwrap_or("");
        let query_map = crate::rest::helpers::parse_query_string(&query_string);

        let file_id = match query_map.get("file_id") {
            Some(fid) => fid,
            None => {
                return create_response(
                    StatusCode::BAD_REQUEST,
                    ErrorResponse::err(400, "Missing file_id in query".to_string()).encode()
                );
            }
        };
        let file_id = decode(file_id).unwrap_or_else(|_| file_id.into());

        debug_log!("download_file_metadata_handler: file_id={}", file_id);

        // 4. Collect chunks for this file, if any
        let mut chunks = get_file_chunks(&file_id);
        if chunks.is_empty() {
            return create_response(
                StatusCode::NOT_FOUND,
                ErrorResponse::err(404, "File not found".to_string()).encode()
            );
        }

        // 5. Sort by chunk index and compute total size
        chunks.sort_by_key(|c| c.chunk_index);
        let total_size: usize = chunks.iter().map(|c| c.size).sum();
        let total_chunks = chunks.len() as u32;

        let filename: String = FILE_META.with(|map| 
            map.borrow()
                .get(&file_id.to_string())
                .clone()  // Change cloned() to clone()
        ).unwrap_or_else(|| "unknown.bin".to_string());

        // Create a JSON response with metadata
        let metadata_response = FileMetadataResponse {
            file_id: file_id.clone().to_string(),
            total_size,
            total_chunks,
            filename
        };

        debug_log!(
            "download_file_metadata_handler: total_size={}, total_chunks={}",
            total_size,
            total_chunks
        );

        create_success_response(&metadata_response)
    }

    /// Returns the data for a single chunk by index.
    pub fn download_file_chunk_handler(req: &HttpRequest, _: &Params) -> HttpResponse<'static> {
        debug_log!("download_file_chunk_handler: Handling file chunk request");

        // // 1. Optionally authenticate
        // let requester_api_key = match authenticate_request(req) {
        //     Some(key) => key,
        //     None => return create_auth_error_response(),
        // };

        // // 2. Owner check, if you want
        // let is_owner = OWNER_ID.with(|owner_id| requester_api_key.user_id == *owner_id);
        // if !is_owner {
        //     return create_auth_error_response();
        // }

        // 3. Parse query for file_id & chunk_index
        let raw_query_string = req.get_query().unwrap_or(Some("".to_string()));
        let query_string = raw_query_string.as_deref().unwrap_or("");
        let query_map = crate::rest::helpers::parse_query_string(query_string);

        let file_id = match query_map.get("file_id") {
            Some(fid) => fid,
            None => {
                return create_response(
                    StatusCode::BAD_REQUEST,
                    ErrorResponse::err(400, "Missing file_id".to_string()).encode()
                );
            }
        };
        let file_id = decode(file_id).unwrap_or_else(|_| file_id.into());

        let chunk_index_str = match query_map.get("chunk_index") {
            Some(cix) => cix,
            None => {
                return create_response(
                    StatusCode::BAD_REQUEST,
                    ErrorResponse::err(400, "Missing chunk_index".to_string()).encode()
                );
            }
        };
        let chunk_index: u32 = match chunk_index_str.parse() {
            Ok(num) => num,
            Err(_) => {
                return create_response(
                    StatusCode::BAD_REQUEST,
                    ErrorResponse::err(400, "Invalid chunk_index".to_string()).encode()
                );
            }
        };

        debug_log!("download_file_chunk_handler: file_id={}, chunk_index={}", file_id, chunk_index);

        // 4. Retrieve all chunks, or just the one
        let mut chunks = get_file_chunks(&file_id);
        chunks.sort_by_key(|c| c.chunk_index);

        // Check if chunk_index is valid
        if chunk_index as usize >= chunks.len() {
            return create_response(
                StatusCode::NOT_FOUND,
                ErrorResponse::err(404, "Chunk index out of range".to_string()).encode()
            );
        }

        let chunk = &chunks[chunk_index as usize];
        debug_log!("download_file_chunk_handler: Found chunk size={}", chunk.size);

        // 5. Return the chunk data in the HTTP body
        //    We'll set the content-type to "application/octet-stream".
        HttpResponse::builder()
            .with_status_code(StatusCode::OK)
            .with_headers(vec![
                ("content-type".to_string(), "application/octet-stream".to_string()),
                ("cache-control".to_string(), "no-store, max-age=0".to_string()),
            ])
            .with_body(chunk.data.clone())
            .build()
    }


    pub fn get_raw_url_proxy_handler(req: &HttpRequest, params: &Params) -> HttpResponse<'static> {
        debug_log!("get_raw_url_proxy_handler: Handling raw URL proxy request");
    
        // 1. Extract file_id from URL parameters
        let file_id_with_extension = match params.get("file_id_with_extension") {
            Some(id) => id,
            None => return create_response(
                StatusCode::BAD_REQUEST,
                ErrorResponse::err(400, "Missing file ID in URL".to_string()).encode()
            ),
        };
    
        // Strip extension from file_id if present
        let file_id = match file_id_with_extension.rfind('.') {
            Some(pos) => &file_id_with_extension[..pos],
            None => file_id_with_extension,
        };
    
        debug_log!("get_raw_url_proxy_handler: file_id={}", file_id.clone());
    
        
        // 2. Look up file metadata
        let file_meta = file_uuid_to_metadata.get(&FileUUID(file_id.to_string()));
        let file_meta = match file_meta {
            Some(meta) => meta,
            None => return create_response(
                StatusCode::NOT_FOUND,
                ErrorResponse::err(404, "File not found".to_string()).encode()
            ),
        };
    
        // 3. Get disk info to access AWS credentials
        let disk = DISKS_BY_ID_HASHTABLE.with(|map| {
            map.borrow()
                .iter()
                .find(|(_, disk)| disk.disk_type == DiskTypeEnum::AwsBucket)
                .map(|(_, disk)| disk.clone())
        });
    
        let disk = match disk {
            Some(d) => d,
            None => return create_response(
                StatusCode::INTERNAL_SERVER_ERROR,
                ErrorResponse::err(500, "No S3 disk configured".to_string()).encode()
            ),
        };
    
        // 4. Parse AWS credentials
        let aws_auth: AwsBucketAuth = match disk.auth_json {
            Some(auth_str) => match serde_json::from_str(&auth_str) {
                Ok(auth) => auth,
                Err(_) => return create_response(
                    StatusCode::INTERNAL_SERVER_ERROR,
                    ErrorResponse::err(500, "Invalid AWS credentials".to_string()).encode()
                ),
            },
            None => return create_response(
                StatusCode::INTERNAL_SERVER_ERROR,
                ErrorResponse::err(500, "Missing AWS credentials".to_string()).encode()
            ),
        };
        
        // 5. Generate the download filename (original filename with extension)
        let download_filename = format!("{}.{}", file_meta.name, file_meta.extension);
        
        // 6. Generate presigned URL with content-disposition header
        let presigned_url = generate_s3_view_url(
            &format!("{}/{}", file_id, file_meta.name),  // S3 key
            &aws_auth,
            Some(3600),
            Some(&download_filename)
        );
    
        debug_log!("get_raw_url_proxy_handler: Redirecting to presigned URL");
    
        // 7. Return 302 redirect response
        HttpResponse::builder()
            .with_status_code(StatusCode::FOUND) // 302 Found
            .with_headers(vec![
                ("location".to_string(), presigned_url),
                ("cache-control".to_string(), "no-store, max-age=0".to_string()),
            ])
            .with_body(Vec::new())
            .build()
    }

    fn json_decode<T>(value: &[u8]) -> T
    where
        T: for<'de> Deserialize<'de>,
    {
        serde_json::from_slice(value).expect("Failed to deserialize value")
    }

    fn create_response(status_code: StatusCode, body: Vec<u8>) -> HttpResponse<'static> {
        HttpResponse::builder()
            .with_status_code(status_code)
            .with_headers(vec![
                ("content-type".to_string(), "application/json".to_string()),
                (
                    "strict-transport-security".to_string(),
                    "max-age=31536000; includeSubDomains".to_string(),
                ),
                ("x-content-type-options".to_string(), "nosniff".to_string()),
                ("referrer-policy".to_string(), "no-referrer".to_string()),
                (
                    "cache-control".to_string(),
                    "no-store, max-age=0".to_string(),
                ),
                ("pragma".to_string(), "no-cache".to_string()),
            ])
            .with_body(body)
            .build()
    }

    fn create_success_response<T: serde::Serialize>(data: &T) -> HttpResponse<'static> {
        let body = serde_json::to_vec(data).expect("Failed to serialize response");
        create_response(StatusCode::OK, body)
    }
    
}

// src/rest/directory/route.rs
use crate::debug_log;
use crate::rest::router;
use crate::types::RouteHandler;

pub const DIRECTORYS_SEARCH_PATH: &str = "/directory/search";
pub const DIRECTORYS_LIST_PATH: &str = "/directory/list";
pub const DIRECTORYS_ACTION_PATH: &str = "/directory/action";
pub const UPLOAD_CHUNK_PATH: &str = "/directory/raw_upload/chunk";
pub const COMPLETE_UPLOAD_PATH: &str = "/directory/raw_upload/complete";
pub const RAW_DOWNLOAD_META_PATH: &str = "/directory/raw_download/meta";
pub const RAW_DOWNLOAD_CHUNK_PATH: &str = "/directory/raw_download/chunk";
pub const RAW_URL_PROXY_PATH: &str = "/directory/asset/{file_id_with_extension}"; // for proxying raw urls 302 redirect to temp presigned s3 urls


type HandlerEntry = (&'static str, &'static str, RouteHandler);

pub fn init_routes() {
    let routes: &[HandlerEntry] = &[
        (
            "POST",
            DIRECTORYS_SEARCH_PATH,
            crate::rest::directory::handler::directorys_handlers::search_directory_handler,
        ),
        (
            "POST",
            DIRECTORYS_LIST_PATH,
            crate::rest::directory::handler::directorys_handlers::list_directorys_handler,
        ),
        (
            "POST",
            DIRECTORYS_ACTION_PATH,
            crate::rest::directory::handler::directorys_handlers::action_directory_handler,
        ),
        (
            "POST",
            UPLOAD_CHUNK_PATH,
            crate::rest::directory::handler::directorys_handlers::handle_upload_chunk,
        ),
        (
            "POST",
            COMPLETE_UPLOAD_PATH,
            crate::rest::directory::handler::directorys_handlers::handle_complete_upload,
        ),
        (
            "GET",
            RAW_DOWNLOAD_META_PATH,
            crate::rest::directory::handler::directorys_handlers::download_file_metadata_handler,
        ),
        (
            "GET",
            RAW_DOWNLOAD_CHUNK_PATH,
            crate::rest::directory::handler::directorys_handlers::download_file_chunk_handler,
        ),
        (
            "GET",
            RAW_URL_PROXY_PATH,
            crate::rest::directory::handler::directorys_handlers::get_raw_url_proxy_handler,
        ),
    ];

    for &(method, path, handler) in routes {
        debug_log!("Registering {} route: {}", method, path);
        router::insert_route(method, path, handler);
    }

}


// src/rest/directory/types.rs
use std::{collections::HashMap, fmt};
use serde::{Deserialize, Serialize, Deserializer, Serializer, ser::SerializeStruct};
use crate::{core::{api::disks::aws_s3::S3UploadResponse, state::directory::types::{DriveFullFilePath, FileMetadata, FileUUID, FolderMetadata, FolderUUID, Tag}}, rest::webhooks::types::SortDirection};
use crate::core::{
    state::disks::types::{DiskID, DiskTypeEnum},
    types::{ICPPrincipalString, UserID}
};
use serde::de;
use serde_json::Value;


#[derive(Debug, Clone, Deserialize)]
pub struct SearchDirectoryRequest {
    pub query_string: String,
}

#[derive(Debug, Clone, Deserialize)]
pub struct ListDirectoryRequest {
    pub folder_id: Option<String>,
    pub path: Option<String>,
    #[serde(default)]
    pub filters: String,
    #[serde(default = "default_page_size")]
    pub page_size: usize,
    #[serde(default)]
    pub direction: SortDirection,
    pub cursor: Option<String>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DirectoryListResponse {
    pub folders: Vec<FolderMetadata>,
    pub files: Vec<FileMetadata>,
    pub total_files: usize,
    pub total_folders: usize,
    pub cursor: Option<String>,
}

fn default_page_size() -> usize {
    50
}


#[derive(Debug, Clone, Deserialize)]
pub struct UploadChunkRequest {
    pub file_id: String,
    pub chunk_index: u32,
    pub chunk_data: Vec<u8>,
    pub total_chunks: u32
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct UploadChunkResponse {
    pub chunk_id: String,
    pub bytes_received: usize
}

#[derive(Debug, Clone, Deserialize)] 
pub struct CompleteUploadRequest {
    pub file_id: String,
    pub filename: String
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct CompleteUploadResponse {
    pub file_id: String,
    pub size: usize,
    pub chunks: u32,
    pub filename: String
}


#[derive(serde::Serialize, Deserialize)]
pub struct FileMetadataResponse {
    pub file_id: String,
    pub total_size: usize,
    pub total_chunks: u32,
    pub filename: String
}

pub type SearchDirectoryResponse = DirectoryListResponse;

pub type DirectoryResponse<'a, T> = crate::rest::drives::types::DriveResponse<'a, T>;
pub type ErrorResponse<'a> = DirectoryResponse<'a, ()>;



#[derive(Debug, Clone, Deserialize)] 
pub struct ClientSideUploadRequest {
    pub disk_id: String,
    pub folder_path: String,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ClientSideUploadResponse {
    pub signature: String,
}


// --------------------------------------------


#[derive(Debug, Clone)]
pub struct DirectoryAction {
    pub action: DirectoryActionEnum,
    pub target: ResourceIdentifier,
    pub payload: DirectoryActionPayload,
}

#[derive(Deserialize)]
struct RawDirectoryAction {
    action: DirectoryActionEnum,
    target: ResourceIdentifier,
    payload: Value,
}

#[derive(Debug, Clone, PartialEq, Eq, Hash, Serialize, Deserialize)]
pub struct DirectoryActionOutcomeID(pub String);

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DirectoryActionOutcome {
    pub id: DirectoryActionOutcomeID,
    pub success: bool,
    pub request: DirectoryAction,
    pub response: DirectoryActionResponse,
}
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DirectoryActionResponse {
    pub result: Option<DirectoryActionResult>,
    pub error: Option<DirectoryActionError>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DirectoryActionRequestBody {
    pub actions: Vec<DirectoryAction>,
}

// Custom deserialization for DirectoryAction.
impl<'de> Deserialize<'de> for DirectoryAction {
    fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>
    where
        D: Deserializer<'de>,
    {
        let raw = RawDirectoryAction::deserialize(deserializer)?;
        // Dispatch based on the action enum to convert the raw JSON payload.
        let payload = match raw.action {
            DirectoryActionEnum::GetFile => {
                DirectoryActionPayload::GetFile(serde_json::from_value(raw.payload)
                    .map_err(de::Error::custom)?)
            }
            DirectoryActionEnum::GetFolder => {
                DirectoryActionPayload::GetFolder(serde_json::from_value(raw.payload)
                    .map_err(de::Error::custom)?)
            }
            DirectoryActionEnum::CreateFile => {
                DirectoryActionPayload::CreateFile(serde_json::from_value(raw.payload)
                    .map_err(de::Error::custom)?)
            }
            DirectoryActionEnum::CreateFolder => {
                DirectoryActionPayload::CreateFolder(serde_json::from_value(raw.payload)
                    .map_err(de::Error::custom)?)
            }
            DirectoryActionEnum::UpdateFile => {
                DirectoryActionPayload::UpdateFile(serde_json::from_value(raw.payload)
                    .map_err(de::Error::custom)?)
            }
            DirectoryActionEnum::UpdateFolder => {
                DirectoryActionPayload::UpdateFolder(serde_json::from_value(raw.payload)
                    .map_err(de::Error::custom)?)
            }
            DirectoryActionEnum::DeleteFile => {
                DirectoryActionPayload::DeleteFile(serde_json::from_value(raw.payload)
                    .map_err(de::Error::custom)?)
            }
            DirectoryActionEnum::DeleteFolder => {
                DirectoryActionPayload::DeleteFolder(serde_json::from_value(raw.payload)
                    .map_err(de::Error::custom)?)
            }
            DirectoryActionEnum::CopyFile => {
                DirectoryActionPayload::CopyFile(serde_json::from_value(raw.payload)
                    .map_err(de::Error::custom)?)
            }
            DirectoryActionEnum::CopyFolder => {
                DirectoryActionPayload::CopyFolder(serde_json::from_value(raw.payload)
                    .map_err(de::Error::custom)?)
            }
            DirectoryActionEnum::MoveFile => {
                DirectoryActionPayload::MoveFile(serde_json::from_value(raw.payload)
                    .map_err(de::Error::custom)?)
            }
            DirectoryActionEnum::MoveFolder => {
                DirectoryActionPayload::MoveFolder(serde_json::from_value(raw.payload)
                    .map_err(de::Error::custom)?)
            }
            DirectoryActionEnum::RestoreTrash => {
                DirectoryActionPayload::RestoreTrash(serde_json::from_value(raw.payload)
                    .map_err(de::Error::custom)?)
            }
        };

        Ok(DirectoryAction {
            action: raw.action,
            target: raw.target,
            payload,
        })
    }
}

// Custom serialization for DirectoryAction.
impl Serialize for DirectoryAction {
    fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>
    where
        S: Serializer,
    {
        let mut state = serializer.serialize_struct("DirectoryAction", 3)?;
        state.serialize_field("action", &self.action)?;
        state.serialize_field("target", &self.target)?;
        // Match on the payload variant so that it serializes as a plain JSON object.
        match &self.payload {
            DirectoryActionPayload::GetFile(p) => state.serialize_field("payload", p)?,
            DirectoryActionPayload::GetFolder(p) => state.serialize_field("payload", p)?,
            DirectoryActionPayload::CreateFile(p) => state.serialize_field("payload", p)?,
            DirectoryActionPayload::CreateFolder(p) => state.serialize_field("payload", p)?,
            DirectoryActionPayload::UpdateFile(p) => state.serialize_field("payload", p)?,
            DirectoryActionPayload::UpdateFolder(p) => state.serialize_field("payload", p)?,
            DirectoryActionPayload::DeleteFile(p) => state.serialize_field("payload", p)?,
            DirectoryActionPayload::DeleteFolder(p) => state.serialize_field("payload", p)?,
            DirectoryActionPayload::CopyFile(p) => state.serialize_field("payload", p)?,
            DirectoryActionPayload::CopyFolder(p) => state.serialize_field("payload", p)?,
            DirectoryActionPayload::MoveFile(p) => state.serialize_field("payload", p)?,
            DirectoryActionPayload::MoveFolder(p) => state.serialize_field("payload", p)?,
            DirectoryActionPayload::RestoreTrash(p) => state.serialize_field("payload", p)?,
        }
        state.end()
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DirectoryActionError {
    pub code: i32,
    pub message: String,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(rename_all = "SCREAMING_SNAKE_CASE")]
pub enum DirectoryActionEnum {
    GetFile,
    GetFolder,
    CreateFile,
    CreateFolder,
    UpdateFile,
    UpdateFolder,
    DeleteFile,
    DeleteFolder,
    CopyFile,
    CopyFolder,
    MoveFile,
    MoveFolder,
    RestoreTrash,
}



#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
pub enum FileConflictResolutionEnum {
    REPLACE,
    KEEP_BOTH,
    KEEP_ORIGINAL,
    KEEP_NEWER,
}
impl fmt::Display for FileConflictResolutionEnum {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        match self {
            FileConflictResolutionEnum::REPLACE => write!(f, "REPLACE"),
            FileConflictResolutionEnum::KEEP_BOTH => write!(f, "KEEP_BOTH"),
            FileConflictResolutionEnum::KEEP_ORIGINAL => write!(f, "KEEP_ORIGINAL"),
            FileConflictResolutionEnum::KEEP_NEWER => write!(f, "KEEP_NEWER"),
        }
    }
}


#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ResourceIdentifier {
    #[serde(default)]
    pub resource_path: Option<DriveFullFilePath>, // points to file/folder itself, except in create file/folder operations would be a parent folder
    #[serde(default)]
    pub resource_id: Option<String>,  // points to file/folder itself, except in create file/folder operations would be a parent folder
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum DirectoryActionPayload {
    GetFile(GetFilePayload),
    GetFolder(GetFolderPayload),
    CreateFile(CreateFilePayload),
    CreateFolder(CreateFolderPayload),
    UpdateFile(UpdateFilePayload),
    UpdateFolder(UpdateFolderPayload),
    DeleteFile(DeleteFilePayload),
    DeleteFolder(DeleteFolderPayload),
    CopyFile(CopyFilePayload),
    CopyFolder(CopyFolderPayload),
    MoveFile(MoveFilePayload),
    MoveFolder(MoveFolderPayload),
    RestoreTrash(RestoreTrashPayload),
}

#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(deny_unknown_fields)]
pub struct GetFilePayload {}

#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(deny_unknown_fields)]
pub struct GetFolderPayload {}

#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(deny_unknown_fields)]
pub struct CreateFilePayload {
    pub name: String,
    pub extension: String,
    pub tags: Vec<Tag>,
    pub file_size: u64,
    pub raw_url: String,
    pub disk_id: DiskID,
    pub expires_at: Option<i64>,
    pub file_conflict_resolution: Option<FileConflictResolutionEnum>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(deny_unknown_fields)]
pub struct CreateFolderPayload {
    pub name: String,
    pub tags: Vec<Tag>,
    pub disk_id: DiskID,
    pub expires_at: Option<i64>,
    pub file_conflict_resolution: Option<FileConflictResolutionEnum>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(deny_unknown_fields)]
pub struct UpdateFilePayload {
    pub name: Option<String>,
    pub tags: Option<Vec<Tag>>,
    pub raw_url: Option<String>,
    pub expires_at: Option<i64>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(deny_unknown_fields)]
pub struct UpdateFolderPayload {
    pub name: Option<String>,
    pub tags: Option<Vec<Tag>>,
    pub expires_at: Option<i64>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(deny_unknown_fields)]
pub struct DeleteFilePayload {
    pub permanent: bool,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(deny_unknown_fields)]
pub struct DeleteFolderPayload {
    pub permanent: bool,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(deny_unknown_fields)]
pub struct CopyFilePayload {
    pub destination_folder_id: Option<FolderUUID>,
    pub destination_folder_path: Option<DriveFullFilePath>,
    pub file_conflict_resolution: Option<FileConflictResolutionEnum>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(deny_unknown_fields)]
pub struct CopyFolderPayload {
    pub destination_folder_id: Option<FolderUUID>,
    pub destination_folder_path: Option<DriveFullFilePath>,
    pub file_conflict_resolution: Option<FileConflictResolutionEnum>,
}

#[derive(Debug, Clone,Serialize, Deserialize)]
#[serde(deny_unknown_fields)]
pub struct MoveFilePayload {
    pub destination_folder_id: Option<FolderUUID>,
    pub destination_folder_path: Option<DriveFullFilePath>,
    pub file_conflict_resolution: Option<FileConflictResolutionEnum>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(deny_unknown_fields)]
pub struct MoveFolderPayload {
    pub destination_folder_id: Option<FolderUUID>,
    pub destination_folder_path: Option<DriveFullFilePath>,
    pub file_conflict_resolution: Option<FileConflictResolutionEnum>,
}



#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(deny_unknown_fields)]
pub struct RestoreTrashPayload {
    pub file_conflict_resolution: Option<FileConflictResolutionEnum>,
    pub restore_to_folder_path: Option<DriveFullFilePath>,
}


// Response types remain the same as before
#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(untagged)]
pub enum DirectoryActionResult {
    GetFile(FileMetadata),
    GetFolder(FolderMetadata),
    CreateFile(CreateFileResponse),
    CreateFolder(FolderMetadata),
    UpdateFile(FileMetadata),
    UpdateFolder(FolderMetadata),
    DeleteFile(DeleteFileResponse),
    DeleteFolder(DeleteFolderResponse),
    CopyFile(FileMetadata),
    CopyFolder(FolderMetadata),
    MoveFile(FileMetadata),
    MoveFolder(FolderMetadata),
    RestoreTrash(RestoreTrashResponse)
}


#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct CreateFileResponse {
    pub file: FileMetadata,
    pub upload: S3UploadResponse,
    pub notes: String,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct CreateFolderResponse {
    pub notes: String,
    pub folder: FolderMetadata,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DeleteFileResponse {
    pub file_id: FileUUID,
    pub path_to_trash: DriveFullFilePath,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DeleteFolderResponse {
    pub folder_id: FolderUUID,
    pub path_to_trash: DriveFullFilePath, // if empty then its permanently deleted
    #[serde(skip_serializing_if = "Option::is_none")]
    pub deleted_files: Option<Vec<FileUUID>>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub deleted_folders: Option<Vec<FolderUUID>>,
}


#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct RestoreTrashResponse {
    pub restored_files: Vec<FileUUID>,
    pub restored_folders: Vec<FolderUUID>,
}

// Example JSON requests:
/*
1. GET_FILE request (by path):
{
    "action": "GET_FILE",
    "target": {
        "resource_path": "/user/documents/report.pdf"
    },
    "payload": {}
}

2. GET_FILE request (by id):
{
    "action": "GET_FILE",
    "target": {
        "resource_id": "file-uuid-123"
    },
    "payload": {}
}

3. GET_FOLDER request:
{
    "action": "GET_FOLDER",
    "target": {
        "resource_id": "folder-uuid-456"
    },
    "payload": {}
}

4. CREATE_FILE request:
{
    "action": "CREATE_FILE",
    "target": {
        "resource_path": "/user/documents/report.pdf"
    },
    "payload": {
        "name": "report.pdf",
        "folder_uuid": "folder-uuid-789",
        "extension": "pdf",
        "tags": ["work", "2024"],
        "file_size": 1024567,
        "raw_url": "https://example.com/files/raw/123",
        "disk_id": "disk-1",
        "expires_at": 1735689600000
    }
}

5. CREATE_FOLDER request:
{
    "action": "CREATE_FOLDER",
    "target": {
        "resource_path": "/user/documents/project-alpha"
    },
    "payload": {
        "name": "project-alpha",
        "parent_folder_uuid": "folder-uuid-123",
        "tags": ["project", "active"],
        "disk_id": "disk-1",
        "expires_at": 1735689600000
    }
}

6. UPDATE_FILE request:
{
    "action": "UPDATE_FILE",
    "target": {
        "resource_id": "file-uuid-123"
    },
    "payload": {
        "name": "updated-report.pdf",
        "folder_uuid": "folder-uuid-new",
        "tags": ["work", "2024", "reviewed"],
        "raw_url": "https://example.com/files/raw/124",
        "expires_at": 1735689600000
    }
}

7. UPDATE_FOLDER request:
{
    "action": "UPDATE_FOLDER",
    "target": {
        "resource_id": "folder-uuid-456"
    },
    "payload": {
        "name": "project-beta",
        "parent_folder_uuid": "folder-uuid-new-parent",
        "tags": ["project", "active", "phase-2"],
        "expires_at": 1735689600000
    }
}

8. DELETE_FILE request:
{
    "action": "DELETE_FILE",
    "target": {
        "resource_id": "file-uuid-123"
    },
    "payload": {
        "permanent": false
    }
}

9. DELETE_FOLDER request:
{
    "action": "DELETE_FOLDER",
    "target": {
        "resource_id": "folder-uuid-456"
    },
    "payload": {
        "permanent": false,
        "recursive": true
    }
}

10. COPY_FILE request:
{
    "action": "COPY_FILE",
    "target": {
        "resource_id": "file-uuid-123"
    },
    "payload": {
        "destination_folder_id": "folder-uuid-destination",
        "new_name": "report-copy.pdf"
    }
}

11. COPY_FOLDER request:
{
    "action": "COPY_FOLDER",
    "target": {
        "resource_id": "folder-uuid-456"
    },
    "payload": {
        "destination_parent_id": "folder-uuid-destination",
        "new_name": "project-alpha-backup",
        "recursive": true
    }
}

12. MOVE_FILE request:
{
    "action": "MOVE_FILE",
    "target": {
        "resource_id": "file-uuid-123"
    },
    "payload": {
        "destination_folder_id": "folder-uuid-destination",
        "new_name": "report-new-location.pdf"
    }
}

13. MOVE_FOLDER request:
{
    "action": "MOVE_FOLDER",
    "target": {
        "resource_id": "folder-uuid-456"
    },
    "payload": {
        "destination_parent_id": "folder-uuid-destination",
        "new_name": "project-alpha-archived"
    }
}

14. RESTORE_TRASH request:
{
    "action": "RESTORE_TRASH",
    "target": {
        "resource_id": "folder-uuid-456"
    },
*/
